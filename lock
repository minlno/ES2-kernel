Documentation/RCU/torture.rst:234:given directory can be supplied to kvm-find-errors.sh in order to have
Documentation/RCU/torture.rst:237:	tools/testing/selftests/rcutorture/bin/kvm-find-errors.sh \
Documentation/admin-guide/hw-vuln/l1tf.rst:357:  EPT can be disabled in the hypervisor via the 'kvm-intel.ept' parameter.
Documentation/admin-guide/hw-vuln/l1tf.rst:424:The option/parameter is "kvm-intel.vmentry_l1d_flush=". It takes the
Documentation/admin-guide/hw-vuln/l1tf.rst:445:line, then 'always' is enforced and the kvm-intel.vmentry_l1d_flush
Documentation/admin-guide/hw-vuln/l1tf.rst:491:  EPT can be disabled in the hypervisor via the 'kvm-intel.ept' parameter.
Documentation/admin-guide/hw-vuln/l1tf.rst:538:    parameters 'nosmt', 'l1tf', 'kvm-intel.vmentry_l1d_flush' and at run
Documentation/admin-guide/hw-vuln/l1tf.rst:550:    EPT can be disabled in the hypervisor via the 'kvm-intel.ept'
Documentation/admin-guide/kernel-parameters.txt:317:			             This mode requires kvm-amd.avic=1.
Documentation/admin-guide/kernel-parameters.txt:2288:	kvm-amd.nested=	[KVM,AMD] Allow nested virtualization in KVM/SVM.
Documentation/admin-guide/kernel-parameters.txt:2291:	kvm-amd.npt=	[KVM,AMD] Disable nested paging (virtualized MMU)
Documentation/admin-guide/kernel-parameters.txt:2295:	kvm-arm.mode=
Documentation/admin-guide/kernel-parameters.txt:2307:	kvm-arm.vgic_v3_group0_trap=
Documentation/admin-guide/kernel-parameters.txt:2311:	kvm-arm.vgic_v3_group1_trap=
Documentation/admin-guide/kernel-parameters.txt:2315:	kvm-arm.vgic_v3_common_trap=
Documentation/admin-guide/kernel-parameters.txt:2319:	kvm-arm.vgic_v4_enable=
Documentation/admin-guide/kernel-parameters.txt:2331:	kvm-intel.ept=	[KVM,Intel] Disable extended page tables
Documentation/admin-guide/kernel-parameters.txt:2335:	kvm-intel.emulate_invalid_guest_state=
Documentation/admin-guide/kernel-parameters.txt:2339:	kvm-intel.flexpriority=
Documentation/admin-guide/kernel-parameters.txt:2343:	kvm-intel.nested=
Documentation/admin-guide/kernel-parameters.txt:2347:	kvm-intel.unrestricted_guest=
Documentation/admin-guide/kernel-parameters.txt:2352:	kvm-intel.vmentry_l1d_flush=[KVM,Intel] Mitigation for L1 Terminal Fault
Documentation/admin-guide/kernel-parameters.txt:2364:	kvm-intel.vpid=	[KVM,Intel] Disable Virtual Processor Identification
Documentation/filesystems/fsverity.rst:637:To test fs-verity, use xfstests.  For example, using `kvm-xfstests
Documentation/filesystems/fsverity.rst:638:<https://github.com/tytso/xfstests-bld/blob/master/Documentation/kvm-quickstart.md>`_::
Documentation/filesystems/fsverity.rst:640:    kvm-xfstests -c ext4,f2fs -g verity
Documentation/filesystems/fscrypt.rst:1266:f2fs encryption using `kvm-xfstests
Documentation/filesystems/fscrypt.rst:1267:<https://github.com/tytso/xfstests-bld/blob/master/Documentation/kvm-quickstart.md>`_::
Documentation/filesystems/fscrypt.rst:1269:    kvm-xfstests -c ext4,f2fs -g encrypt
Documentation/filesystems/fscrypt.rst:1270:    kvm-xfstests -c ext4,f2fs -g encrypt -m inlinecrypt
Documentation/filesystems/fscrypt.rst:1273:a separate command, and it takes some time for kvm-xfstests to set up
Documentation/filesystems/fscrypt.rst:1276:    kvm-xfstests -c ubifs -g encrypt
Documentation/filesystems/fscrypt.rst:1289:kvm-xfstests, use the "encrypt" filesystem configuration::
Documentation/filesystems/fscrypt.rst:1291:    kvm-xfstests -c ext4/encrypt,f2fs/encrypt -g auto
Documentation/filesystems/fscrypt.rst:1292:    kvm-xfstests -c ext4/encrypt,f2fs/encrypt -g auto -m inlinecrypt
Documentation/filesystems/fscrypt.rst:1297:instead of kvm-xfstests::
Documentation/networking/device_drivers/ethernet/mellanox/mlx5.rst:70:|           1) `Legacy SRIOV mode (L2 mac vlan steering based) <https://community.mellanox.com/s/article/howto-configure-sr-iov-for-connectx-4-connectx-5-with-kvm--ethernet-x>`_.
Documentation/virt/kvm/arm/ptp_kvm.rst:8:host to the guest using a KVM-specific hypercall.
Documentation/virt/kvm/amd-memory-encryption.rst:434:See [white-paper]_, [api-spec]_, [amd-apm]_ and [kvm-forum]_ for more info.
Documentation/virt/kvm/amd-memory-encryption.rst:439:.. [kvm-forum]  https://www.linux-kvm.org/images/7/74/02x08A-Thomas_Lendacky-AMDs_Virtualizatoin_Memory_Encryption_Technology.pdf
Documentation/virt/kvm/cpuid.rst:11:mask-out some, or even all KVM-related cpuid features before launching
Documentation/virt/kvm/devices/xive.rst:66:  helpers in KVM-PPC.
Documentation/virt/kvm/halt-polling.rst:27:The powerpc kvm-hv specific case is implemented in:
Documentation/virt/kvm/halt-polling.rst:41:or in the case of powerpc kvm-hv, in the vcore struct:
Documentation/virt/kvm/halt-polling.rst:86:powerpc kvm-hv case.
Documentation/virt/kvm/locking.rst:12:- kvm->lock is taken outside vcpu->mutex
Documentation/virt/kvm/locking.rst:14:- kvm->lock is taken outside kvm->slots_lock and kvm->irq_lock
Documentation/virt/kvm/locking.rst:16:- kvm->slots_lock is taken outside kvm->irq_lock, though acquiring
Documentation/virt/kvm/locking.rst:21:- vcpu->mutex is taken outside kvm->arch.hyperv.hv_lock
Documentation/virt/kvm/locking.rst:23:- kvm->arch.mmu_lock is an rwlock.  kvm->arch.tdp_mmu_pages_lock is
Documentation/virt/kvm/locking.rst:24:  taken inside kvm->arch.mmu_lock, and cannot be taken without already
Documentation/virt/kvm/locking.rst:25:  holding kvm->arch.mmu_lock (typically with ``read_lock``, otherwise
Documentation/virt/kvm/locking.rst:26:  there's no need to take kvm->arch.tdp_mmu_pages_lock at all).
Documentation/virt/kvm/locking.rst:221::Name:		kvm->mmu_lock
Documentation/virt/kvm/locking.rst:227::Name:		kvm->srcu
Documentation/virt/kvm/locking.rst:230::Protects:	- kvm->memslots
Documentation/virt/kvm/locking.rst:231:		- kvm->buses
Documentation/virt/kvm/locking.rst:234:		MMIO/PIO address->device structure mapping (kvm->buses).
Documentation/virt/kvm/running-nested-guests.rst:6:can be KVM-based or a different hypervisor).  The straightforward
Documentation/virt/kvm/running-nested-guests.rst:103:    options kvm-intel nested=y
Documentation/virt/kvm/running-nested-guests.rst:107:    $ sudo rmmod kvm-intel
Documentation/virt/kvm/running-nested-guests.rst:108:    $ sudo modprobe kvm-intel
Documentation/virt/kvm/running-nested-guests.rst:116:name is ``kvm-amd``.
Documentation/virt/kvm/msr.rst:4:KVM-specific MSRs
Documentation/virt/kvm/api.rst:2694:  kvm-pit/<owner-process-pid>
Documentation/virt/kvm/api.rst:6154:kvm-hv module parameter.
Documentation/virt/kvm/api.rst:6164:L2. Similarly, for kvm-intel only, DR6 will not be modified prior to
Documentation/virt/kvm/nested-vmx.rst:42:kvm-intel module.
MAINTAINERS:10011:L:	kvm-ppc@vger.kernel.org
arch/arm64/include/asm/kvm_emulate.h:98:	    vcpu->kvm->arch.vgic.nassgireq)
arch/arm64/include/asm/kvm_host.h:54: * Mode of operation configurable with kvm-arm.mode early param.
arch/arm64/include/asm/kvm_mmu.h:146:#define kvm_phys_shift(kvm)		VTCR_EL2_IPA(kvm->arch.vtcr)
arch/arm64/include/asm/kvm_mmu.h:232: * We are not in the kvm->srcu critical section most of the time, so we take
arch/arm64/include/asm/kvm_mmu.h:239:	int srcu_idx = srcu_read_lock(&kvm->srcu);
arch/arm64/include/asm/kvm_mmu.h:242:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/arm64/include/asm/kvm_mmu.h:250:	int srcu_idx = srcu_read_lock(&kvm->srcu);
arch/arm64/include/asm/kvm_mmu.h:253:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/arm64/include/asm/stage2_pgtable.h:31:#define kvm_stage2_levels(kvm)		VTCR_EL2_LVLS(kvm->arch.vtcr)
arch/arm64/include/uapi/asm/kvm.h:248:/* KVM-as-firmware specific pseudo-registers */
arch/arm64/kernel/idreg-override.c:97:	{ "kvm-arm.mode=nvhe",		"id_aa64mmfr1.vh=0" },
arch/arm64/kernel/idreg-override.c:98:	{ "kvm-arm.mode=protected",	"id_aa64mmfr1.vh=0" },
arch/arm64/kvm/Makefile:13:kvm-y := $(KVM)/kvm_main.o $(KVM)/coalesced_mmio.o $(KVM)/eventfd.o \
arch/arm64/kvm/Makefile:24:	 vgic/vgic-mmio-v3.o vgic/vgic-kvm-device.o \
arch/arm64/kvm/Makefile:27:kvm-$(CONFIG_HW_PERF_EVENTS)  += pmu-emul.o
arch/arm64/kvm/arch_timer.c:756:	mutex_lock(&kvm->lock);
arch/arm64/kvm/arch_timer.c:765:	mutex_unlock(&kvm->lock);
arch/arm64/kvm/arm.c:94:		kvm->arch.return_nisv_io_abort_to_user = true;
arch/arm64/kvm/arm.c:120:		kvm->arch.pfr0_csv2 = 1;
arch/arm64/kvm/arm.c:122:		kvm->arch.pfr0_csv3 = 1;
arch/arm64/kvm/arm.c:137:	ret = kvm_init_stage2_mmu(kvm, &kvm->arch.mmu);
arch/arm64/kvm/arm.c:148:	kvm->arch.max_vcpus = kvm_arm_default_max_vcpus();
arch/arm64/kvm/arm.c:154:	kvm_free_stage2_pgd(&kvm->arch.mmu);
arch/arm64/kvm/arm.c:172:	bitmap_free(kvm->arch.pmu_filter);
arch/arm64/kvm/arm.c:177:		if (kvm->vcpus[i]) {
arch/arm64/kvm/arm.c:178:			kvm_vcpu_destroy(kvm->vcpus[i]);
arch/arm64/kvm/arm.c:179:			kvm->vcpus[i] = NULL;
arch/arm64/kvm/arm.c:182:	atomic_set(&kvm->online_vcpus, 0);
arch/arm64/kvm/arm.c:223:			r = kvm->arch.max_vcpus;
arch/arm64/kvm/arm.c:231:			r = kvm->arch.vgic.msis_require_devid;
arch/arm64/kvm/arm.c:302:	if (id >= kvm->arch.max_vcpus)
arch/arm64/kvm/arm.c:327:	vcpu->arch.hw_mmu = &vcpu->kvm->arch.mmu;
arch/arm64/kvm/arm.c:521:	smp_rmb(); /* Orders read of kvm_vmid_gen and kvm->arch.vmid */
arch/arm64/kvm/arm.c:957:	int nrcpus = atomic_read(&kvm->online_vcpus);
arch/arm64/kvm/arm.c:1328:		mutex_lock(&kvm->lock);
arch/arm64/kvm/arm.c:1330:		mutex_unlock(&kvm->lock);
arch/arm64/kvm/arm.c:2147:early_param("kvm-arm.mode", early_kvm_mode_cfg);
arch/arm64/kvm/hyp/vgic-v2-cpuif-proxy.c:40:	struct vgic_dist *vgic = &kvm->arch.vgic;
arch/arm64/kvm/mmio.c:138:		if (vcpu->kvm->arch.return_nisv_io_abort_to_user) {
arch/arm64/kvm/pvtime.c:25:	idx = srcu_read_lock(&kvm->srcu);
arch/arm64/kvm/pvtime.c:32:	srcu_read_unlock(&kvm->srcu, idx);
arch/arm64/kvm/pvtime.c:96:	idx = srcu_read_lock(&kvm->srcu);
arch/arm64/kvm/pvtime.c:99:	srcu_read_unlock(&kvm->srcu, idx);
arch/arm64/kvm/pmu-emul.c:25:	switch (kvm->arch.pmuver) {
arch/arm64/kvm/pmu-emul.c:33:		WARN_ONCE(1, "Unknown PMU version %d\n", kvm->arch.pmuver);
arch/arm64/kvm/pmu-emul.c:630:	if (vcpu->kvm->arch.pmu_filter &&
arch/arm64/kvm/pmu-emul.c:631:	    !test_bit(eventsel, vcpu->kvm->arch.pmu_filter))
arch/arm64/kvm/pmu-emul.c:789:	unsigned long *bmap = vcpu->kvm->arch.pmu_filter;
arch/arm64/kvm/pmu-emul.c:802:		if (vcpu->kvm->arch.pmuver >= ID_AA64DFR0_PMUVER_8_4)
arch/arm64/kvm/pmu-emul.c:919:	if (!vcpu->kvm->arch.pmuver)
arch/arm64/kvm/pmu-emul.c:920:		vcpu->kvm->arch.pmuver = kvm_pmu_probe_pmuver();
arch/arm64/kvm/pmu-emul.c:922:	if (vcpu->kvm->arch.pmuver == 0xf)
arch/arm64/kvm/pmu-emul.c:967:		mutex_lock(&vcpu->kvm->lock);
arch/arm64/kvm/pmu-emul.c:969:		if (!vcpu->kvm->arch.pmu_filter) {
arch/arm64/kvm/pmu-emul.c:970:			vcpu->kvm->arch.pmu_filter = bitmap_alloc(nr_events, GFP_KERNEL);
arch/arm64/kvm/pmu-emul.c:971:			if (!vcpu->kvm->arch.pmu_filter) {
arch/arm64/kvm/pmu-emul.c:972:				mutex_unlock(&vcpu->kvm->lock);
arch/arm64/kvm/pmu-emul.c:983:				bitmap_zero(vcpu->kvm->arch.pmu_filter, nr_events);
arch/arm64/kvm/pmu-emul.c:985:				bitmap_fill(vcpu->kvm->arch.pmu_filter, nr_events);
arch/arm64/kvm/pmu-emul.c:989:			bitmap_set(vcpu->kvm->arch.pmu_filter, filter.base_event, filter.nevents);
arch/arm64/kvm/pmu-emul.c:991:			bitmap_clear(vcpu->kvm->arch.pmu_filter, filter.base_event, filter.nevents);
arch/arm64/kvm/pmu-emul.c:993:		mutex_unlock(&vcpu->kvm->lock);
arch/arm64/kvm/psci.c:247:		mutex_lock(&kvm->lock);
arch/arm64/kvm/psci.c:249:		mutex_unlock(&kvm->lock);
arch/arm64/kvm/psci.c:357:		mutex_lock(&kvm->lock);
arch/arm64/kvm/psci.c:359:		mutex_unlock(&kvm->lock);
arch/arm64/kvm/psci.c:501:			vcpu->kvm->arch.psci_version = val;
arch/arm64/kvm/psci.c:507:			vcpu->kvm->arch.psci_version = val;
arch/arm64/kvm/reset.c:381:	kvm->arch.vtcr = kvm_get_vtcr(mmfr0, mmfr1, phys_shift);
arch/arm64/kvm/mmu.c:51:		struct kvm_pgtable *pgt = kvm->arch.mmu.pgt;
arch/arm64/kvm/mmu.c:61:			cond_resched_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:83:	kvm_call_hyp(__kvm_tlb_flush_vmid, &kvm->arch.mmu);
arch/arm64/kvm/mmu.c:171:	assert_spin_locked(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:204:	idx = srcu_read_lock(&kvm->srcu);
arch/arm64/kvm/mmu.c:205:	spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:211:	spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:212:	srcu_read_unlock(&kvm->srcu, idx);
arch/arm64/kvm/mmu.c:460:	err = kvm_pgtable_stage2_init(pgt, &kvm->arch, &kvm_s2_mm_ops);
arch/arm64/kvm/mmu.c:473:	mmu->arch = &kvm->arch;
arch/arm64/kvm/mmu.c:522:			unmap_stage2_range(&kvm->arch.mmu, gpa, vm_end - vm_start);
arch/arm64/kvm/mmu.c:541:	idx = srcu_read_lock(&kvm->srcu);
arch/arm64/kvm/mmu.c:543:	spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:549:	spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:551:	srcu_read_unlock(&kvm->srcu, idx);
arch/arm64/kvm/mmu.c:559:	spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:566:	spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:589:	struct kvm_pgtable *pgt = kvm->arch.mmu.pgt;
arch/arm64/kvm/mmu.c:603:		spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:606:		spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:639: * Acquires kvm_mmu_lock. Called with kvm->slots_lock mutex acquired,
arch/arm64/kvm/mmu.c:654:	spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:655:	stage2_wp_range(&kvm->arch.mmu, start, end);
arch/arm64/kvm/mmu.c:656:	spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:679:	stage2_wp_range(&kvm->arch.mmu, start, end);
arch/arm64/kvm/mmu.c:920:	mmu_seq = vcpu->kvm->mmu_notifier_seq;
arch/arm64/kvm/mmu.c:959:	spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:1007:	spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:1022:	spin_lock(&vcpu->kvm->mmu_lock);
arch/arm64/kvm/mmu.c:1025:	spin_unlock(&vcpu->kvm->mmu_lock);
arch/arm64/kvm/mmu.c:1083:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/arm64/kvm/mmu.c:1152:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/arm64/kvm/mmu.c:1158:	if (!kvm->arch.mmu.pgt)
arch/arm64/kvm/mmu.c:1161:	__unmap_stage2_range(&kvm->arch.mmu, range->start << PAGE_SHIFT,
arch/arm64/kvm/mmu.c:1172:	if (!kvm->arch.mmu.pgt)
arch/arm64/kvm/mmu.c:1189:	kvm_pgtable_stage2_map(kvm->arch.mmu.pgt, range->start << PAGE_SHIFT,
arch/arm64/kvm/mmu.c:1202:	if (!kvm->arch.mmu.pgt)
arch/arm64/kvm/mmu.c:1207:	kpte = kvm_pgtable_stage2_mkold(kvm->arch.mmu.pgt,
arch/arm64/kvm/mmu.c:1215:	if (!kvm->arch.mmu.pgt)
arch/arm64/kvm/mmu.c:1218:	return kvm_pgtable_stage2_is_young(kvm->arch.mmu.pgt,
arch/arm64/kvm/mmu.c:1416:	spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:1418:		unmap_stage2_range(&kvm->arch.mmu, mem->guest_phys_addr, mem->memory_size);
arch/arm64/kvm/mmu.c:1421:	spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:1437:	kvm_free_stage2_pgd(&kvm->arch.mmu);
arch/arm64/kvm/mmu.c:1446:	spin_lock(&kvm->mmu_lock);
arch/arm64/kvm/mmu.c:1447:	unmap_stage2_range(&kvm->arch.mmu, gpa, size);
arch/arm64/kvm/mmu.c:1448:	spin_unlock(&kvm->mmu_lock);
arch/arm64/kvm/sys_regs.c:1044:		val |= FIELD_PREP(FEATURE(ID_AA64PFR0_CSV2), (u64)vcpu->kvm->arch.pfr0_csv2);
arch/arm64/kvm/sys_regs.c:1046:		val |= FIELD_PREP(FEATURE(ID_AA64PFR0_CSV3), (u64)vcpu->kvm->arch.pfr0_csv3);
arch/arm64/kvm/sys_regs.c:1175:	vcpu->kvm->arch.pfr0_csv2 = csv2;
arch/arm64/kvm/sys_regs.c:1176:	vcpu->kvm->arch.pfr0_csv3 = csv3 ;
arch/arm64/kvm/vgic/vgic-debug.c:58:	int nr_cpus = atomic_read(&kvm->online_vcpus);
arch/arm64/kvm/vgic/vgic-debug.c:63:	iter->nr_spis = kvm->arch.vgic.nr_spis;
arch/arm64/kvm/vgic/vgic-debug.c:64:	if (kvm->arch.vgic.vgic_model == KVM_DEV_TYPE_ARM_VGIC_V3) {
arch/arm64/kvm/vgic/vgic-debug.c:88:	mutex_lock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-debug.c:89:	iter = kvm->arch.vgic.iter;
arch/arm64/kvm/vgic/vgic-debug.c:102:	kvm->arch.vgic.iter = iter;
arch/arm64/kvm/vgic/vgic-debug.c:107:	mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-debug.c:114:	struct vgic_state_iter *iter = kvm->arch.vgic.iter;
arch/arm64/kvm/vgic/vgic-debug.c:135:	mutex_lock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-debug.c:136:	iter = kvm->arch.vgic.iter;
arch/arm64/kvm/vgic/vgic-debug.c:139:	kvm->arch.vgic.iter = NULL;
arch/arm64/kvm/vgic/vgic-debug.c:140:	mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-debug.c:239:		print_dist_state(s, &kvm->arch.vgic);
arch/arm64/kvm/vgic/vgic-debug.c:243:	if (!kvm->arch.vgic.initialized)
arch/arm64/kvm/vgic/vgic-debug.c:274:	debugfs_create_file("vgic-state", 0444, kvm->debugfs_dentry, kvm,
arch/arm64/kvm/vgic/vgic-irqfd.c:138:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-init.c:54:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-init.c:100:		kvm->arch.max_vcpus = VGIC_V2_MAX_CPUS;
arch/arm64/kvm/vgic/vgic-init.c:102:		kvm->arch.max_vcpus = VGIC_V3_MAX_CPUS;
arch/arm64/kvm/vgic/vgic-init.c:104:	if (atomic_read(&kvm->online_vcpus) > kvm->arch.max_vcpus) {
arch/arm64/kvm/vgic/vgic-init.c:109:	kvm->arch.vgic.in_kernel = true;
arch/arm64/kvm/vgic/vgic-init.c:110:	kvm->arch.vgic.vgic_model = type;
arch/arm64/kvm/vgic/vgic-init.c:112:	kvm->arch.vgic.vgic_dist_base = VGIC_ADDR_UNDEF;
arch/arm64/kvm/vgic/vgic-init.c:115:		kvm->arch.vgic.vgic_cpu_base = VGIC_ADDR_UNDEF;
arch/arm64/kvm/vgic/vgic-init.c:117:		INIT_LIST_HEAD(&kvm->arch.vgic.rd_regions);
arch/arm64/kvm/vgic/vgic-init.c:133:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-init.c:188:	struct vgic_dist *dist = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-init.c:229:		mutex_lock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-init.c:231:		mutex_unlock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-init.c:252: * Must be called with kvm->lock held!
arch/arm64/kvm/vgic/vgic-init.c:256:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-init.c:264:	if (kvm->created_vcpus != atomic_read(&kvm->online_vcpus))
arch/arm64/kvm/vgic/vgic-init.c:329:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-init.c:369:/* To be called with kvm->lock held */
arch/arm64/kvm/vgic/vgic-init.c:385:	mutex_lock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-init.c:387:	mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-init.c:407:		if (kvm->arch.vgic.vgic_model != KVM_DEV_TYPE_ARM_VGIC_V2)
arch/arm64/kvm/vgic/vgic-init.c:410:		mutex_lock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-init.c:412:		mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-init.c:431:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-init.c:437:	mutex_lock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-init.c:455:	mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:34:	if (kvm->arch.vgic.vgic_model != type_needed)
arch/arm64/kvm/vgic/vgic-kvm-device.c:59:	struct vgic_dist *vgic = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-kvm-device.c:63:	mutex_lock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:151:	mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:191:		mutex_lock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:193:		if (vgic_ready(dev->kvm) || dev->kvm->arch.vgic.nr_spis)
arch/arm64/kvm/vgic/vgic-kvm-device.c:196:			dev->kvm->arch.vgic.nr_spis =
arch/arm64/kvm/vgic/vgic-kvm-device.c:199:		mutex_unlock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:206:			mutex_lock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:208:			mutex_unlock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:243:		r = put_user(dev->kvm->arch.vgic.nr_spis +
arch/arm64/kvm/vgic/vgic-kvm-device.c:292:	if (cpuid >= atomic_read(&dev->kvm->online_vcpus))
arch/arm64/kvm/vgic/vgic-kvm-device.c:314:	unlock_vcpus(kvm, atomic_read(&kvm->online_vcpus) - 1);
arch/arm64/kvm/vgic/vgic-kvm-device.c:363:	mutex_lock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:388:	mutex_unlock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:468:	.name = "kvm-arm-vgic-v2",
arch/arm64/kvm/vgic/vgic-kvm-device.c:528:	mutex_lock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:587:	mutex_unlock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:638:			mutex_lock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:641:				mutex_unlock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:646:			mutex_unlock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-kvm-device.c:738:	.name = "kvm-arm-vgic-v3",
arch/arm64/kvm/vgic/vgic-its.c:42:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-its.c:283:	u64 propbase = GICR_PROPBASER_ADDRESS(kvm->arch.vgic.propbaser);
arch/arm64/kvm/vgic/vgic-its.c:321:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-its.c:582:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-its.c:597:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-its.c:648:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-its.c:973:	idx = srcu_read_lock(&its->dev->kvm->srcu);
arch/arm64/kvm/vgic/vgic-its.c:975:	srcu_read_unlock(&its->dev->kvm->srcu, idx);
arch/arm64/kvm/vgic/vgic-its.c:1072:	    lpi_nr >= max_lpis_propbaser(kvm->arch.vgic.propbaser))
arch/arm64/kvm/vgic/vgic-its.c:1224:	if (target_addr >= atomic_read(&kvm->online_vcpus))
arch/arm64/kvm/vgic/vgic-its.c:1356:	if (target1_addr >= atomic_read(&kvm->online_vcpus) ||
arch/arm64/kvm/vgic/vgic-its.c:1357:	    target2_addr >= atomic_read(&kvm->online_vcpus))
arch/arm64/kvm/vgic/vgic-its.c:1810:	mutex_lock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-its.c:1827:	mutex_unlock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-its.c:1837:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-its.c:1844:	sz = atomic_read(&kvm->online_vcpus) * LPI_DEFAULT_PCPU_CACHE_SIZE;
arch/arm64/kvm/vgic/vgic-its.c:1861:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-its.c:1913:	dev->kvm->arch.vgic.msis_require_devid = true;
arch/arm64/kvm/vgic/vgic-its.c:1914:	dev->kvm->arch.vgic.has_its = true;
arch/arm64/kvm/vgic/vgic-its.c:1922:	dev->kvm->arch.vgic.propbaser = INITIAL_PROPBASER_VALUE;
arch/arm64/kvm/vgic/vgic-its.c:1993:	mutex_lock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-its.c:2028:	mutex_unlock(&dev->kvm->lock);
arch/arm64/kvm/vgic/vgic-its.c:2484:	    target_addr >= atomic_read(&kvm->online_vcpus))
arch/arm64/kvm/vgic/vgic-its.c:2668:	mutex_lock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-its.c:2673:		mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-its.c:2691:	mutex_unlock(&kvm->lock);
arch/arm64/kvm/vgic/vgic-its.c:2770:	.name = "kvm-arm-vgic-its",
arch/arm64/kvm/vgic/vgic-mmio-v2.c:28:	struct vgic_dist *vgic = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v2.c:38:		value |= (atomic_read(&vcpu->kvm->online_vcpus) - 1) << 5;
arch/arm64/kvm/vgic/vgic-mmio-v2.c:56:	struct vgic_dist *dist = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v2.c:90:		vcpu->kvm->arch.vgic.v2_groups_user_writable = true;
arch/arm64/kvm/vgic/vgic-mmio-v2.c:102:	if (vcpu->kvm->arch.vgic.v2_groups_user_writable)
arch/arm64/kvm/vgic/vgic-mmio-v2.c:112:	int nr_vcpus = atomic_read(&source_vcpu->kvm->online_vcpus);
arch/arm64/kvm/vgic/vgic-mmio-v2.c:174:	u8 cpu_mask = GENMASK(atomic_read(&vcpu->kvm->online_vcpus) - 1, 0);
arch/arm64/kvm/vgic/vgic-mmio-v3.c:43:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:67:	struct vgic_dist *vgic = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:108:	struct vgic_dist *dist = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:114:		mutex_lock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio-v3.c:142:		mutex_unlock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio-v3.c:157:	struct vgic_dist *dist = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:256:	struct vgic_dist *vgic = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:471:	struct vgic_dist *dist = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:480:	struct vgic_dist *dist = &vcpu->kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:700:	struct vgic_dist *vgic = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio-v3.c:735:	mutex_lock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-mmio-v3.c:738:	mutex_unlock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-mmio-v3.c:767:		mutex_lock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-mmio-v3.c:772:		mutex_unlock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-mmio-v3.c:796:	struct vgic_dist *d = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-mmio.c:267:		vcpu->kvm->arch.vgic.vgic_model == KVM_DEV_TYPE_ARM_VGIC_V2);
arch/arm64/kvm/vgic/vgic-mmio.c:453:	if (vcpu->kvm->arch.vgic.vgic_model == KVM_DEV_TYPE_ARM_VGIC_V3 ||
arch/arm64/kvm/vgic/vgic-mmio.c:461:	if (vcpu->kvm->arch.vgic.vgic_model == KVM_DEV_TYPE_ARM_VGIC_V3 ||
arch/arm64/kvm/vgic/vgic-mmio.c:496:	mutex_lock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio.c:502:	mutex_unlock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio.c:542:		u32 model = vcpu->kvm->arch.vgic.vgic_model;
arch/arm64/kvm/vgic/vgic-mmio.c:591:	mutex_lock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio.c:597:	mutex_unlock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio.c:628:	mutex_lock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio.c:634:	mutex_unlock(&vcpu->kvm->lock);
arch/arm64/kvm/vgic/vgic-mmio.c:748:	int nr_irqs = vcpu->kvm->arch.vgic.nr_spis + VGIC_NR_PRIVATE_IRQS;
arch/arm64/kvm/vgic/vgic-mmio.c:770:	int nr_irqs = vcpu->kvm->arch.vgic.nr_spis + VGIC_NR_PRIVATE_IRQS;
arch/arm64/kvm/vgic/vgic-mmio.c:900:	int flags, nr_irqs = kvm->arch.vgic.nr_spis + VGIC_NR_PRIVATE_IRQS;
arch/arm64/kvm/vgic/vgic-mmio.c:1061:	struct vgic_io_device *io_device = &kvm->arch.vgic.dist_iodev;
arch/arm64/kvm/vgic/vgic-mmio.c:1080:	mutex_lock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-mmio.c:1083:	mutex_unlock(&kvm->slots_lock);
arch/arm64/kvm/vgic/vgic-v2.c:306:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-v3.c:37:	u32 model = vcpu->kvm->arch.vgic.vgic_model;
arch/arm64/kvm/vgic/vgic-v3.c:122:	u32 model = vcpu->kvm->arch.vgic.vgic_model;
arch/arm64/kvm/vgic/vgic-v3.c:210:	u32 model = vcpu->kvm->arch.vgic.vgic_model;
arch/arm64/kvm/vgic/vgic-v3.c:240:	u32 model = vcpu->kvm->arch.vgic.vgic_model;
arch/arm64/kvm/vgic/vgic-v3.c:290:	if (vcpu->kvm->arch.vgic.vgic_model == KVM_DEV_TYPE_ARM_VGIC_V3) {
arch/arm64/kvm/vgic/vgic-v3.c:393:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-v3.c:476:	struct vgic_dist *d = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-v3.c:493:	struct vgic_dist *d = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-v3.c:539:	struct list_head *rd_regions = &kvm->arch.vgic.rd_regions;
arch/arm64/kvm/vgic/vgic-v3.c:552:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-v3.c:602:early_param("kvm-arm.vgic_v3_group0_trap", early_group0_trap_cfg);
arch/arm64/kvm/vgic/vgic-v3.c:608:early_param("kvm-arm.vgic_v3_group1_trap", early_group1_trap_cfg);
arch/arm64/kvm/vgic/vgic-v3.c:614:early_param("kvm-arm.vgic_v3_common_trap", early_common_trap_cfg);
arch/arm64/kvm/vgic/vgic-v3.c:620:early_param("kvm-arm.vgic_v4_enable", early_gicv4_enable);
arch/arm64/kvm/vgic/vgic-v4.c:190:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-v4.c:230: * vgic is initialized. This relies on kvm->lock to be
arch/arm64/kvm/vgic/vgic-v4.c:236:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic-v4.c:246:	nr_vcpus = atomic_read(&kvm->online_vcpus);
arch/arm64/kvm/vgic/vgic-v4.c:308: * Relies on kvm->lock to be held.
arch/arm64/kvm/vgic/vgic-v4.c:312:	struct its_vm *its_vm = &kvm->arch.vgic.its_vm;
arch/arm64/kvm/vgic/vgic-v4.c:360:	err = its_make_vpe_resident(vpe, false, vcpu->kvm->arch.vgic.enabled);
arch/arm64/kvm/vgic/vgic-v4.c:436:		.vm		= &kvm->arch.vgic.its_vm,
arch/arm64/kvm/vgic/vgic.c:26: * kvm->lock (mutex)
arch/arm64/kvm/vgic/vgic.c:30: *         kvm->lpi_list_lock		must be taken with IRQs disabled
arch/arm64/kvm/vgic/vgic.c:60:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic.c:100:	if (intid < (kvm->arch.vgic.nr_spis + VGIC_NR_PRIVATE_IRQS)) {
arch/arm64/kvm/vgic/vgic.c:101:		intid = array_index_nospec(intid, kvm->arch.vgic.nr_spis + VGIC_NR_PRIVATE_IRQS);
arch/arm64/kvm/vgic/vgic.c:102:		return &kvm->arch.vgic.spis[intid - VGIC_NR_PRIVATE_IRQS];
arch/arm64/kvm/vgic/vgic.c:127:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic.c:140:	struct vgic_dist *dist = &kvm->arch.vgic;
arch/arm64/kvm/vgic/vgic.c:231:			     !irq->target_vcpu->kvm->arch.vgic.enabled))
arch/arm64/kvm/vgic/vgic.c:965:	if (!vcpu->kvm->arch.vgic.enabled)
arch/arm64/kvm/vgic/vgic.h:289:		return atomic_read(&kvm->online_vcpus) * KVM_VGIC_V3_REDIST_SIZE;
arch/arm64/kvm/vgic/vgic.h:302:	struct vgic_dist *d = &kvm->arch.vgic;
arch/mips/kvm/Makefile:11:kvm-objs := $(common-objs-y) mips.o emulate.o entry.o \
arch/mips/kvm/Makefile:14:kvm-objs += hypcall.o
arch/mips/kvm/Makefile:15:kvm-objs += mmu.o
arch/mips/kvm/Makefile:17:kvm-objs += loongson_ipi.o
arch/mips/kvm/Makefile:20:kvm-objs		+= vz.o
arch/mips/kvm/loongson_ipi.c:123:		kvm_vcpu_ioctl_interrupt(kvm->vcpus[id], &irq);
arch/mips/kvm/loongson_ipi.c:131:			kvm_vcpu_ioctl_interrupt(kvm->vcpus[id], &irq);
arch/mips/kvm/loongson_ipi.c:197:	s = &kvm->arch.ipi;
arch/mips/kvm/loongson_ipi.c:208:		mutex_lock(&kvm->slots_lock);
arch/mips/kvm/loongson_ipi.c:210:		mutex_unlock(&kvm->slots_lock);
arch/mips/kvm/mmu.c:142:/* Caller must hold kvm->mm_lock */
arch/mips/kvm/mmu.c:147:	return kvm_mips_walk_pgd(kvm->arch.gpa_mm.pgd, cache, addr);
arch/mips/kvm/mmu.c:266: * The caller must hold the @kvm->mmu_lock spinlock.
arch/mips/kvm/mmu.c:273:	return kvm_mips_flush_gpa_pgd(kvm->arch.gpa_mm.pgd,
arch/mips/kvm/mmu.c:391: * The caller must hold the @kvm->mmu_lock spinlock.
arch/mips/kvm/mmu.c:399:	return kvm_mips_mkclean_pgd(kvm->arch.gpa_mm.pgd,
arch/mips/kvm/mmu.c:413: * acquire @kvm->mmu_lock.
arch/mips/kvm/mmu.c:437:	return kvm_mips_mkold_pgd(kvm->arch.gpa_mm.pgd,
arch/mips/kvm/mmu.c:522:	spin_lock(&kvm->mmu_lock);
arch/mips/kvm/mmu.c:557:	spin_unlock(&kvm->mmu_lock);
arch/mips/kvm/mmu.c:602:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/mips/kvm/mmu.c:618:	mmu_seq = kvm->mmu_notifier_seq;
arch/mips/kvm/mmu.c:639:	spin_lock(&kvm->mmu_lock);
arch/mips/kvm/mmu.c:647:		spin_unlock(&kvm->mmu_lock);
arch/mips/kvm/mmu.c:677:	spin_unlock(&kvm->mmu_lock);
arch/mips/kvm/mmu.c:681:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/mips/kvm/mips.c:147:	kvm->arch.gpa_mm.pgd = kvm_pgd_alloc();
arch/mips/kvm/mips.c:148:	if (!kvm->arch.gpa_mm.pgd)
arch/mips/kvm/mips.c:167:	mutex_lock(&kvm->lock);
arch/mips/kvm/mips.c:169:	for (i = 0; i < atomic_read(&kvm->online_vcpus); i++)
arch/mips/kvm/mips.c:170:		kvm->vcpus[i] = NULL;
arch/mips/kvm/mips.c:172:	atomic_set(&kvm->online_vcpus, 0);
arch/mips/kvm/mips.c:174:	mutex_unlock(&kvm->lock);
arch/mips/kvm/mips.c:181:	pgd_free(NULL, kvm->arch.gpa_mm.pgd);
arch/mips/kvm/mips.c:211:	spin_lock(&kvm->mmu_lock);
arch/mips/kvm/mips.c:216:	spin_unlock(&kvm->mmu_lock);
arch/mips/kvm/mips.c:251:		spin_lock(&kvm->mmu_lock);
arch/mips/kvm/mips.c:257:		spin_unlock(&kvm->mmu_lock);
arch/mips/kvm/mips.c:485:		dvcpu = vcpu->kvm->vcpus[irq->cpu];
arch/mips/kvm/tlb.c:42:	struct mm_struct *gpa_mm = &vcpu->kvm->arch.gpa_mm;
arch/mips/kvm/vz.c:2500:	struct mm_struct *gpa_mm = &kvm->arch.gpa_mm;
arch/mips/kvm/vz.c:2551:		if (cpumask_test_and_clear_cpu(cpu, &kvm->arch.asid_flush_mask))
arch/mips/kvm/vz.c:2694:	if (vcpu->kvm->created_vcpus > 1)
arch/mips/kvm/vz.c:3225:		cpumask_setall(&kvm->arch.asid_flush_mask);
arch/powerpc/include/asm/kvm_book3s.h:468:	int stride = kvm->arch.emul_smt_mode;
arch/powerpc/include/asm/kvm_book3s_64.h:141:	return kvm->arch.radix;
arch/powerpc/include/asm/kvm_book3s_64.h:527:	if (atomic_read(&kvm->arch.hpte_mod_interest))
arch/powerpc/include/asm/kvm_book3s_64.h:539:	return rcu_dereference_raw_check(kvm->memslots[0]);
arch/powerpc/include/asm/kvm_book3s_64.h:644:	pte = __find_linux_pte(kvm->arch.pgtable, ea, NULL, hshift);
arch/powerpc/include/asm/kvm_book3s_64.h:653:	VM_WARN(!spin_is_locked(&kvm->mmu_lock),
arch/powerpc/include/asm/kvm_book3s_64.h:655:	pte = __find_linux_pte(kvm->arch.pgtable, ea, NULL, hshift);
arch/powerpc/include/asm/kvm_book3s_64.h:665:	VM_WARN(!spin_is_locked(&kvm->mmu_lock),
arch/powerpc/include/asm/kvm_book3s_64.h:671:	pte = __find_linux_pte(kvm->mm->pgd, ea, NULL, hshift);
arch/powerpc/include/asm/kvm_host.h:307:	struct kvm_resize_hpt *resize_hpt; /* protected by kvm->lock */
arch/powerpc/include/asm/kvm_ppc.h:348:	return kvm->arch.kvm_ops == kvmppc_hv_ops;
arch/powerpc/include/asm/kvm_ppc.h:547:	vcpu->kvm->arch.kvm_ops->fast_vcpu_kick(vcpu);
arch/powerpc/include/asm/kvm_ppc.h:599:		return kvm->arch.pimap;
arch/powerpc/kernel/exceptions-64s.S:1169:	 * machine_check_kvm->kvmppc_interrupt branch to deliver the MC event
arch/powerpc/kvm/Makefile:19:kvm-e500-objs := \
arch/powerpc/kvm/Makefile:29:kvm-objs-$(CONFIG_KVM_E500V2) := $(kvm-e500-objs)
arch/powerpc/kvm/Makefile:31:kvm-e500mc-objs := \
arch/powerpc/kvm/Makefile:41:kvm-objs-$(CONFIG_KVM_E500MC) := $(kvm-e500mc-objs)
arch/powerpc/kvm/Makefile:43:kvm-book3s_64-builtin-objs-$(CONFIG_SPAPR_TCE_IOMMU) := \
arch/powerpc/kvm/Makefile:46:kvm-pr-y := \
arch/powerpc/kvm/Makefile:59:kvm-book3s_64-builtin-objs-$(CONFIG_KVM_BOOK3S_64_HANDLER) += \
arch/powerpc/kvm/Makefile:63:kvm-book3s_64-builtin-objs-$(CONFIG_KVM_BOOK3S_64_HANDLER) += \
arch/powerpc/kvm/Makefile:67:kvm-hv-y += \
arch/powerpc/kvm/Makefile:74:kvm-hv-$(CONFIG_PPC_UV) += \
arch/powerpc/kvm/Makefile:77:kvm-hv-$(CONFIG_PPC_TRANSACTIONAL_MEM) += \
arch/powerpc/kvm/Makefile:80:kvm-book3s_64-builtin-xics-objs-$(CONFIG_KVM_XICS) := \
arch/powerpc/kvm/Makefile:83:kvm-book3s_64-builtin-tm-objs-$(CONFIG_PPC_TRANSACTIONAL_MEM) += \
arch/powerpc/kvm/Makefile:87:kvm-book3s_64-builtin-objs-$(CONFIG_KVM_BOOK3S_64_HANDLER) += \
arch/powerpc/kvm/Makefile:93:	$(kvm-book3s_64-builtin-tm-objs-y) \
arch/powerpc/kvm/Makefile:94:	$(kvm-book3s_64-builtin-xics-objs-y)
arch/powerpc/kvm/Makefile:97:kvm-book3s_64-objs-$(CONFIG_KVM_XICS) += \
arch/powerpc/kvm/Makefile:100:kvm-book3s_64-objs-$(CONFIG_KVM_XIVE) += book3s_xive.o book3s_xive_native.o
arch/powerpc/kvm/Makefile:101:kvm-book3s_64-objs-$(CONFIG_SPAPR_TCE_IOMMU) += book3s_64_vio.o
arch/powerpc/kvm/Makefile:103:kvm-book3s_64-module-objs := \
arch/powerpc/kvm/Makefile:107:	$(kvm-book3s_64-objs-y)
arch/powerpc/kvm/Makefile:109:kvm-objs-$(CONFIG_KVM_BOOK3S_64) := $(kvm-book3s_64-module-objs)
arch/powerpc/kvm/Makefile:111:kvm-book3s_32-objs := \
arch/powerpc/kvm/Makefile:123:kvm-objs-$(CONFIG_KVM_BOOK3S_32) := $(kvm-book3s_32-objs)
arch/powerpc/kvm/Makefile:125:kvm-objs-$(CONFIG_KVM_MPIC) += mpic.o
arch/powerpc/kvm/Makefile:126:kvm-objs-$(CONFIG_HAVE_KVM_IRQ_ROUTING) += $(KVM)/irqchip.o
arch/powerpc/kvm/Makefile:128:kvm-objs := $(kvm-objs-m) $(kvm-objs-y)
arch/powerpc/kvm/Makefile:135:obj-$(CONFIG_KVM_BOOK3S_64_PR) += kvm-pr.o
arch/powerpc/kvm/Makefile:136:obj-$(CONFIG_KVM_BOOK3S_64_HV) += kvm-hv.o
arch/powerpc/kvm/Makefile:138:obj-y += $(kvm-book3s_64-builtin-objs-y)
arch/powerpc/kvm/book3s.c:113:	vcpu->kvm->arch.kvm_ops->inject_interrupt(vcpu, vec, flags);
arch/powerpc/kvm/book3s.c:486:	ret = vcpu->kvm->arch.kvm_ops->get_sregs(vcpu, sregs);
arch/powerpc/kvm/book3s.c:498:	ret = vcpu->kvm->arch.kvm_ops->set_sregs(vcpu, sregs);
arch/powerpc/kvm/book3s.c:575:	r = vcpu->kvm->arch.kvm_ops->get_one_reg(vcpu, id, val);
arch/powerpc/kvm/book3s.c:663:	r = vcpu->kvm->arch.kvm_ops->set_one_reg(vcpu, id, val);
arch/powerpc/kvm/book3s.c:744:	vcpu->kvm->arch.kvm_ops->vcpu_load(vcpu, cpu);
arch/powerpc/kvm/book3s.c:749:	vcpu->kvm->arch.kvm_ops->vcpu_put(vcpu);
arch/powerpc/kvm/book3s.c:754:	vcpu->kvm->arch.kvm_ops->set_msr(vcpu, msr);
arch/powerpc/kvm/book3s.c:760:	return vcpu->kvm->arch.kvm_ops->vcpu_run(vcpu);
arch/powerpc/kvm/book3s.c:786:	return vcpu->kvm->arch.kvm_ops->vcpu_create(vcpu);
arch/powerpc/kvm/book3s.c:791:	vcpu->kvm->arch.kvm_ops->vcpu_free(vcpu);
arch/powerpc/kvm/book3s.c:796:	return vcpu->kvm->arch.kvm_ops->check_requests(vcpu);
arch/powerpc/kvm/book3s.c:806:	return kvm->arch.kvm_ops->get_dirty_log(kvm, log);
arch/powerpc/kvm/book3s.c:811:	kvm->arch.kvm_ops->free_memslot(slot);
arch/powerpc/kvm/book3s.c:816:	kvm->arch.kvm_ops->flush_memslot(kvm, memslot);
arch/powerpc/kvm/book3s.c:824:	return kvm->arch.kvm_ops->prepare_memory_region(kvm, memslot, mem,
arch/powerpc/kvm/book3s.c:834:	kvm->arch.kvm_ops->commit_memory_region(kvm, mem, old, new, change);
arch/powerpc/kvm/book3s.c:839:	return kvm->arch.kvm_ops->unmap_gfn_range(kvm, range);
arch/powerpc/kvm/book3s.c:844:	return kvm->arch.kvm_ops->age_gfn(kvm, range);
arch/powerpc/kvm/book3s.c:849:	return kvm->arch.kvm_ops->test_age_gfn(kvm, range);
arch/powerpc/kvm/book3s.c:854:	return kvm->arch.kvm_ops->set_spte_gfn(kvm, range);
arch/powerpc/kvm/book3s.c:861:	INIT_LIST_HEAD_RCU(&kvm->arch.spapr_tce_tables);
arch/powerpc/kvm/book3s.c:862:	INIT_LIST_HEAD(&kvm->arch.rtas_tokens);
arch/powerpc/kvm/book3s.c:863:	mutex_init(&kvm->arch.rtas_token_lock);
arch/powerpc/kvm/book3s.c:866:	return kvm->arch.kvm_ops->init_vm(kvm);
arch/powerpc/kvm/book3s.c:871:	kvm->arch.kvm_ops->destroy_vm(kvm);
arch/powerpc/kvm/book3s.c:875:	WARN_ON(!list_empty(&kvm->arch.spapr_tce_tables));
arch/powerpc/kvm/book3s.c:883:	kfree(kvm->arch.xive_devices.native);
arch/powerpc/kvm/book3s.c:884:	kvm->arch.xive_devices.native = NULL;
arch/powerpc/kvm/book3s.c:885:	kfree(kvm->arch.xive_devices.xics_on_xive);
arch/powerpc/kvm/book3s.c:886:	kvm->arch.xive_devices.xics_on_xive = NULL;
arch/powerpc/kvm/book3s.c:887:	kfree(kvm->arch.xics_device);
arch/powerpc/kvm/book3s.c:888:	kvm->arch.xics_device = NULL;
arch/powerpc/kvm/book3s.c:903:	srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s.c:905:	srcu_read_unlock(&vcpu->kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s.c:964:	srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s.c:966:	srcu_read_unlock(&vcpu->kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s.c:986:	return kvm->arch.kvm_ops->hcall_implemented(hcall);
arch/powerpc/kvm/book3s_64_mmu_host.c:93:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_64_mmu_host.c:153:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_host.c:205:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu.c:244:	mutex_lock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_64_mmu.c:349:	mutex_unlock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_64_mmu.c:356:	mutex_unlock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_64_mmu_radix.c:88:	int lpid = vcpu->kvm->arch.lpid;
arch/powerpc/kvm/book3s_64_mmu_radix.c:164:		vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_radix.c:166:		srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/book3s_64_mmu_radix.c:242:	vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_radix.c:244:	srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/book3s_64_mmu_radix.c:274:				vcpu->kvm->arch.process_table, pid, &pte);
arch/powerpc/kvm/book3s_64_mmu_radix.c:353:	radix__set_pte_at(kvm->mm, addr, ptep, pte, 0);
arch/powerpc/kvm/book3s_64_mmu_radix.c:391:/* Called with kvm->mmu_lock held */
arch/powerpc/kvm/book3s_64_mmu_radix.c:407:	if (lpid != kvm->arch.lpid)
arch/powerpc/kvm/book3s_64_mmu_radix.c:418:			kvm->stat.num_2M_pages--;
arch/powerpc/kvm/book3s_64_mmu_radix.c:420:			kvm->stat.num_1G_pages--;
arch/powerpc/kvm/book3s_64_mmu_radix.c:514:	pud_free(kvm->mm, pud);
arch/powerpc/kvm/book3s_64_mmu_radix.c:535:	if (kvm->arch.pgtable) {
arch/powerpc/kvm/book3s_64_mmu_radix.c:536:		kvmppc_free_pgtable_radix(kvm, kvm->arch.pgtable,
arch/powerpc/kvm/book3s_64_mmu_radix.c:537:					  kvm->arch.lpid);
arch/powerpc/kvm/book3s_64_mmu_radix.c:538:		pgd_free(kvm->mm, kvm->arch.pgtable);
arch/powerpc/kvm/book3s_64_mmu_radix.c:539:		kvm->arch.pgtable = NULL;
arch/powerpc/kvm/book3s_64_mmu_radix.c:604:		new_pud = pud_alloc_one(kvm->mm, gpa);
arch/powerpc/kvm/book3s_64_mmu_radix.c:616:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:626:		p4d_populate(kvm->mm, p4d, new_pud);
arch/powerpc/kvm/book3s_64_mmu_radix.c:677:		pud_populate(kvm->mm, pud, new_pmd);
arch/powerpc/kvm/book3s_64_mmu_radix.c:729:		pmd_populate(kvm->mm, pmd, new_ptep);
arch/powerpc/kvm/book3s_64_mmu_radix.c:752:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:754:		pud_free(kvm->mm, new_pud);
arch/powerpc/kvm/book3s_64_mmu_radix.c:808:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_64_mmu_radix.c:840:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:845:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:890:	ret = kvmppc_create_pte(kvm, kvm->arch.pgtable, pte, gpa, level,
arch/powerpc/kvm/book3s_64_mmu_radix.c:891:				mmu_seq, kvm->arch.lpid, NULL, NULL);
arch/powerpc/kvm/book3s_64_mmu_radix.c:906:			kvm->stat.num_2M_pages++;
arch/powerpc/kvm/book3s_64_mmu_radix.c:908:			kvm->stat.num_1G_pages++;
arch/powerpc/kvm/book3s_64_mmu_radix.c:943:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE)
arch/powerpc/kvm/book3s_64_mmu_radix.c:975:		spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:977:					    gpa, kvm->arch.lpid))
arch/powerpc/kvm/book3s_64_mmu_radix.c:979:		spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:995:/* Called with kvm->mmu_lock held */
arch/powerpc/kvm/book3s_64_mmu_radix.c:1003:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE) {
arch/powerpc/kvm/book3s_64_mmu_radix.c:1004:		uv_page_inval(kvm->arch.lpid, gpa, PAGE_SHIFT);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1011:				 kvm->arch.lpid);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1014:/* Called with kvm->mmu_lock held */
arch/powerpc/kvm/book3s_64_mmu_radix.c:1024:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE)
arch/powerpc/kvm/book3s_64_mmu_radix.c:1042:/* Called with kvm->mmu_lock held */
arch/powerpc/kvm/book3s_64_mmu_radix.c:1052:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE)
arch/powerpc/kvm/book3s_64_mmu_radix.c:1072:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE)
arch/powerpc/kvm/book3s_64_mmu_radix.c:1076:	 * For performance reasons we don't hold kvm->mmu_lock while walking the
arch/powerpc/kvm/book3s_64_mmu_radix.c:1085:		spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1097:				spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1106:		kvmppc_radix_tlbie_page(kvm, gpa, shift, kvm->arch.lpid);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1112:		spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1150:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START)
arch/powerpc/kvm/book3s_64_mmu_radix.c:1153:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE)
arch/powerpc/kvm/book3s_64_mmu_radix.c:1157:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1162:					 kvm->arch.lpid);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1169:	kvm->mmu_notifier_seq++;
arch/powerpc/kvm/book3s_64_mmu_radix.c:1170:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1212:	kvm->arch.pgtable = pgd_alloc(kvm->mm);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1213:	if (!kvm->arch.pgtable)
arch/powerpc/kvm/book3s_64_mmu_radix.c:1327:				pgt = kvm->arch.pgtable;
arch/powerpc/kvm/book3s_64_mmu_radix.c:1434:	debugfs_create_file("radix", 0400, kvm->arch.debugfs_dir, kvm,
arch/powerpc/kvm/book3s_64_mmu_radix.c:1442:	kvm_pte_cache = kmem_cache_create("kvm-pte", size, size, 0, pte_ctor);
arch/powerpc/kvm/book3s_64_mmu_radix.c:1448:	kvm_pmd_cache = kmem_cache_create("kvm-pmd", size, size, 0, pmd_ctor);
arch/powerpc/kvm/book3s_64_vio.c:77:	list_for_each_entry_rcu(stt, &kvm->arch.spapr_tce_tables, list) {
arch/powerpc/kvm/book3s_64_vio.c:112:	list_for_each_entry_rcu(stt, &kvm->arch.spapr_tce_tables, list) {
arch/powerpc/kvm/book3s_64_vio.c:252:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/book3s_64_vio.c:254:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_64_vio.c:264:	account_locked_vm(kvm->mm,
arch/powerpc/kvm/book3s_64_vio.c:284:	struct mm_struct *mm = kvm->mm;
arch/powerpc/kvm/book3s_64_vio.c:311:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/book3s_64_vio.c:315:	list_for_each_entry(siter, &kvm->arch.spapr_tce_tables, list) {
arch/powerpc/kvm/book3s_64_vio.c:324:		ret = anon_inode_getfd("kvm-spapr-tce", &kvm_spapr_tce_fops,
arch/powerpc/kvm/book3s_64_vio.c:328:		list_add_rcu(&stt->list, &kvm->arch.spapr_tce_tables);
arch/powerpc/kvm/book3s_64_vio.c:332:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_64_vio.c:383:		mem = mm_iommu_lookup(stt->kvm->mm, ua, 1ULL << shift);
arch/powerpc/kvm/book3s_64_vio.c:443:	mem = mm_iommu_lookup(kvm->mm, be64_to_cpu(*pua), pgsize);
arch/powerpc/kvm/book3s_64_vio.c:461:	if (WARN_ON_ONCE(iommu_tce_xchg_no_kill(kvm->mm, tbl, entry, &hpa,
arch/powerpc/kvm/book3s_64_vio.c:470:		iommu_tce_xchg_no_kill(kvm->mm, tbl, entry, &hpa, &dir);
arch/powerpc/kvm/book3s_64_vio.c:505:	mem = mm_iommu_lookup(kvm->mm, ua, 1ULL << tbl->it_page_shift);
arch/powerpc/kvm/book3s_64_vio.c:516:	ret = iommu_tce_xchg_no_kill(kvm->mm, tbl, entry, &hpa, &dir);
arch/powerpc/kvm/book3s_64_vio.c:571:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_64_vio.c:597:			kvmppc_clear_tce(vcpu->kvm->mm, stit->tbl, entry);
arch/powerpc/kvm/book3s_64_vio.c:605:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/book3s_64_vio.c:641:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_64_vio.c:688:				kvmppc_clear_tce(vcpu->kvm->mm, stit->tbl,
arch/powerpc/kvm/book3s_64_vio.c:702:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/book3s_64_vio.c:742:			kvmppc_clear_tce(vcpu->kvm->mm, stit->tbl, entry);
arch/powerpc/kvm/book3s_64_mmu_hv.c:56:	/* These fields protected by kvm->arch.mmu_setup_lock */
arch/powerpc/kvm/book3s_64_mmu_hv.c:66:	 * then protected by kvm->arch.mmu_setup_lock.
arch/powerpc/kvm/book3s_64_mmu_hv.c:119:	atomic64_set(&kvm->arch.mmio_update, 0);
arch/powerpc/kvm/book3s_64_mmu_hv.c:120:	kvm->arch.hpt = *info;
arch/powerpc/kvm/book3s_64_mmu_hv.c:121:	kvm->arch.sdr1 = __pa(info->virt) | (info->order - 18);
arch/powerpc/kvm/book3s_64_mmu_hv.c:124:		 info->virt, (long)info->order, kvm->arch.lpid);
arch/powerpc/kvm/book3s_64_mmu_hv.c:132:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:133:	if (kvm->arch.mmu_ready) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:134:		kvm->arch.mmu_ready = 0;
arch/powerpc/kvm/book3s_64_mmu_hv.c:137:		if (atomic_read(&kvm->arch.vcpus_running)) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:138:			kvm->arch.mmu_ready = 1;
arch/powerpc/kvm/book3s_64_mmu_hv.c:148:	if (kvm->arch.hpt.order == order) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:152:		memset((void *)kvm->arch.hpt.virt, 0, 1ul << order);
arch/powerpc/kvm/book3s_64_mmu_hv.c:161:	if (kvm->arch.hpt.virt) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:162:		kvmppc_free_hpt(&kvm->arch.hpt);
arch/powerpc/kvm/book3s_64_mmu_hv.c:174:		cpumask_setall(&kvm->arch.need_tlb_flush);
arch/powerpc/kvm/book3s_64_mmu_hv.c:176:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:225:	if (npages > kvmppc_hpt_mask(&kvm->arch.hpt) + 1)
arch/powerpc/kvm/book3s_64_mmu_hv.c:226:		npages = kvmppc_hpt_mask(&kvm->arch.hpt) + 1;
arch/powerpc/kvm/book3s_64_mmu_hv.c:237:			& kvmppc_hpt_mask(&kvm->arch.hpt);
arch/powerpc/kvm/book3s_64_mmu_hv.c:291:				kvm->mm->pgd, false, pte_idx_ret);
arch/powerpc/kvm/book3s_64_mmu_hv.c:355:		slb_v = vcpu->kvm->arch.vrma_slb_v;
arch/powerpc/kvm/book3s_64_mmu_hv.c:366:	hptep = (__be64 *)(kvm->arch.hpt.virt + (index << 4));
arch/powerpc/kvm/book3s_64_mmu_hv.c:370:	gr = kvm->arch.hpt.rev[index].guest_rpte;
arch/powerpc/kvm/book3s_64_mmu_hv.c:433:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_hv.c:436:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/book3s_64_mmu_hv.c:518:		mmio_update = atomic64_read(&kvm->arch.mmio_update);
arch/powerpc/kvm/book3s_64_mmu_hv.c:531:	hptep = (__be64 *)(kvm->arch.hpt.virt + (index << 4));
arch/powerpc/kvm/book3s_64_mmu_hv.c:532:	rev = &kvm->arch.hpt.rev[index];
arch/powerpc/kvm/book3s_64_mmu_hv.c:573:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_64_mmu_hv.c:609:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:614:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:673:	if (!kvm->arch.mmu_ready)
arch/powerpc/kvm/book3s_64_mmu_hv.c:739:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_hv.c:743:		spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:750:		spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:752:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_64_mmu_hv.c:760:	__be64 *hptep = (__be64 *) (kvm->arch.hpt.virt + (i << 4));
arch/powerpc/kvm/book3s_64_mmu_hv.c:761:	struct revmap_entry *rev = kvm->arch.hpt.rev;
arch/powerpc/kvm/book3s_64_mmu_hv.c:819:		hptep = (__be64 *) (kvm->arch.hpt.virt + (i << 4));
arch/powerpc/kvm/book3s_64_mmu_hv.c:879:	struct revmap_entry *rev = kvm->arch.hpt.rev;
arch/powerpc/kvm/book3s_64_mmu_hv.c:899:		hptep = (__be64 *) (kvm->arch.hpt.virt + (i << 4));
arch/powerpc/kvm/book3s_64_mmu_hv.c:950:	struct revmap_entry *rev = kvm->arch.hpt.rev;
arch/powerpc/kvm/book3s_64_mmu_hv.c:967:			hp = (unsigned long *)(kvm->arch.hpt.virt + (i << 4));
arch/powerpc/kvm/book3s_64_mmu_hv.c:1004:	return atomic_read(&kvm->arch.vcpus_running) != 0;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1013:	struct revmap_entry *rev = kvm->arch.hpt.rev;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1030:		hptep = (__be64 *) (kvm->arch.hpt.virt + (i << 4));
arch/powerpc/kvm/book3s_64_mmu_hv.c:1143:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1152:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1160:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1179:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1183:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1207:	struct kvm_hpt_info *old = &kvm->arch.hpt;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1254:		int srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1267:		srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1364:	for (i = 0; i < kvmppc_hpt_npte(&kvm->arch.hpt); i++) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:1383:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1386:	hpt_tmp = kvm->arch.hpt;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1390:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1392:	synchronize_srcu_expedited(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1402:	if (WARN_ON(!mutex_is_locked(&kvm->arch.mmu_setup_lock)))
arch/powerpc/kvm/book3s_64_mmu_hv.c:1414:	if (kvm->arch.resize_hpt == resize)
arch/powerpc/kvm/book3s_64_mmu_hv.c:1415:		kvm->arch.resize_hpt = NULL;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1429:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1432:	if (kvm->arch.resize_hpt == resize) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:1434:		 * do not sleep with kvm->arch.mmu_setup_lock held for a while.
arch/powerpc/kvm/book3s_64_mmu_hv.c:1436:		mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1449:		mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1450:		/* It is possible that kvm->arch.resize_hpt != resize
arch/powerpc/kvm/book3s_64_mmu_hv.c:1451:		 * after we grab kvm->arch.mmu_setup_lock again.
arch/powerpc/kvm/book3s_64_mmu_hv.c:1457:	if (kvm->arch.resize_hpt != resize)
arch/powerpc/kvm/book3s_64_mmu_hv.c:1460:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1477:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1479:	resize = kvm->arch.resize_hpt;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1513:	kvm->arch.resize_hpt = resize;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1520:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1543:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1545:	resize = kvm->arch.resize_hpt;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1549:	if (WARN_ON(!kvm->arch.mmu_ready))
arch/powerpc/kvm/book3s_64_mmu_hv.c:1553:	kvm->arch.mmu_ready = 0;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1576:	kvm->arch.mmu_ready = 1;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1580:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1726:	hptp = (__be64 *)(kvm->arch.hpt.virt + (i * HPTE_SIZE));
arch/powerpc/kvm/book3s_64_mmu_hv.c:1727:	revp = kvm->arch.hpt.rev + i;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1742:			while (i < kvmppc_hpt_npte(&kvm->arch.hpt) &&
arch/powerpc/kvm/book3s_64_mmu_hv.c:1752:		while (i < kvmppc_hpt_npte(&kvm->arch.hpt) &&
arch/powerpc/kvm/book3s_64_mmu_hv.c:1768:		while (i < kvmppc_hpt_npte(&kvm->arch.hpt) &&
arch/powerpc/kvm/book3s_64_mmu_hv.c:1789:		if (i >= kvmppc_hpt_npte(&kvm->arch.hpt)) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:1823:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1824:	mmu_ready = kvm->arch.mmu_ready;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1826:		kvm->arch.mmu_ready = 0;	/* temporarily */
arch/powerpc/kvm/book3s_64_mmu_hv.c:1829:		if (atomic_read(&kvm->arch.vcpus_running)) {
arch/powerpc/kvm/book3s_64_mmu_hv.c:1830:			kvm->arch.mmu_ready = 1;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1831:			mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1851:		if (i >= kvmppc_hpt_npte(&kvm->arch.hpt) ||
arch/powerpc/kvm/book3s_64_mmu_hv.c:1852:		    i + hdr.n_valid + hdr.n_invalid > kvmppc_hpt_npte(&kvm->arch.hpt))
arch/powerpc/kvm/book3s_64_mmu_hv.c:1855:		hptp = (__be64 *)(kvm->arch.hpt.virt + (i * HPTE_SIZE));
arch/powerpc/kvm/book3s_64_mmu_hv.c:1890:				kvm->arch.vrma_slb_v = senc | SLB_VSID_B_1T |
arch/powerpc/kvm/book3s_64_mmu_hv.c:1917:	kvm->arch.mmu_ready = mmu_ready;
arch/powerpc/kvm/book3s_64_mmu_hv.c:1918:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1931:		atomic_dec(&ctx->kvm->arch.hpte_mod_interest);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1963:	ret = anon_inode_getfd("kvm-htab", &kvm_htab_fops, ctx, rwflag | O_CLOEXEC);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1971:		mutex_lock(&kvm->slots_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1972:		atomic_inc(&kvm->arch.hpte_mod_interest);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1974:		synchronize_srcu_expedited(&kvm->srcu);
arch/powerpc/kvm/book3s_64_mmu_hv.c:1975:		mutex_unlock(&kvm->slots_lock);
arch/powerpc/kvm/book3s_64_mmu_hv.c:2053:	hptp = (__be64 *)(kvm->arch.hpt.virt + (i * HPTE_SIZE));
arch/powerpc/kvm/book3s_64_mmu_hv.c:2054:	for (; len != 0 && i < kvmppc_hpt_npte(&kvm->arch.hpt);
arch/powerpc/kvm/book3s_64_mmu_hv.c:2065:		gr = kvm->arch.hpt.rev[i].guest_rpte;
arch/powerpc/kvm/book3s_64_mmu_hv.c:2115:	debugfs_create_file("htab", 0400, kvm->arch.debugfs_dir, kvm,
arch/powerpc/kvm/book3s_64_vio_hv.c:68:	list_for_each_entry_lockless(stt, &kvm->arch.spapr_tce_tables, list)
arch/powerpc/kvm/book3s_64_vio_hv.c:124:		mem = mm_iommu_lookup_rm(stt->kvm->mm, ua, 1ULL << shift);
arch/powerpc/kvm/book3s_64_vio_hv.c:253:	iommu_tce_xchg_no_kill_rm(kvm->mm, tbl, entry, &hpa, &dir);
arch/powerpc/kvm/book3s_64_vio_hv.c:267:	mem = mm_iommu_lookup_rm(kvm->mm, be64_to_cpu(*pua), pgsize);
arch/powerpc/kvm/book3s_64_vio_hv.c:285:	if (iommu_tce_xchg_no_kill_rm(kvm->mm, tbl, entry, &hpa, &dir))
arch/powerpc/kvm/book3s_64_vio_hv.c:297:		iommu_tce_xchg_no_kill_rm(kvm->mm, tbl, entry, &hpa, &dir);
arch/powerpc/kvm/book3s_64_vio_hv.c:332:	mem = mm_iommu_lookup_rm(kvm->mm, ua, 1ULL << tbl->it_page_shift);
arch/powerpc/kvm/book3s_64_vio_hv.c:343:	ret = iommu_tce_xchg_no_kill_rm(kvm->mm, tbl, entry, &hpa, &dir);
arch/powerpc/kvm/book3s_64_vio_hv.c:499:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_64_vio_hv.c:521:	if (mm_iommu_preregistered(vcpu->kvm->mm)) {
arch/powerpc/kvm/book3s_64_vio_hv.c:532:		mem = mm_iommu_lookup_rm(vcpu->kvm->mm, ua, IOMMU_PAGE_SIZE_4K);
arch/powerpc/kvm/book3s_64_vio_hv.c:548:		arch_spin_lock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_64_vio_hv.c:593:		arch_spin_unlock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_builtin.c:769:		for (set = 1; set < kvm->arch.tlb_sets; ++set) {
arch/powerpc/kvm/book3s_hv_builtin.c:779:		for (set = 0; set < kvm->arch.tlb_sets; ++set) {
arch/powerpc/kvm/book3s_hv_builtin.c:808:		need_tlb_flush = &kvm->arch.need_tlb_flush;
arch/powerpc/kvm/book3s_hv_nested.c:7: * Description: KVM functions specific to running nested KVM-HV guests
arch/powerpc/kvm/book3s_hv_nested.c:300:	if (vcpu->kvm->arch.l1_ptcr == 0)
arch/powerpc/kvm/book3s_hv_nested.c:306:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_hv_nested.c:309:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/book3s_hv_nested.c:394:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_hv_nested.c:397:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/book3s_hv_nested.c:430:		pr_err("kvm-hv: failed to allocated nested partition table\n");
arch/powerpc/kvm/book3s_hv_nested.c:437:		pr_err("kvm-hv: Parent hypervisor does not support nesting (rc=%ld)\n",
arch/powerpc/kvm/book3s_hv_nested.c:500:	kvm->arch.max_nested_lpid = -1;
arch/powerpc/kvm/book3s_hv_nested.c:515:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_nested.c:523:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_nested.c:525:		kvm->arch.l1_ptcr = ptcr;
arch/powerpc/kvm/book3s_hv_nested.c:577:		vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_hv_nested.c:579:		srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/book3s_hv_nested.c:584:		vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_hv_nested.c:586:		srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/book3s_hv_nested.c:620:	ptbl_addr = (kvm->arch.l1_ptcr & PRTB_MASK) + (gp->l1_lpid << 4);
arch/powerpc/kvm/book3s_hv_nested.c:621:	if (gp->l1_lpid < (1ul << ((kvm->arch.l1_ptcr & PRTS_MASK) + 8))) {
arch/powerpc/kvm/book3s_hv_nested.c:622:		int srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_nested.c:625:		srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_nested.c:648:	gp->shadow_pgtable = pgd_alloc(kvm->mm);
arch/powerpc/kvm/book3s_hv_nested.c:662:	pgd_free(kvm->mm, gp->shadow_pgtable);
arch/powerpc/kvm/book3s_hv_nested.c:679:		 * so we don't need to hold kvm->mmu_lock.
arch/powerpc/kvm/book3s_hv_nested.c:683:		pgd_free(kvm->mm, gp->shadow_pgtable);
arch/powerpc/kvm/book3s_hv_nested.c:696:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:697:	if (gp == kvm->arch.nested_guests[lpid]) {
arch/powerpc/kvm/book3s_hv_nested.c:698:		kvm->arch.nested_guests[lpid] = NULL;
arch/powerpc/kvm/book3s_hv_nested.c:699:		if (lpid == kvm->arch.max_nested_lpid) {
arch/powerpc/kvm/book3s_hv_nested.c:700:			while (--lpid >= 0 && !kvm->arch.nested_guests[lpid])
arch/powerpc/kvm/book3s_hv_nested.c:702:			kvm->arch.max_nested_lpid = lpid;
arch/powerpc/kvm/book3s_hv_nested.c:707:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:726:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:727:	for (i = 0; i <= kvm->arch.max_nested_lpid; i++) {
arch/powerpc/kvm/book3s_hv_nested.c:728:		gp = kvm->arch.nested_guests[i];
arch/powerpc/kvm/book3s_hv_nested.c:731:		kvm->arch.nested_guests[i] = NULL;
arch/powerpc/kvm/book3s_hv_nested.c:737:	kvm->arch.max_nested_lpid = -1;
arch/powerpc/kvm/book3s_hv_nested.c:738:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:744:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_nested.c:747:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_nested.c:755:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:757:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:770:	    l1_lpid >= (1ul << ((kvm->arch.l1_ptcr & PRTS_MASK) + 12 - 4)))
arch/powerpc/kvm/book3s_hv_nested.c:773:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:774:	gp = kvm->arch.nested_guests[l1_lpid];
arch/powerpc/kvm/book3s_hv_nested.c:777:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:785:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:786:	if (kvm->arch.nested_guests[l1_lpid]) {
arch/powerpc/kvm/book3s_hv_nested.c:788:		gp = kvm->arch.nested_guests[l1_lpid];
arch/powerpc/kvm/book3s_hv_nested.c:790:		kvm->arch.nested_guests[l1_lpid] = newgp;
arch/powerpc/kvm/book3s_hv_nested.c:794:		if (l1_lpid > kvm->arch.max_nested_lpid)
arch/powerpc/kvm/book3s_hv_nested.c:795:			kvm->arch.max_nested_lpid = l1_lpid;
arch/powerpc/kvm/book3s_hv_nested.c:798:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:811:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:813:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:820:	if (lpid > kvm->arch.max_nested_lpid)
arch/powerpc/kvm/book3s_hv_nested.c:822:	return kvm->arch.nested_guests[lpid];
arch/powerpc/kvm/book3s_hv_nested.c:835:	VM_WARN(!spin_is_locked(&kvm->mmu_lock),
arch/powerpc/kvm/book3s_hv_nested.c:961:/* called with kvm->mmu_lock held */
arch/powerpc/kvm/book3s_hv_nested.c:1008:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1016:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1103:		spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1107:		spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1131:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1132:	for (i = 0; i <= kvm->arch.max_nested_lpid; i++) {
arch/powerpc/kvm/book3s_hv_nested.c:1133:		gp = kvm->arch.nested_guests[i];
arch/powerpc/kvm/book3s_hv_nested.c:1135:			spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1137:			spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1140:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1298:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1301:				      gpte.raddr, kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv_nested.c:1316:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1443:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_hv_nested.c:1448:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1454:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1529:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_nested.c:1530:	while (++lpid <= kvm->arch.max_nested_lpid) {
arch/powerpc/kvm/book3s_hv_nested.c:1531:		if (kvm->arch.nested_guests[lpid]) {
arch/powerpc/kvm/book3s_hv_nested.c:1536:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv_ras.c:85:			tlbiel_all_lpid(vcpu->kvm->arch.radix);
arch/powerpc/kvm/book3s_hv_ras.c:102:		tlbiel_all_lpid(vcpu->kvm->arch.radix);
arch/powerpc/kvm/book3s_hv_ras.c:116:	if (vcpu->kvm->arch.fwnmi_enabled) {
arch/powerpc/kvm/book3s_hv.c:134:	return kvm->arch.nested_enable && kvm_is_radix(kvm);
arch/powerpc/kvm/book3s_hv.c:437:	       vcpu->arch.vcore->lpcr, vcpu->kvm->arch.sdr1,
arch/powerpc/kvm/book3s_hv.c:796:		if (!vcpu->kvm->arch.dawr1_enabled)
arch/powerpc/kvm/book3s_hv.c:936:	    !test_bit(req/4, vcpu->kvm->arch.enabled_hcalls))
arch/powerpc/kvm/book3s_hv.c:974:		if (list_empty(&vcpu->kvm->arch.rtas_tokens))
arch/powerpc/kvm/book3s_hv.c:977:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:979:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/book3s_hv.c:1130:		 * Instead the kvm->arch.secure_guest flag is checked inside
arch/powerpc/kvm/book3s_hv.c:1221:	nthreads = vcpu->kvm->arch.emul_smt_mode;
arch/powerpc/kvm/book3s_hv.c:1260:	thr = vcpu->vcpu_id & (kvm->arch.emul_smt_mode - 1);
arch/powerpc/kvm/book3s_hv.c:1267:		if (arg >= kvm->arch.emul_smt_mode)
arch/powerpc/kvm/book3s_hv.c:1366:		if (!vcpu->kvm->arch.fwnmi_enabled) {
arch/powerpc/kvm/book3s_hv.c:1563:		srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:1565:		srcu_read_unlock(&vcpu->kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv.c:1573:		srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:1575:		srcu_read_unlock(&vcpu->kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv.c:1959:		*val = get_reg_val(id, vcpu->kvm->arch.l1_ptcr);
arch/powerpc/kvm/book3s_hv.c:2217:		vcpu->kvm->arch.l1_ptcr = set_reg_val(id, *val);
arch/powerpc/kvm/book3s_hv.c:2236:	if (kvm->arch.threads_indep)
arch/powerpc/kvm/book3s_hv.c:2254:	vcore->lpcr = kvm->arch.lpcr;
arch/powerpc/kvm/book3s_hv.c:2394:	vcpu->arch.debugfs_dir = debugfs_create_dir(buf, kvm->arch.debugfs_dir);
arch/powerpc/kvm/book3s_hv.c:2460:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:2464:		if (id >= (KVM_MAX_VCPUS * kvm->arch.emul_smt_mode)) {
arch/powerpc/kvm/book3s_hv.c:2468:			BUG_ON(kvm->arch.smt_mode != 1);
arch/powerpc/kvm/book3s_hv.c:2472:		core = id / kvm->arch.smt_mode;
arch/powerpc/kvm/book3s_hv.c:2475:		vcore = kvm->arch.vcores[core];
arch/powerpc/kvm/book3s_hv.c:2486:					id & ~(kvm->arch.smt_mode - 1));
arch/powerpc/kvm/book3s_hv.c:2487:			mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:2488:			kvm->arch.vcores[core] = vcore;
arch/powerpc/kvm/book3s_hv.c:2489:			kvm->arch.online_vcores++;
arch/powerpc/kvm/book3s_hv.c:2490:			mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:2493:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:2539:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:2541:	if (!kvm->arch.online_vcores) {
arch/powerpc/kvm/book3s_hv.c:2542:		kvm->arch.smt_mode = smt_mode;
arch/powerpc/kvm/book3s_hv.c:2543:		kvm->arch.emul_smt_mode = esmt;
arch/powerpc/kvm/book3s_hv.c:2546:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:2665:		cpumask_set_cpu(cpu, &kvm->arch.need_tlb_flush);
arch/powerpc/kvm/book3s_hv.c:2666:		cpu_in_guest = &kvm->arch.cpu_in_guest;
arch/powerpc/kvm/book3s_hv.c:2732:		cpumask_set_cpu(cpu, &kvm->arch.cpu_in_guest);
arch/powerpc/kvm/book3s_hv.c:2994:		if (!pvc->n_runnable || !pvc->kvm->arch.mmu_ready) {
arch/powerpc/kvm/book3s_hv.c:3023:		if (!vc->kvm->arch.mmu_ready)
arch/powerpc/kvm/book3s_hv.c:3401:	srcu_idx = srcu_read_lock(&vc->kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:3417:	srcu_read_unlock(&vc->kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv.c:3459:		cpumask_clear_cpu(pcpu + i, &vc->kvm->arch.cpu_in_guest);
arch/powerpc/kvm/book3s_hv.c:3509:	mtspr(SPRN_LPCR, vcpu->kvm->arch.host_lpcr | LPCR_HDICE);
arch/powerpc/kvm/book3s_hv.c:3514:		mtspr(SPRN_LPCR, vcpu->kvm->arch.host_lpcr);
arch/powerpc/kvm/book3s_hv.c:3618:	mtspr(SPRN_LPID, vcpu->kvm->arch.host_lpid);	/* restore host LPID */
arch/powerpc/kvm/book3s_hv.c:3637:	mtspr(SPRN_LPCR, vcpu->kvm->arch.host_lpcr);
arch/powerpc/kvm/book3s_hv.c:3737:			hvregs.lpid = vcpu->kvm->arch.lpid;
arch/powerpc/kvm/book3s_hv.c:4024:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:4025:	if (!kvm->arch.mmu_ready) {
arch/powerpc/kvm/book3s_hv.c:4031:			kvm->arch.mmu_ready = 1;
arch/powerpc/kvm/book3s_hv.c:4034:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:4086:		if (!vcpu->kvm->arch.mmu_ready) {
arch/powerpc/kvm/book3s_hv.c:4196:	if (!kvm->arch.mmu_ready)
arch/powerpc/kvm/book3s_hv.c:4216:	if (lazy_irq_pending() || need_resched() || !kvm->arch.mmu_ready)
arch/powerpc/kvm/book3s_hv.c:4248:		lpid = nested ? nested->shadow_lpid : kvm->arch.lpid;
arch/powerpc/kvm/book3s_hv.c:4256:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:4270:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv.c:4273:		mtspr(SPRN_LPID, kvm->arch.host_lpid);
arch/powerpc/kvm/book3s_hv.c:4285:	cpumask_clear_cpu(pcpu, &kvm->arch.cpu_in_guest);
arch/powerpc/kvm/book3s_hv.c:4402:	atomic_inc(&kvm->arch.vcpus_running);
arch/powerpc/kvm/book3s_hv.c:4418:	vcpu->arch.pgdir = kvm->mm->pgd;
arch/powerpc/kvm/book3s_hv.c:4426:		if (kvm->arch.threads_indep && kvm_is_radix(kvm) &&
arch/powerpc/kvm/book3s_hv.c:4440:			srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:4443:			srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv.c:4462:	atomic_dec(&kvm->arch.vcpus_running);
arch/powerpc/kvm/book3s_hv.c:4529:	mutex_lock(&kvm->slots_lock);
arch/powerpc/kvm/book3s_hv.c:4581:	mutex_unlock(&kvm->slots_lock);
arch/powerpc/kvm/book3s_hv.c:4623:		atomic64_inc(&kvm->arch.mmio_update);
arch/powerpc/kvm/book3s_hv.c:4644:	if (!kvm->arch.secure_guest)
arch/powerpc/kvm/book3s_hv.c:4665: * Update LPCR values in kvm->arch and in vcores.
arch/powerpc/kvm/book3s_hv.c:4666: * Caller must hold kvm->arch.mmu_setup_lock (for mutual exclusion
arch/powerpc/kvm/book3s_hv.c:4667: * of kvm->arch.lpcr update).
arch/powerpc/kvm/book3s_hv.c:4674:	if ((kvm->arch.lpcr & mask) == lpcr)
arch/powerpc/kvm/book3s_hv.c:4677:	kvm->arch.lpcr = (kvm->arch.lpcr & ~mask) | lpcr;
arch/powerpc/kvm/book3s_hv.c:4680:		struct kvmppc_vcore *vc = kvm->arch.vcores[i];
arch/powerpc/kvm/book3s_hv.c:4688:		if (++cores_done >= kvm->arch.online_vcores)
arch/powerpc/kvm/book3s_hv.c:4699:		dw0 = ((kvm->arch.vrma_slb_v & SLB_VSID_L) >> 1) |
arch/powerpc/kvm/book3s_hv.c:4700:			((kvm->arch.vrma_slb_v & SLB_VSID_LP) << 1);
arch/powerpc/kvm/book3s_hv.c:4702:		dw0 |= kvm->arch.sdr1;
arch/powerpc/kvm/book3s_hv.c:4705:		dw1 = kvm->arch.process_table;
arch/powerpc/kvm/book3s_hv.c:4708:			__pa(kvm->arch.pgtable) | RADIX_PGD_INDEX_SIZE;
arch/powerpc/kvm/book3s_hv.c:4709:		dw1 = PATB_GR | kvm->arch.process_table;
arch/powerpc/kvm/book3s_hv.c:4711:	kvmhv_set_ptbl_entry(kvm->arch.lpid, dw0, dw1);
arch/powerpc/kvm/book3s_hv.c:4716: * Must be called with kvm->arch.mmu_setup_lock held.
arch/powerpc/kvm/book3s_hv.c:4730:	if (!kvm->arch.hpt.virt) {
arch/powerpc/kvm/book3s_hv.c:4750:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:4760:	mmap_read_lock(kvm->mm);
arch/powerpc/kvm/book3s_hv.c:4761:	vma = find_vma(kvm->mm, hva);
arch/powerpc/kvm/book3s_hv.c:4767:	mmap_read_unlock(kvm->mm);
arch/powerpc/kvm/book3s_hv.c:4779:	kvm->arch.vrma_slb_v = senc | SLB_VSID_B_1T |
arch/powerpc/kvm/book3s_hv.c:4791:	/* Order updates to kvm->arch.lpcr etc. vs. mmu_ready */
arch/powerpc/kvm/book3s_hv.c:4795:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv.c:4800:	mmap_read_unlock(kvm->mm);
arch/powerpc/kvm/book3s_hv.c:4805: * Must be called with kvm->arch.mmu_setup_lock held and
arch/powerpc/kvm/book3s_hv.c:4813:	kvm->arch.process_table = 0;
arch/powerpc/kvm/book3s_hv.c:4815:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv.c:4816:	kvm->arch.radix = 0;
arch/powerpc/kvm/book3s_hv.c:4817:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv.c:4825: * Must be called with kvm->arch.mmu_setup_lock held and
arch/powerpc/kvm/book3s_hv.c:4837:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv.c:4838:	kvm->arch.radix = 1;
arch/powerpc/kvm/book3s_hv.c:4839:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/book3s_hv.c:4840:	kvmppc_free_hpt(&kvm->arch.hpt);
arch/powerpc/kvm/book3s_hv.c:4853: * It is only freed when the kvm-hv module is unloaded.
arch/powerpc/kvm/book3s_hv.c:4932:	mutex_init(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv.c:4933:	INIT_LIST_HEAD(&kvm->arch.uvmem_pfns);
arch/powerpc/kvm/book3s_hv.c:4934:	mutex_init(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:4941:	kvm->arch.lpid = lpid;
arch/powerpc/kvm/book3s_hv.c:4955:		cpumask_setall(&kvm->arch.need_tlb_flush);
arch/powerpc/kvm/book3s_hv.c:4958:	memcpy(kvm->arch.enabled_hcalls, default_enabled_hcalls,
arch/powerpc/kvm/book3s_hv.c:4959:	       sizeof(kvm->arch.enabled_hcalls));
arch/powerpc/kvm/book3s_hv.c:4962:		kvm->arch.host_sdr1 = mfspr(SPRN_SDR1);
arch/powerpc/kvm/book3s_hv.c:4966:		kvm->arch.host_lpid = mfspr(SPRN_LPID);
arch/powerpc/kvm/book3s_hv.c:4967:		kvm->arch.host_lpcr = lpcr = mfspr(SPRN_LPCR);
arch/powerpc/kvm/book3s_hv.c:4974:	kvm->arch.vrma_slb_v = SLB_VSID_B_1T |
arch/powerpc/kvm/book3s_hv.c:5002:		kvm->arch.radix = 1;
arch/powerpc/kvm/book3s_hv.c:5003:		kvm->arch.mmu_ready = 1;
arch/powerpc/kvm/book3s_hv.c:5008:			kvmppc_free_lpid(kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv.c:5015:	kvm->arch.lpcr = lpcr;
arch/powerpc/kvm/book3s_hv.c:5018:	kvm->arch.resize_hpt = NULL;
arch/powerpc/kvm/book3s_hv.c:5028:		kvm->arch.tlb_sets = 1;
arch/powerpc/kvm/book3s_hv.c:5030:		kvm->arch.tlb_sets = POWER9_TLB_SETS_RADIX;	/* 128 */
arch/powerpc/kvm/book3s_hv.c:5032:		kvm->arch.tlb_sets = POWER9_TLB_SETS_HASH;	/* 256 */
arch/powerpc/kvm/book3s_hv.c:5034:		kvm->arch.tlb_sets = POWER8_TLB_SETS;		/* 512 */
arch/powerpc/kvm/book3s_hv.c:5036:		kvm->arch.tlb_sets = POWER7_TLB_SETS;		/* 128 */
arch/powerpc/kvm/book3s_hv.c:5047:			kvm->arch.threads_indep = true;
arch/powerpc/kvm/book3s_hv.c:5049:			kvm->arch.threads_indep = indep_threads_mode;
arch/powerpc/kvm/book3s_hv.c:5052:	if (!kvm->arch.threads_indep)
arch/powerpc/kvm/book3s_hv.c:5063:		kvm->arch.smt_mode = threads_per_subcore;
arch/powerpc/kvm/book3s_hv.c:5065:		kvm->arch.smt_mode = 1;
arch/powerpc/kvm/book3s_hv.c:5066:	kvm->arch.emul_smt_mode = 1;
arch/powerpc/kvm/book3s_hv.c:5072:	kvm->arch.debugfs_dir = debugfs_create_dir(buf, kvm_debugfs_dir);
arch/powerpc/kvm/book3s_hv.c:5085:		kfree(kvm->arch.vcores[i]);
arch/powerpc/kvm/book3s_hv.c:5086:	kvm->arch.online_vcores = 0;
arch/powerpc/kvm/book3s_hv.c:5091:	debugfs_remove_recursive(kvm->arch.debugfs_dir);
arch/powerpc/kvm/book3s_hv.c:5093:	if (!kvm->arch.threads_indep)
arch/powerpc/kvm/book3s_hv.c:5102:		kvmppc_free_hpt(&kvm->arch.hpt);
arch/powerpc/kvm/book3s_hv.c:5108:		kvm->arch.process_table = 0;
arch/powerpc/kvm/book3s_hv.c:5109:		if (kvm->arch.secure_guest)
arch/powerpc/kvm/book3s_hv.c:5110:			uv_svm_terminate(kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv.c:5111:		kvmhv_set_ptbl_entry(kvm->arch.lpid, 0, 0);
arch/powerpc/kvm/book3s_hv.c:5114:	kvmppc_free_lpid(kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv.c:5155:	kfree(kvm->arch.pimap);
arch/powerpc/kvm/book3s_hv.c:5178:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5180:	pimap = kvm->arch.pimap;
arch/powerpc/kvm/book3s_hv.c:5185:			mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5188:		kvm->arch.pimap = pimap;
arch/powerpc/kvm/book3s_hv.c:5200:		mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5212:				mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5220:		mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5246:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5264:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5265:	if (!kvm->arch.pimap)
arch/powerpc/kvm/book3s_hv.c:5268:	pimap = kvm->arch.pimap;
arch/powerpc/kvm/book3s_hv.c:5276:		mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5293:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_hv.c:5478:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:5480:		if (kvm->arch.mmu_ready) {
arch/powerpc/kvm/book3s_hv.c:5481:			kvm->arch.mmu_ready = 0;
arch/powerpc/kvm/book3s_hv.c:5484:			if (atomic_read(&kvm->arch.vcpus_running)) {
arch/powerpc/kvm/book3s_hv.c:5485:				kvm->arch.mmu_ready = 1;
arch/powerpc/kvm/book3s_hv.c:5498:	kvm->arch.process_table = cfg->process_table;
arch/powerpc/kvm/book3s_hv.c:5506:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:5519:		kvm->arch.nested_enable = true;
arch/powerpc/kvm/book3s_hv.c:5581:		kvm->arch.svm_enabled = 1;
arch/powerpc/kvm/book3s_hv.c:5601:	if (!(kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START))
arch/powerpc/kvm/book3s_hv.c:5604:	mutex_lock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:5605:	mmu_was_ready = kvm->arch.mmu_ready;
arch/powerpc/kvm/book3s_hv.c:5606:	if (kvm->arch.mmu_ready) {
arch/powerpc/kvm/book3s_hv.c:5607:		kvm->arch.mmu_ready = 0;
arch/powerpc/kvm/book3s_hv.c:5610:		if (atomic_read(&kvm->arch.vcpus_running)) {
arch/powerpc/kvm/book3s_hv.c:5611:			kvm->arch.mmu_ready = 1;
arch/powerpc/kvm/book3s_hv.c:5617:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv.c:5627:			uv_unregister_mem_slot(kvm->arch.lpid, memslot->id);
arch/powerpc/kvm/book3s_hv.c:5630:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv.c:5632:	ret = uv_svm_terminate(kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv.c:5657:	kvm->arch.secure_guest = 0;
arch/powerpc/kvm/book3s_hv.c:5658:	kvm->arch.mmu_ready = mmu_was_ready;
arch/powerpc/kvm/book3s_hv.c:5660:	mutex_unlock(&kvm->arch.mmu_setup_lock);
arch/powerpc/kvm/book3s_hv.c:5671:		kvm->arch.dawr1_enabled = true;
arch/powerpc/kvm/book3s_hv.c:5772:		pr_err("KVM-HV: Host does not support TLBIE\n");
arch/powerpc/kvm/book3s_hv.c:5803:			pr_err("KVM-HV: Cannot determine method for accessing XICS\n");
arch/powerpc/kvm/book3s_hv.c:5839:		pr_err("KVM-HV: kvmppc_uvmem_init failed %d\n", r);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:44:	if (kvm->arch.online_vcores == 1 && local_paca->kvm_hstate.kvm_vcpu)
arch/powerpc/kvm/book3s_hv_rm_mmu.c:52:		cpumask_setall(&kvm->arch.need_tlb_flush);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:60:		cpumask_clear_cpu(cpu, &kvm->arch.need_tlb_flush);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:78:		head = &kvm->arch.hpt.rev[i];
arch/powerpc/kvm/book3s_hv_rm_mmu.c:81:		tail = &kvm->arch.hpt.rev[head->back];
arch/powerpc/kvm/book3s_hv_rm_mmu.c:168:	next = real_vmalloc_addr(&kvm->arch.hpt.rev[rev->forw]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:169:	prev = real_vmalloc_addr(&kvm->arch.hpt.rev[rev->back]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:215:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_hv_rm_mmu.c:241:	arch_spin_lock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:256:			arch_spin_unlock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:270:	arch_spin_unlock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:296:	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
arch/powerpc/kvm/book3s_hv_rm_mmu.c:300:		hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:331:		hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:348:	rev = &kvm->arch.hpt.rev[pte_index];
arch/powerpc/kvm/book3s_hv_rm_mmu.c:461:				     "r" (rbvalues[i]), "r" (kvm->arch.lpid));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:464:		fixup_tlbie_lpid(rbvalues[i - 1], kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:488:	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
arch/powerpc/kvm/book3s_hv_rm_mmu.c:490:	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:506:	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:529:		atomic64_inc(&kvm->arch.mmio_update);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:576:			    pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt)) {
arch/powerpc/kvm/book3s_hv_rm_mmu.c:582:			hp = (__be64 *) (kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:619:			rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:628:					atomic64_inc(&kvm->arch.mmio_update);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:675:	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
arch/powerpc/kvm/book3s_hv_rm_mmu.c:678:	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:698:	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:729:		atomic64_inc(&kvm->arch.mmio_update);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:745:	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
arch/powerpc/kvm/book3s_hv_rm_mmu.c:751:	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:753:		hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:786:	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
arch/powerpc/kvm/book3s_hv_rm_mmu.c:789:	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:790:	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:833:	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
arch/powerpc/kvm/book3s_hv_rm_mmu.c:836:	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:837:	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:921:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_hv_rm_mmu.c:924:	arch_spin_lock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:936:	arch_spin_unlock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:949:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/book3s_hv_rm_mmu.c:952:	arch_spin_lock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:967:	arch_spin_unlock(&kvm->mmu_lock.rlock.raw_lock);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:1112:	hash = (vsid ^ ((eaddr & somask) >> pshift)) & kvmppc_hpt_mask(&kvm->arch.hpt);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:1123:		hpte = (__be64 *)(kvm->arch.hpt.virt + (hash << 7));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:1159:		hash = hash ^ kvmppc_hpt_mask(&kvm->arch.hpt);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:1193:		mmio_update = atomic64_read(&kvm->arch.mmio_update);
arch/powerpc/kvm/book3s_hv_rm_mmu.c:1208:		hpte = (__be64 *)(kvm->arch.hpt.virt + (index << 4));
arch/powerpc/kvm/book3s_hv_rm_mmu.c:1215:		rev = real_vmalloc_addr(&kvm->arch.hpt.rev[index]);
arch/powerpc/kvm/book3s_hv_rm_xics.c:493:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_hv_rm_xics.c:532:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_hv_rm_xics.c:618:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_hv_rm_xics.c:679:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_hv_rm_xics.c:711:	if (!hlist_empty(&vcpu->kvm->irq_ack_notifier_list)) {
arch/powerpc/kvm/book3s_hv_rm_xics.c:737:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_hv_rm_xics.c:868:	xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_hv_rmhandlers.S:2289:	sldi	r0, r0, 3	/* index into kvm->arch.enabled_hcalls[] */
arch/powerpc/kvm/book3s_hv_uvmem.c:31: * kvm->arch.uvmem_lock is a per-guest lock that prevents concurrent
arch/powerpc/kvm/book3s_hv_uvmem.c:49: * 1. kvm->srcu - Protects KVM memslots
arch/powerpc/kvm/book3s_hv_uvmem.c:50: * 2. kvm->mm->mmap_lock - find_vma, migrate_vma_pages and helpers, ksm_madvise
arch/powerpc/kvm/book3s_hv_uvmem.c:51: * 3. kvm->arch.uvmem_lock - protects read/writes to uvmem slots thus acting
arch/powerpc/kvm/book3s_hv_uvmem.c:261:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:262:	list_add(&p->list, &kvm->arch.uvmem_pfns);
arch/powerpc/kvm/book3s_hv_uvmem.c:263:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:275:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:276:	list_for_each_entry_safe(p, next, &kvm->arch.uvmem_pfns, list) {
arch/powerpc/kvm/book3s_hv_uvmem.c:284:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:292:	list_for_each_entry(p, &kvm->arch.uvmem_pfns, list) {
arch/powerpc/kvm/book3s_hv_uvmem.c:336:	list_for_each_entry(p, &kvm->arch.uvmem_pfns, list) {
arch/powerpc/kvm/book3s_hv_uvmem.c:357: * Must be called with kvm->arch.uvmem_lock  held.
arch/powerpc/kvm/book3s_hv_uvmem.c:366:	list_for_each_entry(p, &kvm->arch.uvmem_pfns, list)
arch/powerpc/kvm/book3s_hv_uvmem.c:401:	mmap_write_lock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:403:		vma = find_vma_intersection(kvm->mm, start, end);
arch/powerpc/kvm/book3s_hv_uvmem.c:417:	mmap_write_unlock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:424:	uv_unregister_mem_slot(kvm->arch.lpid, memslot->id);
arch/powerpc/kvm/book3s_hv_uvmem.c:440:	ret = uv_register_mem_slot(kvm->arch.lpid,
arch/powerpc/kvm/book3s_hv_uvmem.c:463:	kvm->arch.secure_guest = KVMPPC_SECURE_INIT_START;
arch/powerpc/kvm/book3s_hv_uvmem.c:473:	if (!kvm->arch.svm_enabled)
arch/powerpc/kvm/book3s_hv_uvmem.c:476:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_uvmem.c:495:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_uvmem.c:502: * Caller must held kvm->arch.uvmem_lock.
arch/powerpc/kvm/book3s_hv_uvmem.c:558:		ret = uv_page_out(kvm->arch.lpid, pfn << page_shift,
arch/powerpc/kvm/book3s_hv_uvmem.c:583:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:585:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:608:	mmap_read_lock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:617:			vma = find_vma_intersection(kvm->mm, addr, addr+1);
arch/powerpc/kvm/book3s_hv_uvmem.c:624:		mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:641:		mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:644:	mmap_read_unlock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:656:	if (!(kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START))
arch/powerpc/kvm/book3s_hv_uvmem.c:659:	if (kvm->arch.secure_guest & KVMPPC_SECURE_INIT_DONE)
arch/powerpc/kvm/book3s_hv_uvmem.c:662:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_uvmem.c:667:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_uvmem.c:669:	kvm->arch.secure_guest = 0;
arch/powerpc/kvm/book3s_hv_uvmem.c:670:	uv_svm_terminate(kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv_uvmem.c:681: * Called with kvm->arch.uvmem_lock held
arch/powerpc/kvm/book3s_hv_uvmem.c:769:			ret = uv_page_in(kvm->arch.lpid, pfn << page_shift,
arch/powerpc/kvm/book3s_hv_uvmem.c:791:	mmap_read_lock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:792:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:800:		vma = find_vma_intersection(kvm->mm, start, end);
arch/powerpc/kvm/book3s_hv_uvmem.c:814:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:815:	mmap_read_unlock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:826:	if (!(kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START))
arch/powerpc/kvm/book3s_hv_uvmem.c:830:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_uvmem.c:849:	kvm->arch.secure_guest |= KVMPPC_SECURE_INIT_DONE;
arch/powerpc/kvm/book3s_hv_uvmem.c:850:	pr_info("LPID %d went secure\n", kvm->arch.lpid);
arch/powerpc/kvm/book3s_hv_uvmem.c:853:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_uvmem.c:878:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_uvmem.c:879:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:892:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:897:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:907:	if (!uv_page_in(kvm->arch.lpid, pfn << page_shift, gpa, 0,
arch/powerpc/kvm/book3s_hv_uvmem.c:913:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:915:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_uvmem.c:935:	if (!(kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START))
arch/powerpc/kvm/book3s_hv_uvmem.c:948:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_uvmem.c:949:	mmap_read_lock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:955:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:961:	vma = find_vma_intersection(kvm->mm, start, end);
arch/powerpc/kvm/book3s_hv_uvmem.c:972:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:974:	mmap_read_unlock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:975:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_uvmem.c:1005: * Gets called with kvm->arch.uvmem_lock held.
arch/powerpc/kvm/book3s_hv_uvmem.c:1044:	if (!(kvm->arch.secure_guest & KVMPPC_SECURE_INIT_START))
arch/powerpc/kvm/book3s_hv_uvmem.c:1054:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_hv_uvmem.c:1055:	mmap_read_lock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:1061:	vma = find_vma_intersection(kvm->mm, start, end);
arch/powerpc/kvm/book3s_hv_uvmem.c:1068:	mmap_read_unlock(kvm->mm);
arch/powerpc/kvm/book3s_hv_uvmem.c:1069:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_hv_uvmem.c:1082:	mutex_lock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:1086:	ret = uv_page_in(kvm->arch.lpid, pfn << PAGE_SHIFT, gfn << PAGE_SHIFT,
arch/powerpc/kvm/book3s_hv_uvmem.c:1090:	mutex_unlock(&kvm->arch.uvmem_lock);
arch/powerpc/kvm/book3s_hv_uvmem.c:1158:		 * Don't fail the initialization of kvm-hv module if
arch/powerpc/kvm/book3s_mmu_hpte.c:377:	hpte_cache = kmem_cache_create("kvm-spt", sizeof(struct hpte_cache),
arch/powerpc/kvm/book3s_pr.c:1177:			int idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_pr.c:1179:			srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/book3s_pr.c:1227:			int idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_pr.c:1229:			srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/book3s_pr.c:1869:	mutex_lock(&kvm->slots_lock);
arch/powerpc/kvm/book3s_pr.c:1889:	mutex_unlock(&kvm->slots_lock);
arch/powerpc/kvm/book3s_pr.c:1993:	mutex_init(&kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr.c:2012:	WARN_ON(!list_empty(&kvm->arch.spapr_tce_tables));
arch/powerpc/kvm/book3s_pr_papr.c:49:	mutex_lock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:80:	mutex_unlock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:96:	mutex_lock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:121:	mutex_unlock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:151:	mutex_lock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:208:	mutex_unlock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:224:	mutex_lock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:256:	mutex_unlock(&vcpu->kvm->arch.hpt_mutex);
arch/powerpc/kvm/book3s_pr_papr.c:359:	    !test_bit(cmd/4, vcpu->kvm->arch.enabled_hcalls))
arch/powerpc/kvm/book3s_pr_papr.c:397:		if (list_empty(&vcpu->kvm->arch.rtas_tokens))
arch/powerpc/kvm/book3s_pr_papr.c:399:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_pr_papr.c:401:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/book3s_pr_papr.c:469:		__set_bit(hcall / 4, kvm->arch.enabled_hcalls);
arch/powerpc/kvm/book3s_rtas.c:146:	lockdep_assert_held(&kvm->arch.rtas_token_lock);
arch/powerpc/kvm/book3s_rtas.c:148:	list_for_each_entry_safe(d, tmp, &kvm->arch.rtas_tokens, list) {
arch/powerpc/kvm/book3s_rtas.c:167:	lockdep_assert_held(&kvm->arch.rtas_token_lock);
arch/powerpc/kvm/book3s_rtas.c:169:	list_for_each_entry(d, &kvm->arch.rtas_tokens, list) {
arch/powerpc/kvm/book3s_rtas.c:193:	list_add_tail(&d->list, &kvm->arch.rtas_tokens);
arch/powerpc/kvm/book3s_rtas.c:206:	mutex_lock(&kvm->arch.rtas_token_lock);
arch/powerpc/kvm/book3s_rtas.c:213:	mutex_unlock(&kvm->arch.rtas_token_lock);
arch/powerpc/kvm/book3s_rtas.c:232:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_rtas.c:234:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/book3s_rtas.c:247:	mutex_lock(&vcpu->kvm->arch.rtas_token_lock);
arch/powerpc/kvm/book3s_rtas.c:250:	list_for_each_entry(d, &vcpu->kvm->arch.rtas_tokens, list) {
arch/powerpc/kvm/book3s_rtas.c:258:	mutex_unlock(&vcpu->kvm->arch.rtas_token_lock);
arch/powerpc/kvm/book3s_rtas.c:284:	list_for_each_entry_safe(d, tmp, &kvm->arch.rtas_tokens, list) {
arch/powerpc/kvm/book3s_xics.c:168:	struct kvmppc_xics *xics = kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:198:	struct kvmppc_xics *xics = kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:224:	struct kvmppc_xics *xics = kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:251:	struct kvmppc_xics *xics = kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:623:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:724:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:779:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:819:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:850:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:877:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:960:	xics_debugfs_irqmap(m, kvm->arch.pimap);
arch/powerpc/kvm/book3s_xics.c:1021:	name = kasprintf(GFP_KERNEL, "kvm-xics-%p", xics);
arch/powerpc/kvm/book3s_xics.c:1042:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/book3s_xics.c:1067:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/book3s_xics.c:1075:	if (!vcpu->kvm->arch.xics)
arch/powerpc/kvm/book3s_xics.c:1113:	struct kvmppc_xics *xics = vcpu->kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:1296:	struct kvmppc_xics *xics = kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:1338: * Called when device fd is closed. kvm->lock is held.
arch/powerpc/kvm/book3s_xics.c:1379:		kvm->arch.xics = NULL;
arch/powerpc/kvm/book3s_xics.c:1396:	struct kvmppc_xics **kvm_xics_device = &kvm->arch.xics_device;
arch/powerpc/kvm/book3s_xics.c:1417:	if (kvm->arch.xics)
arch/powerpc/kvm/book3s_xics.c:1427:	kvm->arch.xics = xics;
arch/powerpc/kvm/book3s_xics.c:1449:	.name = "kvm-xics",
arch/powerpc/kvm/book3s_xics.c:1490:	struct kvmppc_xics *xics = kvm->arch.xics;
arch/powerpc/kvm/book3s_xics.c:1506:	struct kvmppc_xics *xics = kvm->arch.xics;
arch/powerpc/kvm/book3s_xive.c:196:		name = kasprintf(GFP_KERNEL, "kvm-%d-%d",
arch/powerpc/kvm/book3s_xive.c:197:				 vcpu->kvm->arch.lpid, xc->server_num);
arch/powerpc/kvm/book3s_xive.c:199:		name = kasprintf(GFP_KERNEL, "kvm-%d-%d-%d",
arch/powerpc/kvm/book3s_xive.c:200:				 vcpu->kvm->arch.lpid, xc->server_num, prio);
arch/powerpc/kvm/book3s_xive.c:283:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:494:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:578:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:679:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:701:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:740:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:802:	struct kvmppc_xive *xive = vcpu->kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:861:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:958:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:1040:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:1115:	struct kvmppc_xive *xive = vcpu->kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:1794:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive.c:1941: * Called when device fd is closed.  kvm->lock is held.
arch/powerpc/kvm/book3s_xive.c:1986:	kvm->arch.xive = NULL;
arch/powerpc/kvm/book3s_xive.c:2021:		&kvm->arch.xive_devices.native :
arch/powerpc/kvm/book3s_xive.c:2022:		&kvm->arch.xive_devices.xics_on_xive;
arch/powerpc/kvm/book3s_xive.c:2036: * Create a XICS device with XIVE backend.  kvm->lock is held.
arch/powerpc/kvm/book3s_xive.c:2046:	if (kvm->arch.xive)
arch/powerpc/kvm/book3s_xive.c:2074:	kvm->arch.xive = xive;
arch/powerpc/kvm/book3s_xive.c:2230:	name = kasprintf(GFP_KERNEL, "kvm-xive-%p", xive);
arch/powerpc/kvm/book3s_xive.c:2252:	.name = "kvm-xive",
arch/powerpc/kvm/book3s_xive_template.c:45:		pr_warn("KVM-XIVE: CPU %d odd ack CPPR, got %d at %d\n",
arch/powerpc/kvm/book3s_xive_template.c:440:	struct kvmppc_xive *xive = vcpu->kvm->arch.xive;
arch/powerpc/kvm/book3s_xive_template.c:498:	struct kvmppc_xive *xive = vcpu->kvm->arch.xive;
arch/powerpc/kvm/book3s_xive_native.c:198:	struct kvmppc_xive *xive = kvm->arch.xive;
arch/powerpc/kvm/book3s_xive_native.c:641:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/powerpc/kvm/book3s_xive_native.c:646:		srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_xive_native.c:653:		srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_xive_native.c:659:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_xive_native.c:902:		srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/book3s_xive_native.c:904:		srcu_read_unlock(&vcpu->kvm->srcu, srcu_idx);
arch/powerpc/kvm/book3s_xive_native.c:1007: * Called when device fd is closed.  kvm->lock is held.
arch/powerpc/kvm/book3s_xive_native.c:1061:	kvm->arch.xive = NULL;
arch/powerpc/kvm/book3s_xive_native.c:1084: * Create a XIVE device.  kvm->lock is held.
arch/powerpc/kvm/book3s_xive_native.c:1093:	if (kvm->arch.xive)
arch/powerpc/kvm/book3s_xive_native.c:1116:	kvm->arch.xive = xive;
arch/powerpc/kvm/book3s_xive_native.c:1167:	struct kvmppc_xive *xive = vcpu->kvm->arch.xive;
arch/powerpc/kvm/book3s_xive_native.c:1253:	name = kasprintf(GFP_KERNEL, "kvm-xive-%p", xive);
arch/powerpc/kvm/book3s_xive_native.c:1275:	.name = "kvm-xive-native",
arch/powerpc/kvm/booke.c:778:	vcpu->arch.pgdir = vcpu->kvm->mm->pgd;
arch/powerpc/kvm/booke.c:1266:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/booke.c:1290:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/booke.c:1314:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/booke.c:1332:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/booke.c:1594:	ret = vcpu->kvm->arch.kvm_ops->get_sregs(vcpu, sregs);
arch/powerpc/kvm/booke.c:1617:	ret = vcpu->kvm->arch.kvm_ops->set_sregs(vcpu, sregs);
arch/powerpc/kvm/booke.c:1673:		r = vcpu->kvm->arch.kvm_ops->get_one_reg(vcpu, id, val);
arch/powerpc/kvm/booke.c:1742:		r = vcpu->kvm->arch.kvm_ops->set_one_reg(vcpu, id, val);
arch/powerpc/kvm/booke.c:2079:	return kvm->arch.kvm_ops->init_vm(kvm);
arch/powerpc/kvm/booke.c:2087:	r = vcpu->kvm->arch.kvm_ops->vcpu_create(vcpu);
arch/powerpc/kvm/booke.c:2113:		vcpu->kvm->arch.kvm_ops->vcpu_free(vcpu);
arch/powerpc/kvm/booke.c:2120:	vcpu->kvm->arch.kvm_ops->vcpu_free(vcpu);
arch/powerpc/kvm/booke.c:2125:	kvm->arch.kvm_ops->destroy_vm(kvm);
arch/powerpc/kvm/booke.c:2130:	vcpu->kvm->arch.kvm_ops->vcpu_load(vcpu, cpu);
arch/powerpc/kvm/booke.c:2135:	vcpu->kvm->arch.kvm_ops->vcpu_put(vcpu);
arch/powerpc/kvm/e500.h:307:	return get_thread_specific_lpid(vcpu->kvm->arch.lpid);
arch/powerpc/kvm/e500_mmu.c:431:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/e500_mmu.c:447:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/e500_mmu_host.c:131:		__write_host_tlbe(stlbe, mas0, vcpu_e500->vcpu.kvm->arch.lpid);
arch/powerpc/kvm/e500_mmu_host.c:136:				  vcpu_e500->vcpu.kvm->arch.lpid);
arch/powerpc/kvm/e500_mmu_host.c:342:	mmu_seq = kvm->mmu_notifier_seq;
arch/powerpc/kvm/e500_mmu_host.c:358:		mmap_read_lock(kvm->mm);
arch/powerpc/kvm/e500_mmu_host.c:360:		vma = find_vma(kvm->mm, hva);
arch/powerpc/kvm/e500_mmu_host.c:444:		mmap_read_unlock(kvm->mm);
arch/powerpc/kvm/e500_mmu_host.c:462:	spin_lock(&kvm->mmu_lock);
arch/powerpc/kvm/e500_mmu_host.c:473:	 * We are holding kvm->mmu_lock so a notifier invalidate
arch/powerpc/kvm/e500_mmu_host.c:502:	spin_unlock(&kvm->mmu_lock);
arch/powerpc/kvm/e500mc.c:356:	kvm->arch.lpid = lpid;
arch/powerpc/kvm/e500mc.c:362:	int lpid = kvm->arch.lpid;
arch/powerpc/kvm/emulate.c:115:		emulated = vcpu->kvm->arch.kvm_ops->emulate_mtspr(vcpu, sprn,
arch/powerpc/kvm/emulate.c:176:		emulated = vcpu->kvm->arch.kvm_ops->emulate_mfspr(vcpu, sprn,
arch/powerpc/kvm/emulate.c:288:		emulated = vcpu->kvm->arch.kvm_ops->emulate_op(vcpu, inst,
arch/powerpc/kvm/emulate_loadstore.c:244:			if (vcpu->kvm->arch.kvm_ops->giveup_ext)
arch/powerpc/kvm/emulate_loadstore.c:245:				vcpu->kvm->arch.kvm_ops->giveup_ext(vcpu,
arch/powerpc/kvm/emulate_loadstore.c:268:			if (vcpu->kvm->arch.kvm_ops->giveup_ext)
arch/powerpc/kvm/emulate_loadstore.c:269:				vcpu->kvm->arch.kvm_ops->giveup_ext(vcpu,
arch/powerpc/kvm/emulate_loadstore.c:313:			if (vcpu->kvm->arch.kvm_ops->giveup_ext)
arch/powerpc/kvm/emulate_loadstore.c:314:				vcpu->kvm->arch.kvm_ops->giveup_ext(vcpu,
arch/powerpc/kvm/irq.h:12:	ret = ret || (kvm->arch.mpic != NULL);
arch/powerpc/kvm/irq.h:15:	ret = ret || (kvm->arch.xics != NULL);
arch/powerpc/kvm/irq.h:16:	ret = ret || (kvm->arch.xive != NULL);
arch/powerpc/kvm/mpic.c:1475:	mutex_lock(&opp->kvm->slots_lock);
arch/powerpc/kvm/mpic.c:1489:	mutex_unlock(&opp->kvm->slots_lock);
arch/powerpc/kvm/mpic.c:1567:			mutex_lock(&opp->kvm->slots_lock);
arch/powerpc/kvm/mpic.c:1569:			mutex_unlock(&opp->kvm->slots_lock);
arch/powerpc/kvm/mpic.c:1635:	dev->kvm->arch.mpic = NULL;
arch/powerpc/kvm/mpic.c:1661:	if (dev->kvm->arch.mpic)
arch/powerpc/kvm/mpic.c:1714:	dev->kvm->arch.mpic = opp;
arch/powerpc/kvm/mpic.c:1724:	.name = "kvm-mpic",
arch/powerpc/kvm/mpic.c:1795:	struct openpic *opp = kvm->arch.mpic;
arch/powerpc/kvm/mpic.c:1809:	struct openpic *opp = kvm->arch.mpic;
arch/powerpc/kvm/mpic.c:1818:	openpic_msi_write(kvm->arch.mpic, MSIIR_OFFSET, e->msi.data);
arch/powerpc/kvm/powerpc.c:333:	if (vcpu->kvm->arch.kvm_ops && vcpu->kvm->arch.kvm_ops->store_to_eaddr)
arch/powerpc/kvm/powerpc.c:334:		r = vcpu->kvm->arch.kvm_ops->store_to_eaddr(vcpu, eaddr, ptr,
arch/powerpc/kvm/powerpc.c:376:	if (vcpu->kvm->arch.kvm_ops && vcpu->kvm->arch.kvm_ops->load_from_eaddr)
arch/powerpc/kvm/powerpc.c:377:		rc = vcpu->kvm->arch.kvm_ops->load_from_eaddr(vcpu, eaddr, ptr,
arch/powerpc/kvm/powerpc.c:406:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/powerpc.c:408:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/powerpc/kvm/powerpc.c:458:	kvm->arch.kvm_ops = kvm_ops;
arch/powerpc/kvm/powerpc.c:482:	mutex_lock(&kvm->lock);
arch/powerpc/kvm/powerpc.c:483:	for (i = 0; i < atomic_read(&kvm->online_vcpus); i++)
arch/powerpc/kvm/powerpc.c:484:		kvm->vcpus[i] = NULL;
arch/powerpc/kvm/powerpc.c:486:	atomic_set(&kvm->online_vcpus, 0);
arch/powerpc/kvm/powerpc.c:490:	mutex_unlock(&kvm->lock);
arch/powerpc/kvm/powerpc.c:493:	module_put(kvm->arch.kvm_ops->owner);
arch/powerpc/kvm/powerpc.c:583:			if (kvm->arch.emul_smt_mode > 1)
arch/powerpc/kvm/powerpc.c:584:				r = kvm->arch.emul_smt_mode;
arch/powerpc/kvm/powerpc.c:586:				r = kvm->arch.smt_mode;
arch/powerpc/kvm/powerpc.c:849:	if (kvm->arch.kvm_ops->irq_bypass_add_producer)
arch/powerpc/kvm/powerpc.c:850:		return kvm->arch.kvm_ops->irq_bypass_add_producer(cons, prod);
arch/powerpc/kvm/powerpc.c:862:	if (kvm->arch.kvm_ops->irq_bypass_del_producer)
arch/powerpc/kvm/powerpc.c:863:		kvm->arch.kvm_ops->irq_bypass_del_producer(cons, prod);
arch/powerpc/kvm/powerpc.c:1168:		if (vcpu->kvm->arch.kvm_ops->giveup_ext)
arch/powerpc/kvm/powerpc.c:1169:			vcpu->kvm->arch.kvm_ops->giveup_ext(vcpu, MSR_FP);
arch/powerpc/kvm/powerpc.c:1184:		if (vcpu->kvm->arch.kvm_ops->giveup_ext)
arch/powerpc/kvm/powerpc.c:1185:			vcpu->kvm->arch.kvm_ops->giveup_ext(vcpu, MSR_VSX);
arch/powerpc/kvm/powerpc.c:1201:		if (vcpu->kvm->arch.kvm_ops->giveup_ext)
arch/powerpc/kvm/powerpc.c:1202:			vcpu->kvm->arch.kvm_ops->giveup_ext(vcpu, MSR_VEC);
arch/powerpc/kvm/powerpc.c:1259:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/powerpc.c:1264:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/powerpc.c:1364:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/powerpc/kvm/powerpc.c:1369:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/powerpc/kvm/powerpc.c:1982:		vcpu->kvm->arch.fwnmi_enabled = true;
arch/powerpc/kvm/powerpc.c:1999:	if (kvm->arch.mpic)
arch/powerpc/kvm/powerpc.c:2003:	if (kvm->arch.xics || kvm->arch.xive)
arch/powerpc/kvm/powerpc.c:2163:			set_bit(hcall / 4, kvm->arch.enabled_hcalls);
arch/powerpc/kvm/powerpc.c:2165:			clear_bit(hcall / 4, kvm->arch.enabled_hcalls);
arch/powerpc/kvm/powerpc.c:2174:		if (kvm->arch.kvm_ops->set_smt_mode)
arch/powerpc/kvm/powerpc.c:2175:			r = kvm->arch.kvm_ops->set_smt_mode(kvm, mode, flags);
arch/powerpc/kvm/powerpc.c:2182:		    !kvm->arch.kvm_ops->enable_nested)
arch/powerpc/kvm/powerpc.c:2184:		r = kvm->arch.kvm_ops->enable_nested(kvm);
arch/powerpc/kvm/powerpc.c:2190:		if (!is_kvmppc_hv_enabled(kvm) || !kvm->arch.kvm_ops->enable_svm)
arch/powerpc/kvm/powerpc.c:2192:		r = kvm->arch.kvm_ops->enable_svm(kvm);
arch/powerpc/kvm/powerpc.c:2196:		if (!is_kvmppc_hv_enabled(kvm) || !kvm->arch.kvm_ops->enable_dawr1)
arch/powerpc/kvm/powerpc.c:2198:		r = kvm->arch.kvm_ops->enable_dawr1(kvm);
arch/powerpc/kvm/powerpc.c:2394:		r = kvm->arch.kvm_ops->get_smmu_info(kvm, &info);
arch/powerpc/kvm/powerpc.c:2410:		if (!kvm->arch.kvm_ops->configure_mmu)
arch/powerpc/kvm/powerpc.c:2415:		r = kvm->arch.kvm_ops->configure_mmu(kvm, &cfg);
arch/powerpc/kvm/powerpc.c:2423:		if (!kvm->arch.kvm_ops->get_rmmu_info)
arch/powerpc/kvm/powerpc.c:2425:		r = kvm->arch.kvm_ops->get_rmmu_info(kvm, &info);
arch/powerpc/kvm/powerpc.c:2442:		if (!kvm->arch.kvm_ops->svm_off)
arch/powerpc/kvm/powerpc.c:2445:		r = kvm->arch.kvm_ops->svm_off(kvm);
arch/powerpc/kvm/powerpc.c:2450:		r = kvm->arch.kvm_ops->arch_vm_ioctl(filp, ioctl, arg);
arch/s390/kvm/Makefile:11:kvm-objs := $(common-objs) kvm-s390.o intercept.o interrupt.o priv.o sigp.o
arch/s390/kvm/Makefile:12:kvm-objs += diag.o gaccess.o guestdbg.o vsie.o pv.o
arch/s390/kvm/diag.c:15:#include "kvm-s390.h"
arch/s390/kvm/diag.c:250:	if (!vcpu->kvm->arch.css_support ||
arch/s390/kvm/gaccess.h:17:#include "kvm-s390.h"
arch/s390/kvm/intercept.c:20:#include "kvm-s390.h"
arch/s390/kvm/intercept.c:439:	if (vcpu->arch.sie_block->ipa == 0 && vcpu->kvm->arch.user_instr0)
arch/s390/kvm/intercept.c:474:	struct kvm_s390_float_interrupt *fi = &vcpu->kvm->arch.float_int;
arch/s390/kvm/guestdbg.c:11:#include "kvm-s390.h"
arch/s390/kvm/interrupt.c:10:#define KMSG_COMPONENT "kvm-s390"
arch/s390/kvm/interrupt.c:31:#include "kvm-s390.h"
arch/s390/kvm/interrupt.c:50:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/interrupt.c:51:	if (vcpu->kvm->arch.use_esca) {
arch/s390/kvm/interrupt.c:52:		struct esca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/interrupt.c:59:		struct bsca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/interrupt.c:66:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/interrupt.c:79:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/interrupt.c:80:	if (vcpu->kvm->arch.use_esca) {
arch/s390/kvm/interrupt.c:81:		struct esca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/interrupt.c:93:		struct bsca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/interrupt.c:105:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/interrupt.c:122:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/interrupt.c:123:	if (vcpu->kvm->arch.use_esca) {
arch/s390/kvm/interrupt.c:124:		struct esca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/interrupt.c:132:		struct bsca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/interrupt.c:140:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/interrupt.c:327:	unsigned long pending = vcpu->kvm->arch.float_int.pending_irqs |
arch/s390/kvm/interrupt.c:330:	pending &= ~vcpu->kvm->arch.float_int.masked_irqs;
arch/s390/kvm/interrupt.c:336:	struct kvm_s390_gisa_interrupt *gi = &vcpu->kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:406:	   (vcpu->kvm->arch.float_int.mchk.cr14 |
arch/s390/kvm/interrupt.c:422:	set_bit(vcpu->vcpu_id, vcpu->kvm->arch.idle_mask);
arch/s390/kvm/interrupt.c:428:	clear_bit(vcpu->vcpu_id, vcpu->kvm->arch.idle_mask);
arch/s390/kvm/interrupt.c:680:	struct kvm_s390_float_interrupt *fi = &vcpu->kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1001:	struct kvm_s390_float_interrupt *fi = &vcpu->kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1029:	struct kvm_s390_float_interrupt *fi = &vcpu->kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1053:	struct kvm_s390_float_interrupt *fi = &vcpu->kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1095:	struct kvm_s390_float_interrupt *fi = &vcpu->kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1170:	struct kvm_s390_gisa_interrupt *gi = &vcpu->kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:1176:	fi = &vcpu->kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1303:	struct kvm_s390_gisa_interrupt *gi = &vcpu->kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:1337:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/s390/kvm/interrupt.c:1340:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/s390/kvm/interrupt.c:1700:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1738:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:1773:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:1811:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1813:	kvm->stat.inject_service_signal++;
arch/s390/kvm/interrupt.c:1842:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1844:	kvm->stat.inject_virtio++;
arch/s390/kvm/interrupt.c:1860:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1862:	kvm->stat.inject_pfault_done++;
arch/s390/kvm/interrupt.c:1880:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1882:	kvm->stat.inject_float_mchk++;
arch/s390/kvm/interrupt.c:1894:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:1899:	kvm->stat.inject_io++;
arch/s390/kvm/interrupt.c:1916:	fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:1946:	online_vcpus = atomic_read(&kvm->online_vcpus);
arch/s390/kvm/interrupt.c:1951:	sigcpu = find_first_bit(kvm->arch.idle_mask, online_vcpus);
arch/s390/kvm/interrupt.c:1954:			sigcpu = kvm->arch.float_int.next_rr_cpu++;
arch/s390/kvm/interrupt.c:1955:			kvm->arch.float_int.next_rr_cpu %= online_vcpus;
arch/s390/kvm/interrupt.c:1970:		      kvm->arch.gisa_int.origin) ||
arch/s390/kvm/interrupt.c:2214:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:2217:	mutex_lock(&kvm->lock);
arch/s390/kvm/interrupt.c:2220:	mutex_unlock(&kvm->lock);
arch/s390/kvm/interrupt.c:2235:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:2274:	fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:2325:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:2443:	return kvm->arch.adapters[id];
arch/s390/kvm/interrupt.c:2462:	if (dev->kvm->arch.adapters[adapter_info.id] != NULL)
arch/s390/kvm/interrupt.c:2476:	dev->kvm->arch.adapters[adapter->id] = adapter;
arch/s390/kvm/interrupt.c:2498:		kfree(kvm->arch.adapters[i]);
arch/s390/kvm/interrupt.c:2561:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:2601:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:2642:	struct kvm_s390_float_interrupt *fi = &kvm->arch.float_int;
arch/s390/kvm/interrupt.c:2673:		dev->kvm->arch.gmap->pfault_enabled = 1;
arch/s390/kvm/interrupt.c:2676:		dev->kvm->arch.gmap->pfault_enabled = 0;
arch/s390/kvm/interrupt.c:2682:		synchronize_srcu(&dev->kvm->srcu);
arch/s390/kvm/interrupt.c:2735:	if (dev->kvm->arch.flic)
arch/s390/kvm/interrupt.c:2737:	dev->kvm->arch.flic = dev;
arch/s390/kvm/interrupt.c:2743:	dev->kvm->arch.flic = NULL;
arch/s390/kvm/interrupt.c:2749:	.name = "kvm-flic",
arch/s390/kvm/interrupt.c:2770:	mmap_read_lock(kvm->mm);
arch/s390/kvm/interrupt.c:2771:	get_user_pages_remote(kvm->mm, uaddr, 1, FOLL_WRITE,
arch/s390/kvm/interrupt.c:2773:	mmap_read_unlock(kvm->mm);
arch/s390/kvm/interrupt.c:2795:	idx = srcu_read_lock(&kvm->srcu);
arch/s390/kvm/interrupt.c:2808:	srcu_read_unlock(&kvm->srcu, idx);
arch/s390/kvm/interrupt.c:2890:		uaddr =  gmap_translate(kvm->arch.gmap, ue->u.adapter.summary_addr);
arch/s390/kvm/interrupt.c:2894:		uaddr =  gmap_translate(kvm->arch.gmap, ue->u.adapter.ind_addr);
arch/s390/kvm/interrupt.c:3053:	int vcpu_id, online_vcpus = atomic_read(&kvm->online_vcpus);
arch/s390/kvm/interrupt.c:3054:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:3057:	for_each_set_bit(vcpu_id, kvm->arch.idle_mask, online_vcpus) {
arch/s390/kvm/interrupt.c:3129:			gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:3140:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:3150:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:3154:	gi->origin = &kvm->arch.sie_page2->gisa;
arch/s390/kvm/interrupt.c:3167:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:3199:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/interrupt.c:3238:	struct kvm_s390_gisa_interrupt *gi = &kvm->arch.gisa_int;
arch/s390/kvm/kvm-s390.h:48:	debug_sprintf_event(d_kvm->arch.dbf, d_loglevel, d_string "\n", \
arch/s390/kvm/kvm-s390.h:54:	debug_sprintf_event(d_vcpu->kvm->arch.dbf, d_loglevel, \
arch/s390/kvm/kvm-s390.h:82:	return test_bit(vcpu->vcpu_id, vcpu->kvm->arch.idle_mask);
arch/s390/kvm/kvm-s390.h:88:	if (kvm->arch.gmap)
arch/s390/kvm/kvm-s390.h:184:	return __test_facility(nr, kvm->arch.model.fac_mask) &&
arch/s390/kvm/kvm-s390.h:185:		__test_facility(nr, kvm->arch.model.fac_list);
arch/s390/kvm/kvm-s390.h:202:	return test_bit_inv(nr, kvm->arch.cpu_feat);
arch/s390/kvm/kvm-s390.h:208:	return kvm->arch.user_cpu_state_ctrl != 0;
arch/s390/kvm/kvm-s390.h:224:	return kvm->arch.pv.handle;
arch/s390/kvm/kvm-s390.h:234:	lockdep_assert_held(&kvm->lock);
arch/s390/kvm/kvm-s390.h:328:/* implemented in kvm-s390.c */
arch/s390/kvm/kvm-s390.h:354:	WARN_ON(!mutex_is_locked(&kvm->lock));
arch/s390/kvm/kvm-s390.h:373:	rc = get_tod_clock_fast() + kvm->arch.epoch;
arch/s390/kvm/kvm-s390.h:446:	struct bsca_block *sca = kvm->arch.sca; /* SCA version doesn't matter */
arch/s390/kvm/kvm-s390.h:469: * Note: The kvm->lock must be held while calling this function
arch/s390/kvm/gaccess.c:15:#include "kvm-s390.h"
arch/s390/kvm/gaccess.c:269:		read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:271:		read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:274:	return vcpu->kvm->arch.ipte_lock_count != 0;
arch/s390/kvm/gaccess.c:281:	mutex_lock(&vcpu->kvm->arch.ipte_mutex);
arch/s390/kvm/gaccess.c:282:	vcpu->kvm->arch.ipte_lock_count++;
arch/s390/kvm/gaccess.c:283:	if (vcpu->kvm->arch.ipte_lock_count > 1)
arch/s390/kvm/gaccess.c:286:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:291:			read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:298:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:300:	mutex_unlock(&vcpu->kvm->arch.ipte_mutex);
arch/s390/kvm/gaccess.c:307:	mutex_lock(&vcpu->kvm->arch.ipte_mutex);
arch/s390/kvm/gaccess.c:308:	vcpu->kvm->arch.ipte_lock_count--;
arch/s390/kvm/gaccess.c:309:	if (vcpu->kvm->arch.ipte_lock_count)
arch/s390/kvm/gaccess.c:311:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:318:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:319:	wake_up(&vcpu->kvm->arch.ipte_wq);
arch/s390/kvm/gaccess.c:321:	mutex_unlock(&vcpu->kvm->arch.ipte_mutex);
arch/s390/kvm/gaccess.c:329:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:334:			read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:342:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:349:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:358:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/gaccess.c:360:		wake_up(&vcpu->kvm->arch.ipte_wq);
arch/s390/kvm/priv.c:31:#include "kvm-s390.h"
arch/s390/kvm/priv.c:221:	if (!vcpu->kvm->arch.use_skf)
arch/s390/kvm/priv.c:236:	if (vcpu->kvm->arch.use_skf) {
arch/s390/kvm/priv.c:431:	wait_event(vcpu->kvm->arch.ipte_wq, !ipte_lock_held(vcpu));
arch/s390/kvm/priv.c:573:	if (vcpu->kvm->arch.css_support) {
arch/s390/kvm/priv.c:648:	if (!(vcpu->kvm->arch.crypto.crycbd & 0x02) && (reg0 & 0x0000c0f0UL))
arch/s390/kvm/priv.c:660:	if (vcpu->kvm->arch.crypto.pqap_hook) {
arch/s390/kvm/priv.c:661:		if (!try_module_get(vcpu->kvm->arch.crypto.pqap_hook->owner))
arch/s390/kvm/priv.c:663:		ret = vcpu->kvm->arch.crypto.pqap_hook->hook(vcpu);
arch/s390/kvm/priv.c:664:		module_put(vcpu->kvm->arch.crypto.pqap_hook->owner);
arch/s390/kvm/priv.c:694:	fac = *vcpu->kvm->arch.model.fac_list >> 32;
arch/s390/kvm/priv.c:782:	u64 stidp_data = vcpu->kvm->arch.model.cpuid;
arch/s390/kvm/priv.c:810:	cpus = atomic_read(&vcpu->kvm->online_vcpus);
arch/s390/kvm/priv.c:908:	if (vcpu->kvm->arch.user_stsi) {
arch/s390/kvm/priv.c:1124: * Must be called with relevant read locks held (kvm->mm->mmap_lock, kvm->srcu)
arch/s390/kvm/priv.c:1145:	nappended = pgste_perform_essa(vcpu->kvm->mm, hva, orc, &ptev, &pgstev);
arch/s390/kvm/priv.c:1182:			atomic64_inc(&vcpu->kvm->arch.cmma_dirty_pages);
arch/s390/kvm/priv.c:1199:	if (!vcpu->kvm->arch.use_cmma)
arch/s390/kvm/priv.c:1211:	if (!vcpu->kvm->arch.migration_mode) {
arch/s390/kvm/priv.c:1221:		if (vcpu->kvm->mm->context.uses_cmm == 0) {
arch/s390/kvm/priv.c:1222:			mmap_write_lock(vcpu->kvm->mm);
arch/s390/kvm/priv.c:1223:			vcpu->kvm->mm->context.uses_cmm = 1;
arch/s390/kvm/priv.c:1224:			mmap_write_unlock(vcpu->kvm->mm);
arch/s390/kvm/priv.c:1241:		mmap_read_lock(vcpu->kvm->mm);
arch/s390/kvm/priv.c:1242:		srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/s390/kvm/priv.c:1244:		srcu_read_unlock(&vcpu->kvm->srcu, srcu_idx);
arch/s390/kvm/priv.c:1245:		mmap_read_unlock(vcpu->kvm->mm);
arch/s390/kvm/pv.c:15:#include "kvm-s390.h"
arch/s390/kvm/pv.c:109:	vfree(kvm->arch.pv.stor_var);
arch/s390/kvm/pv.c:110:	free_pages(kvm->arch.pv.stor_base,
arch/s390/kvm/pv.c:112:	memset(&kvm->arch.pv, 0, sizeof(kvm->arch.pv));
arch/s390/kvm/pv.c:122:	kvm->arch.pv.stor_var = NULL;
arch/s390/kvm/pv.c:123:	kvm->arch.pv.stor_base = __get_free_pages(GFP_KERNEL_ACCOUNT, get_order(base));
arch/s390/kvm/pv.c:124:	if (!kvm->arch.pv.stor_base)
arch/s390/kvm/pv.c:133:	mutex_lock(&kvm->slots_lock);
arch/s390/kvm/pv.c:136:	mutex_unlock(&kvm->slots_lock);
arch/s390/kvm/pv.c:138:	kvm->arch.pv.guest_len = npages * PAGE_SIZE;
arch/s390/kvm/pv.c:148:	kvm->arch.pv.stor_var = vmalloc_no_huge(vlen);
arch/s390/kvm/pv.c:149:	if (!kvm->arch.pv.stor_var)
arch/s390/kvm/pv.c:164:	s390_reset_acc(kvm->mm);
arch/s390/kvm/pv.c:168:	WRITE_ONCE(kvm->arch.gmap->guest_handle, 0);
arch/s390/kvm/pv.c:169:	atomic_set(&kvm->mm->context.is_protected, 0);
arch/s390/kvm/pv.c:193:	uvcb.guest_stor_len = kvm->arch.pv.guest_len;
arch/s390/kvm/pv.c:194:	uvcb.guest_asce = kvm->arch.gmap->asce;
arch/s390/kvm/pv.c:195:	uvcb.guest_sca = (unsigned long)kvm->arch.sca;
arch/s390/kvm/pv.c:196:	uvcb.conf_base_stor_origin = (u64)kvm->arch.pv.stor_base;
arch/s390/kvm/pv.c:197:	uvcb.conf_virt_stor_origin = (u64)kvm->arch.pv.stor_var;
arch/s390/kvm/pv.c:206:	kvm->arch.pv.handle = uvcb.guest_handle;
arch/s390/kvm/pv.c:215:	kvm->arch.gmap->guest_handle = uvcb.guest_handle;
arch/s390/kvm/pv.c:236:		atomic_set(&kvm->mm->context.is_protected, 1);
arch/s390/kvm/pv.c:251:	int ret = gmap_make_secure(kvm->arch.gmap, addr, &uvcb);
arch/s390/kvm/sigp.c:17:#include "kvm-s390.h"
arch/s390/kvm/sigp.c:362:	if (!vcpu->kvm->arch.user_sigp)
arch/s390/kvm/kvm-s390.c:14:#define KMSG_COMPONENT "kvm-s390"
arch/s390/kvm/kvm-s390.c:49:#include "kvm-s390.h"
arch/s390/kvm/kvm-s390.c:289:				kvm->arch.epoch = vcpu->arch.sie_block->epoch;
arch/s390/kvm/kvm-s390.c:290:				kvm->arch.epdx = vcpu->arch.sie_block->epdx;
arch/s390/kvm/kvm-s390.c:469:	kvm_s390_dbf = debug_register("kvm-trace", 32, 1, 7 * sizeof(long));
arch/s390/kvm/kvm-s390.c:473:	kvm_s390_dbf_uv = debug_register("kvm-uv", 32, 1, 7 * sizeof(long));
arch/s390/kvm/kvm-s390.c:602:	struct gmap *gmap = kvm->arch.gmap;
arch/s390/kvm/kvm-s390.c:644:	mutex_lock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:661:	mutex_unlock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:685:		kvm->arch.use_irqchip = 1;
arch/s390/kvm/kvm-s390.c:690:		kvm->arch.user_sigp = 1;
arch/s390/kvm/kvm-s390.c:694:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:695:		if (kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:698:			set_kvm_facility(kvm->arch.model.fac_mask, 129);
arch/s390/kvm/kvm-s390.c:699:			set_kvm_facility(kvm->arch.model.fac_list, 129);
arch/s390/kvm/kvm-s390.c:701:				set_kvm_facility(kvm->arch.model.fac_mask, 134);
arch/s390/kvm/kvm-s390.c:702:				set_kvm_facility(kvm->arch.model.fac_list, 134);
arch/s390/kvm/kvm-s390.c:705:				set_kvm_facility(kvm->arch.model.fac_mask, 135);
arch/s390/kvm/kvm-s390.c:706:				set_kvm_facility(kvm->arch.model.fac_list, 135);
arch/s390/kvm/kvm-s390.c:709:				set_kvm_facility(kvm->arch.model.fac_mask, 148);
arch/s390/kvm/kvm-s390.c:710:				set_kvm_facility(kvm->arch.model.fac_list, 148);
arch/s390/kvm/kvm-s390.c:713:				set_kvm_facility(kvm->arch.model.fac_mask, 152);
arch/s390/kvm/kvm-s390.c:714:				set_kvm_facility(kvm->arch.model.fac_list, 152);
arch/s390/kvm/kvm-s390.c:719:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:725:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:726:		if (kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:729:			set_kvm_facility(kvm->arch.model.fac_mask, 64);
arch/s390/kvm/kvm-s390.c:730:			set_kvm_facility(kvm->arch.model.fac_list, 64);
arch/s390/kvm/kvm-s390.c:733:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:738:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:739:		if (kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:742:			set_kvm_facility(kvm->arch.model.fac_mask, 72);
arch/s390/kvm/kvm-s390.c:743:			set_kvm_facility(kvm->arch.model.fac_list, 72);
arch/s390/kvm/kvm-s390.c:746:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:752:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:753:		if (kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:756:			set_kvm_facility(kvm->arch.model.fac_mask, 133);
arch/s390/kvm/kvm-s390.c:757:			set_kvm_facility(kvm->arch.model.fac_list, 133);
arch/s390/kvm/kvm-s390.c:760:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:765:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:766:		if (kvm->created_vcpus)
arch/s390/kvm/kvm-s390.c:768:		else if (!hpage || kvm->arch.use_cmma || kvm_is_ucontrol(kvm))
arch/s390/kvm/kvm-s390.c:772:			mmap_write_lock(kvm->mm);
arch/s390/kvm/kvm-s390.c:773:			kvm->mm->context.allow_gmap_hpage_1m = 1;
arch/s390/kvm/kvm-s390.c:774:			mmap_write_unlock(kvm->mm);
arch/s390/kvm/kvm-s390.c:780:			kvm->arch.use_skf = 0;
arch/s390/kvm/kvm-s390.c:781:			kvm->arch.use_pfmfi = 0;
arch/s390/kvm/kvm-s390.c:783:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:789:		kvm->arch.user_stsi = 1;
arch/s390/kvm/kvm-s390.c:794:		kvm->arch.user_instr0 = 1;
arch/s390/kvm/kvm-s390.c:813:			 kvm->arch.mem_limit);
arch/s390/kvm/kvm-s390.c:814:		if (put_user(kvm->arch.mem_limit, (u64 __user *)attr->addr))
arch/s390/kvm/kvm-s390.c:835:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:836:		if (kvm->created_vcpus)
arch/s390/kvm/kvm-s390.c:838:		else if (kvm->mm->context.allow_gmap_hpage_1m)
arch/s390/kvm/kvm-s390.c:841:			kvm->arch.use_cmma = 1;
arch/s390/kvm/kvm-s390.c:843:			kvm->arch.use_pfmfi = 0;
arch/s390/kvm/kvm-s390.c:846:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:853:		if (!kvm->arch.use_cmma)
arch/s390/kvm/kvm-s390.c:857:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:858:		idx = srcu_read_lock(&kvm->srcu);
arch/s390/kvm/kvm-s390.c:859:		s390_reset_cmma(kvm->arch.gmap->mm);
arch/s390/kvm/kvm-s390.c:860:		srcu_read_unlock(&kvm->srcu, idx);
arch/s390/kvm/kvm-s390.c:861:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:873:		if (kvm->arch.mem_limit != KVM_S390_NO_MEM_LIMIT &&
arch/s390/kvm/kvm-s390.c:874:		    new_limit > kvm->arch.mem_limit)
arch/s390/kvm/kvm-s390.c:885:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:886:		if (!kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:893:				gmap_remove(kvm->arch.gmap);
arch/s390/kvm/kvm-s390.c:895:				kvm->arch.gmap = new;
arch/s390/kvm/kvm-s390.c:899:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:902:			 (void *) kvm->arch.gmap->asce);
arch/s390/kvm/kvm-s390.c:932:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:936:			mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:940:			kvm->arch.crypto.crycb->aes_wrapping_key_mask,
arch/s390/kvm/kvm-s390.c:941:			sizeof(kvm->arch.crypto.crycb->aes_wrapping_key_mask));
arch/s390/kvm/kvm-s390.c:942:		kvm->arch.crypto.aes_kw = 1;
arch/s390/kvm/kvm-s390.c:947:			mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:951:			kvm->arch.crypto.crycb->dea_wrapping_key_mask,
arch/s390/kvm/kvm-s390.c:952:			sizeof(kvm->arch.crypto.crycb->dea_wrapping_key_mask));
arch/s390/kvm/kvm-s390.c:953:		kvm->arch.crypto.dea_kw = 1;
arch/s390/kvm/kvm-s390.c:958:			mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:961:		kvm->arch.crypto.aes_kw = 0;
arch/s390/kvm/kvm-s390.c:962:		memset(kvm->arch.crypto.crycb->aes_wrapping_key_mask, 0,
arch/s390/kvm/kvm-s390.c:963:			sizeof(kvm->arch.crypto.crycb->aes_wrapping_key_mask));
arch/s390/kvm/kvm-s390.c:968:			mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:971:		kvm->arch.crypto.dea_kw = 0;
arch/s390/kvm/kvm-s390.c:972:		memset(kvm->arch.crypto.crycb->dea_wrapping_key_mask, 0,
arch/s390/kvm/kvm-s390.c:973:			sizeof(kvm->arch.crypto.crycb->dea_wrapping_key_mask));
arch/s390/kvm/kvm-s390.c:978:			mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:981:		kvm->arch.crypto.apie = 1;
arch/s390/kvm/kvm-s390.c:985:			mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:988:		kvm->arch.crypto.apie = 0;
arch/s390/kvm/kvm-s390.c:991:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:996:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1010: * Must be called with kvm->srcu held to avoid races on memslots, and with
arch/s390/kvm/kvm-s390.c:1011: * kvm->slots_lock to avoid races with ourselves and kvm_s390_vm_stop_migration.
arch/s390/kvm/kvm-s390.c:1021:	if (kvm->arch.migration_mode)
arch/s390/kvm/kvm-s390.c:1027:	if (!kvm->arch.use_cmma) {
arch/s390/kvm/kvm-s390.c:1028:		kvm->arch.migration_mode = 1;
arch/s390/kvm/kvm-s390.c:1045:	atomic64_set(&kvm->arch.cmma_dirty_pages, ram_pages);
arch/s390/kvm/kvm-s390.c:1046:	kvm->arch.migration_mode = 1;
arch/s390/kvm/kvm-s390.c:1052: * Must be called with kvm->slots_lock to avoid races with ourselves and
arch/s390/kvm/kvm-s390.c:1058:	if (!kvm->arch.migration_mode)
arch/s390/kvm/kvm-s390.c:1060:	kvm->arch.migration_mode = 0;
arch/s390/kvm/kvm-s390.c:1061:	if (kvm->arch.use_cmma)
arch/s390/kvm/kvm-s390.c:1071:	mutex_lock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:1082:	mutex_unlock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:1090:	u64 mig = kvm->arch.migration_mode;
arch/s390/kvm/kvm-s390.c:1178:	gtod->tod = clk.tod + kvm->arch.epoch;
arch/s390/kvm/kvm-s390.c:1181:		gtod->epoch_idx = clk.ei + kvm->arch.epdx;
arch/s390/kvm/kvm-s390.c:1257:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1258:	if (kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:1269:		kvm->arch.model.cpuid = proc->cpuid;
arch/s390/kvm/kvm-s390.c:1274:				kvm->arch.model.ibc = unblocked_ibc;
arch/s390/kvm/kvm-s390.c:1276:				kvm->arch.model.ibc = lowest_ibc;
arch/s390/kvm/kvm-s390.c:1278:				kvm->arch.model.ibc = proc->ibc;
arch/s390/kvm/kvm-s390.c:1280:		memcpy(kvm->arch.model.fac_list, proc->fac_list,
arch/s390/kvm/kvm-s390.c:1283:			 kvm->arch.model.ibc,
arch/s390/kvm/kvm-s390.c:1284:			 kvm->arch.model.cpuid);
arch/s390/kvm/kvm-s390.c:1286:			 kvm->arch.model.fac_list[0],
arch/s390/kvm/kvm-s390.c:1287:			 kvm->arch.model.fac_list[1],
arch/s390/kvm/kvm-s390.c:1288:			 kvm->arch.model.fac_list[2]);
arch/s390/kvm/kvm-s390.c:1293:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1309:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1310:	if (kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:1311:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1314:	bitmap_copy(kvm->arch.cpu_feat, (unsigned long *) data.feat,
arch/s390/kvm/kvm-s390.c:1316:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1327:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1328:	if (kvm->created_vcpus) {
arch/s390/kvm/kvm-s390.c:1329:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1333:	if (copy_from_user(&kvm->arch.model.subfuncs, (void __user *)attr->addr,
arch/s390/kvm/kvm-s390.c:1335:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1338:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:1341:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[0],
arch/s390/kvm/kvm-s390.c:1342:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[1],
arch/s390/kvm/kvm-s390.c:1343:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[2],
arch/s390/kvm/kvm-s390.c:1344:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[3]);
arch/s390/kvm/kvm-s390.c:1346:		 ((unsigned long *) &kvm->arch.model.subfuncs.ptff)[0],
arch/s390/kvm/kvm-s390.c:1347:		 ((unsigned long *) &kvm->arch.model.subfuncs.ptff)[1]);
arch/s390/kvm/kvm-s390.c:1349:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmac)[0],
arch/s390/kvm/kvm-s390.c:1350:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmac)[1]);
arch/s390/kvm/kvm-s390.c:1352:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmc)[0],
arch/s390/kvm/kvm-s390.c:1353:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmc)[1]);
arch/s390/kvm/kvm-s390.c:1355:		 ((unsigned long *) &kvm->arch.model.subfuncs.km)[0],
arch/s390/kvm/kvm-s390.c:1356:		 ((unsigned long *) &kvm->arch.model.subfuncs.km)[1]);
arch/s390/kvm/kvm-s390.c:1358:		 ((unsigned long *) &kvm->arch.model.subfuncs.kimd)[0],
arch/s390/kvm/kvm-s390.c:1359:		 ((unsigned long *) &kvm->arch.model.subfuncs.kimd)[1]);
arch/s390/kvm/kvm-s390.c:1361:		 ((unsigned long *) &kvm->arch.model.subfuncs.klmd)[0],
arch/s390/kvm/kvm-s390.c:1362:		 ((unsigned long *) &kvm->arch.model.subfuncs.klmd)[1]);
arch/s390/kvm/kvm-s390.c:1364:		 ((unsigned long *) &kvm->arch.model.subfuncs.pckmo)[0],
arch/s390/kvm/kvm-s390.c:1365:		 ((unsigned long *) &kvm->arch.model.subfuncs.pckmo)[1]);
arch/s390/kvm/kvm-s390.c:1367:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmctr)[0],
arch/s390/kvm/kvm-s390.c:1368:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmctr)[1]);
arch/s390/kvm/kvm-s390.c:1370:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmf)[0],
arch/s390/kvm/kvm-s390.c:1371:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmf)[1]);
arch/s390/kvm/kvm-s390.c:1373:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmo)[0],
arch/s390/kvm/kvm-s390.c:1374:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmo)[1]);
arch/s390/kvm/kvm-s390.c:1376:		 ((unsigned long *) &kvm->arch.model.subfuncs.pcc)[0],
arch/s390/kvm/kvm-s390.c:1377:		 ((unsigned long *) &kvm->arch.model.subfuncs.pcc)[1]);
arch/s390/kvm/kvm-s390.c:1379:		 ((unsigned long *) &kvm->arch.model.subfuncs.ppno)[0],
arch/s390/kvm/kvm-s390.c:1380:		 ((unsigned long *) &kvm->arch.model.subfuncs.ppno)[1]);
arch/s390/kvm/kvm-s390.c:1382:		 ((unsigned long *) &kvm->arch.model.subfuncs.kma)[0],
arch/s390/kvm/kvm-s390.c:1383:		 ((unsigned long *) &kvm->arch.model.subfuncs.kma)[1]);
arch/s390/kvm/kvm-s390.c:1385:		 ((unsigned long *) &kvm->arch.model.subfuncs.kdsa)[0],
arch/s390/kvm/kvm-s390.c:1386:		 ((unsigned long *) &kvm->arch.model.subfuncs.kdsa)[1]);
arch/s390/kvm/kvm-s390.c:1388:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[0],
arch/s390/kvm/kvm-s390.c:1389:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[1],
arch/s390/kvm/kvm-s390.c:1390:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[2],
arch/s390/kvm/kvm-s390.c:1391:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[3]);
arch/s390/kvm/kvm-s390.c:1393:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[0],
arch/s390/kvm/kvm-s390.c:1394:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[1],
arch/s390/kvm/kvm-s390.c:1395:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[2],
arch/s390/kvm/kvm-s390.c:1396:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[3]);
arch/s390/kvm/kvm-s390.c:1429:	proc->cpuid = kvm->arch.model.cpuid;
arch/s390/kvm/kvm-s390.c:1430:	proc->ibc = kvm->arch.model.ibc;
arch/s390/kvm/kvm-s390.c:1431:	memcpy(&proc->fac_list, kvm->arch.model.fac_list,
arch/s390/kvm/kvm-s390.c:1434:		 kvm->arch.model.ibc,
arch/s390/kvm/kvm-s390.c:1435:		 kvm->arch.model.cpuid);
arch/s390/kvm/kvm-s390.c:1437:		 kvm->arch.model.fac_list[0],
arch/s390/kvm/kvm-s390.c:1438:		 kvm->arch.model.fac_list[1],
arch/s390/kvm/kvm-s390.c:1439:		 kvm->arch.model.fac_list[2]);
arch/s390/kvm/kvm-s390.c:1459:	memcpy(&mach->fac_mask, kvm->arch.model.fac_mask,
arch/s390/kvm/kvm-s390.c:1464:		 kvm->arch.model.ibc,
arch/s390/kvm/kvm-s390.c:1465:		 kvm->arch.model.cpuid);
arch/s390/kvm/kvm-s390.c:1486:	bitmap_copy((unsigned long *) data.feat, kvm->arch.cpu_feat,
arch/s390/kvm/kvm-s390.c:1517:	if (copy_to_user((void __user *)attr->addr, &kvm->arch.model.subfuncs,
arch/s390/kvm/kvm-s390.c:1522:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[0],
arch/s390/kvm/kvm-s390.c:1523:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[1],
arch/s390/kvm/kvm-s390.c:1524:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[2],
arch/s390/kvm/kvm-s390.c:1525:		 ((unsigned long *) &kvm->arch.model.subfuncs.plo)[3]);
arch/s390/kvm/kvm-s390.c:1527:		 ((unsigned long *) &kvm->arch.model.subfuncs.ptff)[0],
arch/s390/kvm/kvm-s390.c:1528:		 ((unsigned long *) &kvm->arch.model.subfuncs.ptff)[1]);
arch/s390/kvm/kvm-s390.c:1530:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmac)[0],
arch/s390/kvm/kvm-s390.c:1531:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmac)[1]);
arch/s390/kvm/kvm-s390.c:1533:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmc)[0],
arch/s390/kvm/kvm-s390.c:1534:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmc)[1]);
arch/s390/kvm/kvm-s390.c:1536:		 ((unsigned long *) &kvm->arch.model.subfuncs.km)[0],
arch/s390/kvm/kvm-s390.c:1537:		 ((unsigned long *) &kvm->arch.model.subfuncs.km)[1]);
arch/s390/kvm/kvm-s390.c:1539:		 ((unsigned long *) &kvm->arch.model.subfuncs.kimd)[0],
arch/s390/kvm/kvm-s390.c:1540:		 ((unsigned long *) &kvm->arch.model.subfuncs.kimd)[1]);
arch/s390/kvm/kvm-s390.c:1542:		 ((unsigned long *) &kvm->arch.model.subfuncs.klmd)[0],
arch/s390/kvm/kvm-s390.c:1543:		 ((unsigned long *) &kvm->arch.model.subfuncs.klmd)[1]);
arch/s390/kvm/kvm-s390.c:1545:		 ((unsigned long *) &kvm->arch.model.subfuncs.pckmo)[0],
arch/s390/kvm/kvm-s390.c:1546:		 ((unsigned long *) &kvm->arch.model.subfuncs.pckmo)[1]);
arch/s390/kvm/kvm-s390.c:1548:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmctr)[0],
arch/s390/kvm/kvm-s390.c:1549:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmctr)[1]);
arch/s390/kvm/kvm-s390.c:1551:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmf)[0],
arch/s390/kvm/kvm-s390.c:1552:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmf)[1]);
arch/s390/kvm/kvm-s390.c:1554:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmo)[0],
arch/s390/kvm/kvm-s390.c:1555:		 ((unsigned long *) &kvm->arch.model.subfuncs.kmo)[1]);
arch/s390/kvm/kvm-s390.c:1557:		 ((unsigned long *) &kvm->arch.model.subfuncs.pcc)[0],
arch/s390/kvm/kvm-s390.c:1558:		 ((unsigned long *) &kvm->arch.model.subfuncs.pcc)[1]);
arch/s390/kvm/kvm-s390.c:1560:		 ((unsigned long *) &kvm->arch.model.subfuncs.ppno)[0],
arch/s390/kvm/kvm-s390.c:1561:		 ((unsigned long *) &kvm->arch.model.subfuncs.ppno)[1]);
arch/s390/kvm/kvm-s390.c:1563:		 ((unsigned long *) &kvm->arch.model.subfuncs.kma)[0],
arch/s390/kvm/kvm-s390.c:1564:		 ((unsigned long *) &kvm->arch.model.subfuncs.kma)[1]);
arch/s390/kvm/kvm-s390.c:1566:		 ((unsigned long *) &kvm->arch.model.subfuncs.kdsa)[0],
arch/s390/kvm/kvm-s390.c:1567:		 ((unsigned long *) &kvm->arch.model.subfuncs.kdsa)[1]);
arch/s390/kvm/kvm-s390.c:1569:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[0],
arch/s390/kvm/kvm-s390.c:1570:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[1],
arch/s390/kvm/kvm-s390.c:1571:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[2],
arch/s390/kvm/kvm-s390.c:1572:		 ((unsigned long *) &kvm->arch.model.subfuncs.sortl)[3]);
arch/s390/kvm/kvm-s390.c:1574:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[0],
arch/s390/kvm/kvm-s390.c:1575:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[1],
arch/s390/kvm/kvm-s390.c:1576:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[2],
arch/s390/kvm/kvm-s390.c:1577:		 ((unsigned long *) &kvm->arch.model.subfuncs.dfltcc)[3]);
arch/s390/kvm/kvm-s390.c:1825:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/s390/kvm/kvm-s390.c:1837:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/s390/kvm/kvm-s390.c:1883:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/s390/kvm/kvm-s390.c:1908:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/s390/kvm/kvm-s390.c:1973:		if (get_pgste(kvm->mm, hva, &pgstev) < 0)
arch/s390/kvm/kvm-s390.c:2032:			atomic64_dec(&kvm->arch.cmma_dirty_pages);
arch/s390/kvm/kvm-s390.c:2033:		if (get_pgste(kvm->mm, hva, &pgstev) < 0)
arch/s390/kvm/kvm-s390.c:2073:	if (!kvm->arch.use_cmma)
arch/s390/kvm/kvm-s390.c:2080:	if (!peek && !kvm->arch.migration_mode)
arch/s390/kvm/kvm-s390.c:2084:	if (!bufsize || !kvm->mm->context.uses_cmm) {
arch/s390/kvm/kvm-s390.c:2089:	if (!peek && !atomic64_read(&kvm->arch.cmma_dirty_pages)) {
arch/s390/kvm/kvm-s390.c:2098:	mmap_read_lock(kvm->mm);
arch/s390/kvm/kvm-s390.c:2099:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/s390/kvm/kvm-s390.c:2104:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/s390/kvm/kvm-s390.c:2105:	mmap_read_unlock(kvm->mm);
arch/s390/kvm/kvm-s390.c:2107:	if (kvm->arch.migration_mode)
arch/s390/kvm/kvm-s390.c:2108:		args->remaining = atomic64_read(&kvm->arch.cmma_dirty_pages);
arch/s390/kvm/kvm-s390.c:2133:	if (!kvm->arch.use_cmma)
arch/s390/kvm/kvm-s390.c:2155:	mmap_read_lock(kvm->mm);
arch/s390/kvm/kvm-s390.c:2156:	srcu_idx = srcu_read_lock(&kvm->srcu);
arch/s390/kvm/kvm-s390.c:2167:		set_pgste_bits(kvm->mm, hva, mask, pgstev);
arch/s390/kvm/kvm-s390.c:2169:	srcu_read_unlock(&kvm->srcu, srcu_idx);
arch/s390/kvm/kvm-s390.c:2170:	mmap_read_unlock(kvm->mm);
arch/s390/kvm/kvm-s390.c:2172:	if (!kvm->mm->context.uses_cmm) {
arch/s390/kvm/kvm-s390.c:2173:		mmap_write_lock(kvm->mm);
arch/s390/kvm/kvm-s390.c:2174:		kvm->mm->context.uses_cmm = 1;
arch/s390/kvm/kvm-s390.c:2175:		mmap_write_unlock(kvm->mm);
arch/s390/kvm/kvm-s390.c:2263:		set_bit(IRQ_PEND_EXT_SERVICE, &kvm->arch.float_int.masked_irqs);
arch/s390/kvm/kvm-s390.c:2282:		clear_bit(IRQ_PEND_EXT_SERVICE, &kvm->arch.float_int.masked_irqs);
arch/s390/kvm/kvm-s390.c:2320:		if (!kvm_s390_pv_is_protected(kvm) || !mm_is_protected(kvm->mm))
arch/s390/kvm/kvm-s390.c:2392:		if (kvm->arch.use_irqchip) {
arch/s390/kvm/kvm-s390.c:2446:		mutex_lock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:2448:		mutex_unlock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:2462:		mutex_lock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:2464:		mutex_unlock(&kvm->slots_lock);
arch/s390/kvm/kvm-s390.c:2471:		kvm->arch.user_cpu_state_ctrl = 1;
arch/s390/kvm/kvm-s390.c:2485:		mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2487:		mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2523:	kvm->arch.crypto.crycbd = (__u32)(unsigned long) kvm->arch.crypto.crycb;
arch/s390/kvm/kvm-s390.c:2526:	kvm->arch.crypto.crycbd &= ~(CRYCB_FORMAT_MASK);
arch/s390/kvm/kvm-s390.c:2533:		kvm->arch.crypto.crycbd |= CRYCB_FORMAT2;
arch/s390/kvm/kvm-s390.c:2535:		kvm->arch.crypto.crycbd |= CRYCB_FORMAT1;
arch/s390/kvm/kvm-s390.c:2541:	struct kvm_s390_crypto_cb *crycb = kvm->arch.crypto.crycb;
arch/s390/kvm/kvm-s390.c:2543:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2546:	switch (kvm->arch.crypto.crycbd & CRYCB_FORMAT_MASK) {
arch/s390/kvm/kvm-s390.c:2574:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2580:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2583:	memset(&kvm->arch.crypto.crycb->apcb0, 0,
arch/s390/kvm/kvm-s390.c:2584:	       sizeof(kvm->arch.crypto.crycb->apcb0));
arch/s390/kvm/kvm-s390.c:2585:	memset(&kvm->arch.crypto.crycb->apcb1, 0,
arch/s390/kvm/kvm-s390.c:2586:	       sizeof(kvm->arch.crypto.crycb->apcb1));
arch/s390/kvm/kvm-s390.c:2592:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2607:	kvm->arch.crypto.crycb = &kvm->arch.sie_page2->crycb;
arch/s390/kvm/kvm-s390.c:2614:	kvm->arch.crypto.aes_kw = 1;
arch/s390/kvm/kvm-s390.c:2615:	kvm->arch.crypto.dea_kw = 1;
arch/s390/kvm/kvm-s390.c:2616:	get_random_bytes(kvm->arch.crypto.crycb->aes_wrapping_key_mask,
arch/s390/kvm/kvm-s390.c:2617:			 sizeof(kvm->arch.crypto.crycb->aes_wrapping_key_mask));
arch/s390/kvm/kvm-s390.c:2618:	get_random_bytes(kvm->arch.crypto.crycb->dea_wrapping_key_mask,
arch/s390/kvm/kvm-s390.c:2619:			 sizeof(kvm->arch.crypto.crycb->dea_wrapping_key_mask));
arch/s390/kvm/kvm-s390.c:2624:	if (kvm->arch.use_esca)
arch/s390/kvm/kvm-s390.c:2625:		free_pages_exact(kvm->arch.sca, sizeof(struct esca_block));
arch/s390/kvm/kvm-s390.c:2627:		free_page((unsigned long)(kvm->arch.sca));
arch/s390/kvm/kvm-s390.c:2628:	kvm->arch.sca = NULL;
arch/s390/kvm/kvm-s390.c:2657:	rwlock_init(&kvm->arch.sca_lock);
arch/s390/kvm/kvm-s390.c:2659:	kvm->arch.sca = (struct bsca_block *) get_zeroed_page(alloc_flags);
arch/s390/kvm/kvm-s390.c:2660:	if (!kvm->arch.sca)
arch/s390/kvm/kvm-s390.c:2666:	kvm->arch.sca = (struct bsca_block *)
arch/s390/kvm/kvm-s390.c:2667:			((char *) kvm->arch.sca + sca_offset);
arch/s390/kvm/kvm-s390.c:2670:	sprintf(debug_name, "kvm-%u", current->pid);
arch/s390/kvm/kvm-s390.c:2672:	kvm->arch.dbf = debug_register(debug_name, 32, 1, 7 * sizeof(long));
arch/s390/kvm/kvm-s390.c:2673:	if (!kvm->arch.dbf)
arch/s390/kvm/kvm-s390.c:2677:	kvm->arch.sie_page2 =
arch/s390/kvm/kvm-s390.c:2679:	if (!kvm->arch.sie_page2)
arch/s390/kvm/kvm-s390.c:2682:	kvm->arch.sie_page2->kvm = kvm;
arch/s390/kvm/kvm-s390.c:2683:	kvm->arch.model.fac_list = kvm->arch.sie_page2->fac_list;
arch/s390/kvm/kvm-s390.c:2686:		kvm->arch.model.fac_mask[i] = S390_lowcore.stfle_fac_list[i] &
arch/s390/kvm/kvm-s390.c:2689:		kvm->arch.model.fac_list[i] = S390_lowcore.stfle_fac_list[i] &
arch/s390/kvm/kvm-s390.c:2692:	kvm->arch.model.subfuncs = kvm_s390_available_subfunc;
arch/s390/kvm/kvm-s390.c:2695:	set_kvm_facility(kvm->arch.model.fac_mask, 138);
arch/s390/kvm/kvm-s390.c:2696:	set_kvm_facility(kvm->arch.model.fac_list, 138);
arch/s390/kvm/kvm-s390.c:2698:	set_kvm_facility(kvm->arch.model.fac_mask, 74);
arch/s390/kvm/kvm-s390.c:2699:	set_kvm_facility(kvm->arch.model.fac_list, 74);
arch/s390/kvm/kvm-s390.c:2701:		set_kvm_facility(kvm->arch.model.fac_mask, 147);
arch/s390/kvm/kvm-s390.c:2702:		set_kvm_facility(kvm->arch.model.fac_list, 147);
arch/s390/kvm/kvm-s390.c:2706:		set_kvm_facility(kvm->arch.model.fac_mask, 65);
arch/s390/kvm/kvm-s390.c:2708:	kvm->arch.model.cpuid = kvm_s390_get_initial_cpuid();
arch/s390/kvm/kvm-s390.c:2709:	kvm->arch.model.ibc = sclp.ibc & 0x0fff;
arch/s390/kvm/kvm-s390.c:2713:	mutex_init(&kvm->arch.float_int.ais_lock);
arch/s390/kvm/kvm-s390.c:2714:	spin_lock_init(&kvm->arch.float_int.lock);
arch/s390/kvm/kvm-s390.c:2716:		INIT_LIST_HEAD(&kvm->arch.float_int.lists[i]);
arch/s390/kvm/kvm-s390.c:2717:	init_waitqueue_head(&kvm->arch.ipte_wq);
arch/s390/kvm/kvm-s390.c:2718:	mutex_init(&kvm->arch.ipte_mutex);
arch/s390/kvm/kvm-s390.c:2720:	debug_register_view(kvm->arch.dbf, &debug_sprintf_view);
arch/s390/kvm/kvm-s390.c:2724:		kvm->arch.gmap = NULL;
arch/s390/kvm/kvm-s390.c:2725:		kvm->arch.mem_limit = KVM_S390_NO_MEM_LIMIT;
arch/s390/kvm/kvm-s390.c:2728:			kvm->arch.mem_limit = TASK_SIZE_MAX;
arch/s390/kvm/kvm-s390.c:2730:			kvm->arch.mem_limit = min_t(unsigned long, TASK_SIZE_MAX,
arch/s390/kvm/kvm-s390.c:2732:		kvm->arch.gmap = gmap_create(current->mm, kvm->arch.mem_limit - 1);
arch/s390/kvm/kvm-s390.c:2733:		if (!kvm->arch.gmap)
arch/s390/kvm/kvm-s390.c:2735:		kvm->arch.gmap->private = kvm;
arch/s390/kvm/kvm-s390.c:2736:		kvm->arch.gmap->pfault_enabled = 0;
arch/s390/kvm/kvm-s390.c:2739:	kvm->arch.use_pfmfi = sclp.has_pfmfi;
arch/s390/kvm/kvm-s390.c:2740:	kvm->arch.use_skf = sclp.has_skey;
arch/s390/kvm/kvm-s390.c:2741:	spin_lock_init(&kvm->arch.start_stop_lock);
arch/s390/kvm/kvm-s390.c:2749:	free_page((unsigned long)kvm->arch.sie_page2);
arch/s390/kvm/kvm-s390.c:2750:	debug_unregister(kvm->arch.dbf);
arch/s390/kvm/kvm-s390.c:2770:	if (vcpu->kvm->arch.use_cmma)
arch/s390/kvm/kvm-s390.c:2786:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2787:	for (i = 0; i < atomic_read(&kvm->online_vcpus); i++)
arch/s390/kvm/kvm-s390.c:2788:		kvm->vcpus[i] = NULL;
arch/s390/kvm/kvm-s390.c:2790:	atomic_set(&kvm->online_vcpus, 0);
arch/s390/kvm/kvm-s390.c:2791:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2802:	 * We are already at the end of life and kvm->lock is not taken.
arch/s390/kvm/kvm-s390.c:2809:	debug_unregister(kvm->arch.dbf);
arch/s390/kvm/kvm-s390.c:2810:	free_page((unsigned long)kvm->arch.sie_page2);
arch/s390/kvm/kvm-s390.c:2812:		gmap_remove(kvm->arch.gmap);
arch/s390/kvm/kvm-s390.c:2834:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/kvm-s390.c:2835:	if (vcpu->kvm->arch.use_esca) {
arch/s390/kvm/kvm-s390.c:2836:		struct esca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/kvm-s390.c:2841:		struct bsca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/kvm-s390.c:2846:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/kvm-s390.c:2852:		struct bsca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/kvm-s390.c:2859:	read_lock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/kvm-s390.c:2860:	if (vcpu->kvm->arch.use_esca) {
arch/s390/kvm/kvm-s390.c:2861:		struct esca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/kvm-s390.c:2869:		struct bsca_block *sca = vcpu->kvm->arch.sca;
arch/s390/kvm/kvm-s390.c:2876:	read_unlock(&vcpu->kvm->arch.sca_lock);
arch/s390/kvm/kvm-s390.c:2899:	struct bsca_block *old_sca = kvm->arch.sca;
arch/s390/kvm/kvm-s390.c:2905:	if (kvm->arch.use_esca)
arch/s390/kvm/kvm-s390.c:2916:	write_lock(&kvm->arch.sca_lock);
arch/s390/kvm/kvm-s390.c:2925:	kvm->arch.sca = new_sca;
arch/s390/kvm/kvm-s390.c:2926:	kvm->arch.use_esca = 1;
arch/s390/kvm/kvm-s390.c:2928:	write_unlock(&kvm->arch.sca_lock);
arch/s390/kvm/kvm-s390.c:2934:		 old_sca, kvm->arch.sca);
arch/s390/kvm/kvm-s390.c:2952:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:2953:	rc = kvm->arch.use_esca ? 0 : sca_switch_to_extended(kvm);
arch/s390/kvm/kvm-s390.c:2954:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:3069:	mutex_lock(&vcpu->kvm->lock);
arch/s390/kvm/kvm-s390.c:3071:	vcpu->arch.sie_block->epoch = vcpu->kvm->arch.epoch;
arch/s390/kvm/kvm-s390.c:3072:	vcpu->arch.sie_block->epdx = vcpu->kvm->arch.epdx;
arch/s390/kvm/kvm-s390.c:3074:	mutex_unlock(&vcpu->kvm->lock);
arch/s390/kvm/kvm-s390.c:3076:		vcpu->arch.gmap = vcpu->kvm->arch.gmap;
arch/s390/kvm/kvm-s390.c:3079:	if (test_kvm_facility(vcpu->kvm, 74) || vcpu->kvm->arch.user_instr0)
arch/s390/kvm/kvm-s390.c:3087:	if (test_bit_inv(nr, (unsigned long *)&kvm->arch.model.subfuncs.pckmo) &&
arch/s390/kvm/kvm-s390.c:3110:	if (!vcpu->kvm->arch.crypto.apie && !test_kvm_facility(vcpu->kvm, 76))
arch/s390/kvm/kvm-s390.c:3113:	vcpu->arch.sie_block->crycbd = vcpu->kvm->arch.crypto.crycbd;
arch/s390/kvm/kvm-s390.c:3118:	if (vcpu->kvm->arch.crypto.apie)
arch/s390/kvm/kvm-s390.c:3122:	if (vcpu->kvm->arch.crypto.aes_kw) {
arch/s390/kvm/kvm-s390.c:3129:	if (vcpu->kvm->arch.crypto.dea_kw)
arch/s390/kvm/kvm-s390.c:3149:	struct kvm_s390_cpu_model *model = &vcpu->kvm->arch.model;
arch/s390/kvm/kvm-s390.c:3180:	if (test_kvm_facility(vcpu->kvm, 8) && vcpu->kvm->arch.use_pfmfi)
arch/s390/kvm/kvm-s390.c:3215:	if (vcpu->kvm->arch.use_cmma) {
arch/s390/kvm/kvm-s390.c:3227:	mutex_lock(&vcpu->kvm->lock);
arch/s390/kvm/kvm-s390.c:3233:	mutex_unlock(&vcpu->kvm->lock);
arch/s390/kvm/kvm-s390.c:3264:	vcpu->arch.sie_block->gd = (u32)(u64)vcpu->kvm->arch.gisa_int.origin;
arch/s390/kvm/kvm-s390.c:3758:	vcpu->kvm->arch.user_cpu_state_ctrl = 1;
arch/s390/kvm/kvm-s390.c:3855:		if ((vcpu->kvm->arch.use_cmma) &&
arch/s390/kvm/kvm-s390.c:3856:		    (vcpu->kvm->mm->context.uses_cmm))
arch/s390/kvm/kvm-s390.c:3876:	mutex_lock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:3881:	kvm->arch.epoch = gtod->tod - clk.tod;
arch/s390/kvm/kvm-s390.c:3882:	kvm->arch.epdx = 0;
arch/s390/kvm/kvm-s390.c:3884:		kvm->arch.epdx = gtod->epoch_idx - clk.ei;
arch/s390/kvm/kvm-s390.c:3885:		if (kvm->arch.epoch > gtod->tod)
arch/s390/kvm/kvm-s390.c:3886:			kvm->arch.epdx -= 1;
arch/s390/kvm/kvm-s390.c:3891:		vcpu->arch.sie_block->epoch = kvm->arch.epoch;
arch/s390/kvm/kvm-s390.c:3892:		vcpu->arch.sie_block->epdx  = kvm->arch.epdx;
arch/s390/kvm/kvm-s390.c:3897:	mutex_unlock(&kvm->lock);
arch/s390/kvm/kvm-s390.c:4023:	clear_bit(vcpu->vcpu_id, vcpu->kvm->arch.gisa_int.kicked_mask);
arch/s390/kvm/kvm-s390.c:4130:	 * We try to hold kvm->srcu during most of vcpu_run (except when run-
arch/s390/kvm/kvm-s390.c:4133:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/s390/kvm/kvm-s390.c:4140:		srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/s390/kvm/kvm-s390.c:4177:		vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/s390/kvm/kvm-s390.c:4182:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/s390/kvm/kvm-s390.c:4530:	spin_lock(&vcpu->kvm->arch.start_stop_lock);
arch/s390/kvm/kvm-s390.c:4531:	online_vcpus = atomic_read(&vcpu->kvm->online_vcpus);
arch/s390/kvm/kvm-s390.c:4537:			spin_unlock(&vcpu->kvm->arch.start_stop_lock);
arch/s390/kvm/kvm-s390.c:4543:		if (!is_vcpu_stopped(vcpu->kvm->vcpus[i]))
arch/s390/kvm/kvm-s390.c:4572:	spin_unlock(&vcpu->kvm->arch.start_stop_lock);
arch/s390/kvm/kvm-s390.c:4586:	spin_lock(&vcpu->kvm->arch.start_stop_lock);
arch/s390/kvm/kvm-s390.c:4587:	online_vcpus = atomic_read(&vcpu->kvm->online_vcpus);
arch/s390/kvm/kvm-s390.c:4593:			spin_unlock(&vcpu->kvm->arch.start_stop_lock);
arch/s390/kvm/kvm-s390.c:4605:		if (!is_vcpu_stopped(vcpu->kvm->vcpus[i])) {
arch/s390/kvm/kvm-s390.c:4607:			started_vcpu = vcpu->kvm->vcpus[i];
arch/s390/kvm/kvm-s390.c:4619:	spin_unlock(&vcpu->kvm->arch.start_stop_lock);
arch/s390/kvm/kvm-s390.c:4633:		if (!vcpu->kvm->arch.css_support) {
arch/s390/kvm/kvm-s390.c:4634:			vcpu->kvm->arch.css_support = 1;
arch/s390/kvm/kvm-s390.c:4738:	srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/s390/kvm/kvm-s390.c:4754:	srcu_read_unlock(&vcpu->kvm->srcu, srcu_idx);
arch/s390/kvm/kvm-s390.c:4799:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/s390/kvm/kvm-s390.c:4801:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/s390/kvm/kvm-s390.c:4988:	if (mem->guest_phys_addr + mem->memory_size > kvm->arch.mem_limit)
arch/s390/kvm/kvm-s390.c:5007:		rc = gmap_unmap_segment(kvm->arch.gmap, old->base_gfn * PAGE_SIZE,
arch/s390/kvm/kvm-s390.c:5011:		rc = gmap_unmap_segment(kvm->arch.gmap, old->base_gfn * PAGE_SIZE,
arch/s390/kvm/kvm-s390.c:5017:		rc = gmap_map_segment(kvm->arch.gmap, mem->userspace_addr,
arch/s390/kvm/trace-s390.h:8:#define TRACE_SYSTEM kvm-s390
arch/s390/kvm/vsie.c:22:#include "kvm-s390.h"
arch/s390/kvm/vsie.c:317:				 vcpu->kvm->arch.crypto.crycb,
arch/s390/kvm/vsie.c:342:			    vcpu->kvm->arch.crypto.crycb->dea_wrapping_key_mask;
arch/s390/kvm/vsie.c:370:	if (vcpu->kvm->arch.model.ibc && new_ibc) {
arch/s390/kvm/vsie.c:376:		if (scb_s->ibc > vcpu->kvm->arch.model.ibc)
arch/s390/kvm/vsie.c:377:			scb_s->ibc = vcpu->kvm->arch.model.ibc;
arch/s390/kvm/vsie.c:576:	for (i = 0; i < kvm->arch.vsie.page_count; i++) {
arch/s390/kvm/vsie.c:577:		page = READ_ONCE(kvm->arch.vsie.pages[i]);
arch/s390/kvm/vsie.c:1082:	__releases(vcpu->kvm->srcu)
arch/s390/kvm/vsie.c:1083:	__acquires(vcpu->kvm->srcu)
arch/s390/kvm/vsie.c:1092:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/s390/kvm/vsie.c:1134:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/s390/kvm/vsie.c:1227:	scb_s->epoch += vcpu->kvm->arch.epoch;
arch/s390/kvm/vsie.c:1230:		scb_s->epdx += vcpu->kvm->arch.epdx;
arch/s390/kvm/vsie.c:1231:		if (scb_s->epoch < vcpu->kvm->arch.epoch)
arch/s390/kvm/vsie.c:1315:	page = radix_tree_lookup(&kvm->arch.vsie.addr_to_page, addr >> 9);
arch/s390/kvm/vsie.c:1327:	nr_vcpus = atomic_read(&kvm->online_vcpus);
arch/s390/kvm/vsie.c:1329:	mutex_lock(&kvm->arch.vsie.mutex);
arch/s390/kvm/vsie.c:1330:	if (kvm->arch.vsie.page_count < nr_vcpus) {
arch/s390/kvm/vsie.c:1333:			mutex_unlock(&kvm->arch.vsie.mutex);
arch/s390/kvm/vsie.c:1337:		kvm->arch.vsie.pages[kvm->arch.vsie.page_count] = page;
arch/s390/kvm/vsie.c:1338:		kvm->arch.vsie.page_count++;
arch/s390/kvm/vsie.c:1342:			page = kvm->arch.vsie.pages[kvm->arch.vsie.next];
arch/s390/kvm/vsie.c:1346:			kvm->arch.vsie.next++;
arch/s390/kvm/vsie.c:1347:			kvm->arch.vsie.next %= nr_vcpus;
arch/s390/kvm/vsie.c:1349:		radix_tree_delete(&kvm->arch.vsie.addr_to_page, page->index >> 9);
arch/s390/kvm/vsie.c:1353:	if (radix_tree_insert(&kvm->arch.vsie.addr_to_page, addr >> 9, page)) {
arch/s390/kvm/vsie.c:1355:		mutex_unlock(&kvm->arch.vsie.mutex);
arch/s390/kvm/vsie.c:1358:	mutex_unlock(&kvm->arch.vsie.mutex);
arch/s390/kvm/vsie.c:1432:	mutex_init(&kvm->arch.vsie.mutex);
arch/s390/kvm/vsie.c:1433:	INIT_RADIX_TREE(&kvm->arch.vsie.addr_to_page, GFP_KERNEL_ACCOUNT);
arch/s390/kvm/vsie.c:1443:	mutex_lock(&kvm->arch.vsie.mutex);
arch/s390/kvm/vsie.c:1444:	for (i = 0; i < kvm->arch.vsie.page_count; i++) {
arch/s390/kvm/vsie.c:1445:		page = kvm->arch.vsie.pages[i];
arch/s390/kvm/vsie.c:1446:		kvm->arch.vsie.pages[i] = NULL;
arch/s390/kvm/vsie.c:1450:		radix_tree_delete(&kvm->arch.vsie.addr_to_page, page->index >> 9);
arch/s390/kvm/vsie.c:1453:	kvm->arch.vsie.page_count = 0;
arch/s390/kvm/vsie.c:1454:	mutex_unlock(&kvm->arch.vsie.mutex);
arch/x86/include/asm/kvm_page_track.h:14: * Write access on the head is protected by kvm->mmu_lock, read access
arch/x86/include/asm/kvm_host.h:1432:#include <asm/kvm-x86-ops.h>
arch/x86/include/asm/kvm_host.h:1439:#include <asm/kvm-x86-ops.h>
arch/x86/kernel/kvmclock.c:110:	pr_info("kvm-clock: using sched offset of %llu cycles",
arch/x86/kernel/kvmclock.c:167:	.name	= "kvm-clock",
arch/x86/kernel/kvmclock.c:186:	pr_info("kvm-clock: cpu %d, msr %llx, %s", smp_processor_id(), pa, txt);
arch/x86/kernel/kvmclock.c:312:	pr_info("kvm-clock: Using msrs %x and %x",
arch/x86/kernel/kvm.c:10:#define pr_fmt(fmt) "kvm-guest: " fmt
arch/x86/kernel/kvm.c:515:			WARN_ONCE(ret < 0, "kvm-guest: failed to send PV IPI: %ld",
arch/x86/kernel/kvm.c:526:		WARN_ONCE(ret < 0, "kvm-guest: failed to send PV IPI: %ld",
arch/x86/kvm/Makefile:12:kvm-y			+= $(KVM)/kvm_main.o $(KVM)/coalesced_mmio.o \
arch/x86/kvm/Makefile:15:kvm-$(CONFIG_KVM_ASYNC_PF)	+= $(KVM)/async_pf.o
arch/x86/kvm/Makefile:17:kvm-y			+= x86.o emulate.o i8259.o irq.o lapic.o \
arch/x86/kvm/Makefile:21:kvm-$(CONFIG_X86_64) += mmu/tdp_iter.o mmu/tdp_mmu.o
arch/x86/kvm/Makefile:22:kvm-$(CONFIG_KVM_XEN)	+= xen.o
arch/x86/kvm/Makefile:24:kvm-intel-y		+= vmx/vmx.o vmx/vmenter.o vmx/pmu_intel.o vmx/vmcs12.o \
arch/x86/kvm/Makefile:26:kvm-intel-$(CONFIG_X86_SGX_KVM)	+= vmx/sgx.o
arch/x86/kvm/Makefile:28:kvm-amd-y		+= svm/svm.o svm/vmenter.o svm/pmu.o svm/nested.o svm/avic.o svm/sev.o
arch/x86/kvm/Makefile:31:obj-$(CONFIG_KVM_INTEL)	+= kvm-intel.o
arch/x86/kvm/Makefile:32:obj-$(CONFIG_KVM_AMD)	+= kvm-amd.o
arch/x86/kvm/Kconfig:85:	  will be called kvm-intel.
arch/x86/kvm/Kconfig:107:	  will be called kvm-amd.
arch/x86/kvm/i8254.c:220:	struct kvm_pit *pit = vcpu->kvm->arch.vpit;
arch/x86/kvm/i8254.c:262:	if (atomic_read(&kvm->arch.vapics_in_nmi_mode) > 0)
arch/x86/kvm/i8254.c:681:	pit->worker = kthread_create_worker(0, "kvm-pit/%d", pid_nr);
arch/x86/kvm/i8254.c:701:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/i8254.c:716:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/i8254.c:723:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/i8254.c:735:	struct kvm_pit *pit = kvm->arch.vpit;
arch/x86/kvm/i8254.c:738:		mutex_lock(&kvm->slots_lock);
arch/x86/kvm/i8254.c:741:		mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/hyperv.h:55:	return &kvm->arch.hyperv;
arch/x86/kvm/hyperv.h:79:	return &vcpu->kvm->arch.hyperv.hv_syndbg;
arch/x86/kvm/i8259.c:237:	struct kvm_pic *s = kvm->arch.vpic;
arch/x86/kvm/i8259.c:563:	struct kvm_pic *s = kvm->arch.vpic;
arch/x86/kvm/i8259.c:606:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/i8259.c:620:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/i8259.c:622:	kvm->arch.vpic = s;
arch/x86/kvm/i8259.c:633:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/i8259.c:642:	struct kvm_pic *vpic = kvm->arch.vpic;
arch/x86/kvm/i8259.c:647:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/i8259.c:651:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/i8259.c:653:	kvm->arch.vpic = NULL;
arch/x86/kvm/hyperv.c:187:	idx = srcu_read_lock(&kvm->irq_srcu);
arch/x86/kvm/hyperv.c:191:	srcu_read_unlock(&kvm->irq_srcu, idx);
arch/x86/kvm/hyperv.c:492:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
arch/x86/kvm/hyperv.c:493:					lockdep_is_held(&kvm->irq_lock));
arch/x86/kvm/hyperv.c:1199:	idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/hyperv.c:1203:	srcu_read_unlock(&kvm->srcu, idx);
arch/x86/kvm/hyperv.c:1879:	/* the eventfd is protected by vcpu->kvm->srcu, but conn_to_evt isn't */
arch/x86/kvm/hyperv.c:2093:	synchronize_srcu(&kvm->srcu);
arch/x86/kvm/ioapic.c:113:	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
arch/x86/kvm/ioapic.c:142:	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
arch/x86/kvm/ioapic.c:281:	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
arch/x86/kvm/ioapic.c:553:	struct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;
arch/x86/kvm/ioapic.c:695:	kvm->arch.vioapic = ioapic;
arch/x86/kvm/ioapic.c:699:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/ioapic.c:702:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/ioapic.c:704:		kvm->arch.vioapic = NULL;
arch/x86/kvm/ioapic.c:713:	struct kvm_ioapic *ioapic = kvm->arch.vioapic;
arch/x86/kvm/ioapic.c:719:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/ioapic.c:721:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/ioapic.c:722:	kvm->arch.vioapic = NULL;
arch/x86/kvm/ioapic.c:728:	struct kvm_ioapic *ioapic = kvm->arch.vioapic;
arch/x86/kvm/ioapic.c:738:	struct kvm_ioapic *ioapic = kvm->arch.vioapic;
arch/x86/kvm/irq.c:69:		return v->kvm->arch.vpic->output;
arch/x86/kvm/irq.c:118:		return v->kvm->arch.xen.upcall_vector;
arch/x86/kvm/irq.h:70:	int mode = kvm->arch.irqchip_mode;
arch/x86/kvm/irq.h:79:	int mode = kvm->arch.irqchip_mode;
arch/x86/kvm/irq.h:93:	int mode = kvm->arch.irqchip_mode;
arch/x86/kvm/mmu/mmu_audit.c:30:		fmt, audit_point_name[kvm->arch.audit_point], ##args)
arch/x86/kvm/mmu/mmu_audit.c:89:	list_for_each_entry(sp, &kvm->arch.active_mmu_pages, link)
arch/x86/kvm/mmu/mmu_audit.c:170:	if (vcpu->kvm->arch.audit_point == AUDIT_POST_SYNC && sp->unsync)
arch/x86/kvm/mmu/mmu_audit.c:246:	vcpu->kvm->arch.audit_point = point;
arch/x86/kvm/mmu/mmutrace.h:293:		__entry->mmu_valid_gen = kvm->arch.mmu_valid_gen;
arch/x86/kvm/mmu/mmutrace.h:294:		__entry->mmu_used_pages = kvm->arch.n_used_mmu_pages;
arch/x86/kvm/mmu/mmutrace.h:297:	TP_printk("kvm-mmu-valid-gen %u used_pages %x",
arch/x86/kvm/mmu/mmu.c:755:	kvm->arch.indirect_shadow_pages++;
arch/x86/kvm/mmu/mmu.c:773:	++kvm->stat.nx_lpage_splits;
arch/x86/kvm/mmu/mmu.c:775:		      &kvm->arch.lpage_disallowed_mmu_pages);
arch/x86/kvm/mmu/mmu.c:785:	kvm->arch.indirect_shadow_pages--;
arch/x86/kvm/mmu/mmu.c:798:	--kvm->stat.nx_lpage_splits;
arch/x86/kvm/mmu/mmu.c:1069:		--kvm->stat.lpages;
arch/x86/kvm/mmu/mmu.c:1543: * kvm->arch.n_used_mmu_pages values.  We need a global,
arch/x86/kvm/mmu/mmu.c:1549:	kvm->arch.n_used_mmu_pages += nr;
arch/x86/kvm/mmu/mmu.c:1606:	sp->mmu_valid_gen = vcpu->kvm->arch.mmu_valid_gen;
arch/x86/kvm/mmu/mmu.c:1607:	list_add(&sp->link, &vcpu->kvm->arch.active_mmu_pages);
arch/x86/kvm/mmu/mmu.c:1733:	--kvm->stat.mmu_unsync;
arch/x86/kvm/mmu/mmu.c:1804:	       unlikely(sp->mmu_valid_gen != kvm->arch.mmu_valid_gen);
arch/x86/kvm/mmu/mmu.c:1929:		if (need_resched() || rwlock_needbreak(&vcpu->kvm->mmu_lock)) {
arch/x86/kvm/mmu/mmu.c:1931:			cond_resched_rwlock_write(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:1978:	sp_list = &vcpu->kvm->arch.mmu_page_hash[kvm_page_table_hashfn(gfn)];
arch/x86/kvm/mmu/mmu.c:2015:	++vcpu->kvm->stat.mmu_cache_miss;
arch/x86/kvm/mmu/mmu.c:2039:	if (collisions > vcpu->kvm->stat.max_mmu_page_hash_collisions)
arch/x86/kvm/mmu/mmu.c:2040:		vcpu->kvm->stat.max_mmu_page_hash_collisions = collisions;
arch/x86/kvm/mmu/mmu.c:2158:				--kvm->stat.lpages;
arch/x86/kvm/mmu/mmu.c:2233:	++kvm->stat.mmu_shadow_zapped;
arch/x86/kvm/mmu/mmu.c:2326:	if (list_empty(&kvm->arch.active_mmu_pages))
arch/x86/kvm/mmu/mmu.c:2330:	list_for_each_entry_safe_reverse(sp, tmp, &kvm->arch.active_mmu_pages, link) {
arch/x86/kvm/mmu/mmu.c:2350:	kvm->stat.mmu_recycled += total_zapped;
arch/x86/kvm/mmu/mmu.c:2356:	if (kvm->arch.n_max_mmu_pages > kvm->arch.n_used_mmu_pages)
arch/x86/kvm/mmu/mmu.c:2357:		return kvm->arch.n_max_mmu_pages -
arch/x86/kvm/mmu/mmu.c:2358:			kvm->arch.n_used_mmu_pages;
arch/x86/kvm/mmu/mmu.c:2392:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:2394:	if (kvm->arch.n_used_mmu_pages > goal_nr_mmu_pages) {
arch/x86/kvm/mmu/mmu.c:2395:		kvm_mmu_zap_oldest_mmu_pages(kvm, kvm->arch.n_used_mmu_pages -
arch/x86/kvm/mmu/mmu.c:2398:		goal_nr_mmu_pages = kvm->arch.n_used_mmu_pages;
arch/x86/kvm/mmu/mmu.c:2401:	kvm->arch.n_max_mmu_pages = goal_nr_mmu_pages;
arch/x86/kvm/mmu/mmu.c:2403:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:2414:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:2422:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:2445:	++vcpu->kvm->stat.mmu_unsync;
arch/x86/kvm/mmu/mmu.c:2600:		++vcpu->kvm->stat.lpages;
arch/x86/kvm/mmu/mmu.c:2697:	if (unlikely(vcpu->kvm->mmu_notifier_count))
arch/x86/kvm/mmu/mmu.c:2723:	pte = lookup_address_in_mm(kvm->mm, hva, &level);
arch/x86/kvm/mmu/mmu.c:3153:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3179:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3214:	write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3249:	write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3283:	write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3345:	write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3433:		write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3439:		write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3443:	write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3457:	write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3742:	mmu_seq = vcpu->kvm->mmu_notifier_seq;
arch/x86/kvm/mmu/mmu.c:3755:		read_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3757:		write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3774:		read_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:3776:		write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5024:	if (!READ_ONCE(vcpu->kvm->arch.indirect_shadow_pages))
arch/x86/kvm/mmu/mmu.c:5038:	write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5042:	++vcpu->kvm->stat.mmu_pte_write;
arch/x86/kvm/mmu/mmu.c:5049:			++vcpu->kvm->stat.mmu_flooded;
arch/x86/kvm/mmu/mmu.c:5062:				++vcpu->kvm->stat.mmu_pde_zapped;
arch/x86/kvm/mmu/mmu.c:5070:	write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5251:		if (need_resched() || rwlock_needbreak(&kvm->mmu_lock)) {
arch/x86/kvm/mmu/mmu.c:5258:			cond_resched_rwlock_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5381:	      &kvm->arch.active_mmu_pages, link) {
arch/x86/kvm/mmu/mmu.c:5404:		    cond_resched_rwlock_write(&kvm->mmu_lock)) {
arch/x86/kvm/mmu/mmu.c:5410:				&kvm->arch.zapped_obsolete_pages, &nr_zapped)) {
arch/x86/kvm/mmu/mmu.c:5421:	kvm_mmu_commit_zap_page(kvm, &kvm->arch.zapped_obsolete_pages);
arch/x86/kvm/mmu/mmu.c:5435:	lockdep_assert_held(&kvm->slots_lock);
arch/x86/kvm/mmu/mmu.c:5437:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5447:	kvm->arch.mmu_valid_gen = kvm->arch.mmu_valid_gen ? 0 : 1;
arch/x86/kvm/mmu/mmu.c:5470:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5473:		read_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5475:		read_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5481:	return unlikely(!list_empty_careful(&kvm->arch.zapped_obsolete_pages));
arch/x86/kvm/mmu/mmu.c:5493:	struct kvm_page_track_notifier_node *node = &kvm->arch.mmu_sp_tracker;
arch/x86/kvm/mmu/mmu.c:5504:	struct kvm_page_track_notifier_node *node = &kvm->arch.mmu_sp_tracker;
arch/x86/kvm/mmu/mmu.c:5518:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5539:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5544:		read_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5552:		read_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5569:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5572:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5575:		read_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5577:		read_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5642:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5647:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5652:		read_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5656:		read_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5670:	lockdep_assert_held(&kvm->slots_lock);
arch/x86/kvm/mmu/mmu.c:5680:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5682:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5685:		read_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5687:		read_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5706:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5708:	list_for_each_entry_safe(sp, node, &kvm->arch.active_mmu_pages, link) {
arch/x86/kvm/mmu/mmu.c:5713:		if (cond_resched_rwlock_write(&kvm->mmu_lock))
arch/x86/kvm/mmu/mmu.c:5722:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5772:		 * n_used_mmu_pages is accessed without holding kvm->mmu_lock
arch/x86/kvm/mmu/mmu.c:5777:		if (!kvm->arch.n_used_mmu_pages &&
arch/x86/kvm/mmu/mmu.c:5781:		idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/mmu/mmu.c:5782:		write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5786:			      &kvm->arch.zapped_obsolete_pages);
arch/x86/kvm/mmu/mmu.c:5793:		write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5794:		srcu_read_unlock(&kvm->srcu, idx);
arch/x86/kvm/mmu/mmu.c:5801:		list_move_tail(&kvm->vm_list, &vm_list);
arch/x86/kvm/mmu/mmu.c:5861:			mutex_lock(&kvm->slots_lock);
arch/x86/kvm/mmu/mmu.c:5863:			mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/mmu/mmu.c:5865:			wake_up_process(kvm->arch.nx_lpage_recovery_thread);
arch/x86/kvm/mmu/mmu.c:5975:			wake_up_process(kvm->arch.nx_lpage_recovery_thread);
arch/x86/kvm/mmu/mmu.c:5992:	rcu_idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/mmu/mmu.c:5993:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:5996:	to_zap = ratio ? DIV_ROUND_UP(kvm->stat.nx_lpage_splits, ratio) : 0;
arch/x86/kvm/mmu/mmu.c:5998:		if (list_empty(&kvm->arch.lpage_disallowed_mmu_pages))
arch/x86/kvm/mmu/mmu.c:6006:		sp = list_first_entry(&kvm->arch.lpage_disallowed_mmu_pages,
arch/x86/kvm/mmu/mmu.c:6017:		if (need_resched() || rwlock_needbreak(&kvm->mmu_lock)) {
arch/x86/kvm/mmu/mmu.c:6019:			cond_resched_rwlock_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:6025:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/mmu.c:6026:	srcu_read_unlock(&kvm->srcu, rcu_idx);
arch/x86/kvm/mmu/mmu.c:6066:					  "kvm-nx-lpage-recovery",
arch/x86/kvm/mmu/mmu.c:6067:					  &kvm->arch.nx_lpage_recovery_thread);
arch/x86/kvm/mmu/mmu.c:6069:		kthread_unpark(kvm->arch.nx_lpage_recovery_thread);
arch/x86/kvm/mmu/mmu.c:6076:	if (kvm->arch.nx_lpage_recovery_thread)
arch/x86/kvm/mmu/mmu.c:6077:		kthread_stop(kvm->arch.nx_lpage_recovery_thread);
arch/x86/kvm/mmu/page_track.c:78: * It should be called under the protection both of mmu-lock and kvm->srcu
arch/x86/kvm/mmu/page_track.c:79: * or kvm->slots_lock.
arch/x86/kvm/mmu/page_track.c:113: * It should be called under the protection both of mmu-lock and kvm->srcu
arch/x86/kvm/mmu/page_track.c:114: * or kvm->slots_lock.
arch/x86/kvm/mmu/page_track.c:162:	head = &kvm->arch.track_notifier_head;
arch/x86/kvm/mmu/page_track.c:170:	head = &kvm->arch.track_notifier_head;
arch/x86/kvm/mmu/page_track.c:185:	head = &kvm->arch.track_notifier_head;
arch/x86/kvm/mmu/page_track.c:187:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/page_track.c:189:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/page_track.c:203:	head = &kvm->arch.track_notifier_head;
arch/x86/kvm/mmu/page_track.c:205:	write_lock(&kvm->mmu_lock);
arch/x86/kvm/mmu/page_track.c:207:	write_unlock(&kvm->mmu_lock);
arch/x86/kvm/mmu/page_track.c:226:	head = &vcpu->kvm->arch.track_notifier_head;
arch/x86/kvm/mmu/page_track.c:252:	head = &kvm->arch.track_notifier_head;
arch/x86/kvm/mmu/paging_tmpl.h:612:	if (unlikely(vcpu->kvm->mmu_notifier_count))
arch/x86/kvm/mmu/paging_tmpl.h:853:	mmu_seq = vcpu->kvm->mmu_notifier_seq;
arch/x86/kvm/mmu/paging_tmpl.h:884:	write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/paging_tmpl.h:897:	write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/paging_tmpl.h:935:	write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/paging_tmpl.h:970:	write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/mmu/paging_tmpl.h:1030: *   And we increase kvm->tlbs_dirty to delay tlbs flush in this case.
arch/x86/kvm/mmu/paging_tmpl.h:1066:			vcpu->kvm->tlbs_dirty++;
arch/x86/kvm/mmu/paging_tmpl.h:1086:			vcpu->kvm->tlbs_dirty++;
arch/x86/kvm/mmu/tdp_mmu.h:45:	lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.h:85:static inline bool is_tdp_mmu_enabled(struct kvm *kvm) { return kvm->arch.tdp_mmu_enabled; }
arch/x86/kvm/pmu.c:190:	filter = srcu_dereference(kvm->arch.pmu_event_filter, &kvm->srcu);
arch/x86/kvm/pmu.c:251:	filter = srcu_dereference(kvm->arch.pmu_event_filter, &kvm->srcu);
arch/x86/kvm/pmu.c:348:			vcpu->kvm->arch.kvmclock_offset;
arch/x86/kvm/pmu.c:521:	mutex_lock(&kvm->lock);
arch/x86/kvm/pmu.c:522:	filter = rcu_replace_pointer(kvm->arch.pmu_event_filter, filter,
arch/x86/kvm/pmu.c:523:				     mutex_is_locked(&kvm->lock));
arch/x86/kvm/pmu.c:524:	mutex_unlock(&kvm->lock);
arch/x86/kvm/pmu.c:526:	synchronize_srcu_expedited(&kvm->srcu);
arch/x86/kvm/svm/svm.c:4428:		kvm->arch.pause_in_guest = true;
arch/x86/kvm/svm/avic.c:237:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/svm/avic.c:241:	 * memory region. So, we need to ensure that kvm->mm == current->mm.
arch/x86/kvm/svm/avic.c:243:	if ((kvm->arch.apic_access_page_done == activate) ||
arch/x86/kvm/svm/avic.c:244:	    (kvm->mm != current->mm))
arch/x86/kvm/svm/avic.c:256:	kvm->arch.apic_access_page_done = activate;
arch/x86/kvm/svm/avic.c:258:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/svm/avic.c:599:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/x86/kvm/svm/avic.c:602:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/svm/avic.c:826:	idx = srcu_read_lock(&kvm->irq_srcu);
arch/x86/kvm/svm/avic.c:827:	irq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
arch/x86/kvm/svm/avic.c:909:	srcu_read_unlock(&kvm->irq_srcu, idx);
arch/x86/kvm/svm/sev.c:236:	if (kvm->created_vcpus)
arch/x86/kvm/svm/sev.c:387:	lockdep_assert_held(&kvm->lock);
arch/x86/kvm/svm/sev.c:1516:	mutex_lock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1594:	mutex_unlock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1619:	mutex_lock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1623:		mutex_unlock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1631:	mutex_unlock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1682:	mutex_lock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1704:	mutex_unlock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1708:	mutex_unlock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1727:	mutex_lock(&source_kvm->lock);
arch/x86/kvm/svm/sev.c:1749:	mutex_unlock(&source_kvm->lock);
arch/x86/kvm/svm/sev.c:1750:	mutex_lock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1763:	mutex_unlock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1767:	mutex_unlock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1771:	mutex_unlock(&source_kvm->lock);
arch/x86/kvm/svm/sev.c:1793:	mutex_lock(&kvm->lock);
arch/x86/kvm/svm/sev.c:1814:	mutex_unlock(&kvm->lock);
arch/x86/kvm/mmu/tdp_mmu.c:23:	kvm->arch.tdp_mmu_enabled = true;
arch/x86/kvm/mmu/tdp_mmu.c:25:	INIT_LIST_HEAD(&kvm->arch.tdp_mmu_roots);
arch/x86/kvm/mmu/tdp_mmu.c:26:	spin_lock_init(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:27:	INIT_LIST_HEAD(&kvm->arch.tdp_mmu_pages);
arch/x86/kvm/mmu/tdp_mmu.c:34:		lockdep_assert_held_read(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:36:		lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:41:	if (!kvm->arch.tdp_mmu_enabled)
arch/x86/kvm/mmu/tdp_mmu.c:44:	WARN_ON(!list_empty(&kvm->arch.tdp_mmu_roots));
arch/x86/kvm/mmu/tdp_mmu.c:91:	spin_lock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:93:	spin_unlock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:116:		next_root = list_next_or_null_rcu(&kvm->arch.tdp_mmu_roots,
arch/x86/kvm/mmu/tdp_mmu.c:120:		next_root = list_first_or_null_rcu(&kvm->arch.tdp_mmu_roots,
arch/x86/kvm/mmu/tdp_mmu.c:124:		next_root = list_next_or_null_rcu(&kvm->arch.tdp_mmu_roots,
arch/x86/kvm/mmu/tdp_mmu.c:153:	list_for_each_entry_rcu(_root, &_kvm->arch.tdp_mmu_roots, link,		\
arch/x86/kvm/mmu/tdp_mmu.c:154:				lockdep_is_held_type(&kvm->mmu_lock, 0) ||	\
arch/x86/kvm/mmu/tdp_mmu.c:155:				lockdep_is_held(&kvm->arch.tdp_mmu_pages_lock))	\
arch/x86/kvm/mmu/tdp_mmu.c:197:	lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:211:	spin_lock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:212:	list_add_rcu(&root->link, &kvm->arch.tdp_mmu_roots);
arch/x86/kvm/mmu/tdp_mmu.c:213:	spin_unlock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:267:		spin_lock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:269:		lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:271:	list_add(&sp->link, &kvm->arch.tdp_mmu_pages);
arch/x86/kvm/mmu/tdp_mmu.c:276:		spin_unlock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:292:		spin_lock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:294:		lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:301:		spin_unlock(&kvm->arch.tdp_mmu_pages_lock);
arch/x86/kvm/mmu/tdp_mmu.c:449:			atomic64_sub(1, (atomic64_t*)&kvm->stat.lpages);
arch/x86/kvm/mmu/tdp_mmu.c:451:			atomic64_add(1, (atomic64_t*)&kvm->stat.lpages);
arch/x86/kvm/mmu/tdp_mmu.c:519:	lockdep_assert_held_read(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:600:	lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:681:	if (need_resched() || rwlock_needbreak(&kvm->mmu_lock)) {
arch/x86/kvm/mmu/tdp_mmu.c:688:			cond_resched_rwlock_read(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:690:			cond_resched_rwlock_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:813:		next_root = list_next_or_null_rcu(&kvm->arch.tdp_mmu_roots,
arch/x86/kvm/mmu/tdp_mmu.c:817:		next_root = list_first_or_null_rcu(&kvm->arch.tdp_mmu_roots,
arch/x86/kvm/mmu/tdp_mmu.c:822:		next_root = list_next_or_null_rcu(&kvm->arch.tdp_mmu_roots,
arch/x86/kvm/mmu/tdp_mmu.c:844:	lockdep_assert_held_read(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:899:	lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:900:	list_for_each_entry(root, &kvm->arch.tdp_mmu_roots, link)
arch/x86/kvm/mmu/tdp_mmu.c:1250:	lockdep_assert_held_read(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:1320:	lockdep_assert_held_read(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:1387:	lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:1451:	lockdep_assert_held_read(&kvm->mmu_lock);
arch/x86/kvm/mmu/tdp_mmu.c:1500:	lockdep_assert_held_write(&kvm->mmu_lock);
arch/x86/kvm/vmx/posted_intr.c:275:	    !kvm_vcpu_apicv_active(kvm->vcpus[0]))
arch/x86/kvm/vmx/posted_intr.c:278:	idx = srcu_read_lock(&kvm->irq_srcu);
arch/x86/kvm/vmx/posted_intr.c:279:	irq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
arch/x86/kvm/vmx/posted_intr.c:344:	srcu_read_unlock(&kvm->irq_srcu, idx);
arch/x86/kvm/vmx/sgx.c:170:	if (!vcpu->kvm->arch.sgx_provisioning_allowed &&
arch/x86/kvm/vmx/sgx.c:437:	if (!vcpu->kvm->arch.sgx_provisioning_allowed)
arch/x86/kvm/x86.h:297:	return !(kvm->arch.disabled_quirks & quirk);
arch/x86/kvm/x86.h:380:	return kvm->arch.mwait_in_guest;
arch/x86/kvm/x86.h:385:	return kvm->arch.hlt_in_guest;
arch/x86/kvm/x86.h:390:	return kvm->arch.pause_in_guest;
arch/x86/kvm/x86.h:395:	return kvm->arch.cstate_in_guest;
arch/x86/kvm/xen.c:29:	int idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/xen.c:31:	ret = kvm_gfn_to_hva_cache_init(kvm, &kvm->arch.xen.shinfo_cache,
arch/x86/kvm/xen.c:36:	kvm->arch.xen.shinfo_set = true;
arch/x86/kvm/xen.c:52:	if (kvm->arch.xen.long_mode) {
arch/x86/kvm/xen.c:62:	srcu_read_unlock(&kvm->srcu, idx);
arch/x86/kvm/xen.c:121:	if (v->kvm->arch.xen.long_mode)
arch/x86/kvm/xen.c:234:	mutex_lock(&kvm->lock);
arch/x86/kvm/xen.c:241:			kvm->arch.xen.long_mode = !!data->u.long_mode;
arch/x86/kvm/xen.c:248:			kvm->arch.xen.shinfo_set = false;
arch/x86/kvm/xen.c:260:			kvm->arch.xen.upcall_vector = data->u.vector;
arch/x86/kvm/xen.c:269:	mutex_unlock(&kvm->lock);
arch/x86/kvm/xen.c:277:	mutex_lock(&kvm->lock);
arch/x86/kvm/xen.c:281:		data->u.long_mode = kvm->arch.xen.long_mode;
arch/x86/kvm/xen.c:286:		if (kvm->arch.xen.shinfo_set)
arch/x86/kvm/xen.c:287:			data->u.shared_info.gfn = gpa_to_gfn(kvm->arch.xen.shinfo_cache.gpa);
arch/x86/kvm/xen.c:294:		data->u.vector = kvm->arch.xen.upcall_vector;
arch/x86/kvm/xen.c:302:	mutex_unlock(&kvm->lock);
arch/x86/kvm/xen.c:310:	mutex_lock(&vcpu->kvm->lock);
arch/x86/kvm/xen.c:311:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/xen.c:473:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/xen.c:474:	mutex_unlock(&vcpu->kvm->lock);
arch/x86/kvm/xen.c:482:	mutex_lock(&vcpu->kvm->lock);
arch/x86/kvm/xen.c:548:	mutex_unlock(&vcpu->kvm->lock);
arch/x86/kvm/xen.c:560:	vcpu->kvm->arch.xen.long_mode = lm;
arch/x86/kvm/xen.c:599:		hva_t blob_addr = lm ? kvm->arch.xen_hvm_config.blob_addr_64
arch/x86/kvm/xen.c:600:				     : kvm->arch.xen_hvm_config.blob_addr_32;
arch/x86/kvm/xen.c:601:		u8 blob_size = lm ? kvm->arch.xen_hvm_config.blob_size_64
arch/x86/kvm/xen.c:602:				  : kvm->arch.xen_hvm_config.blob_size_32;
arch/x86/kvm/xen.c:636:	mutex_lock(&kvm->lock);
arch/x86/kvm/xen.c:638:	if (xhc->msr && !kvm->arch.xen_hvm_config.msr)
arch/x86/kvm/xen.c:640:	else if (!xhc->msr && kvm->arch.xen_hvm_config.msr)
arch/x86/kvm/xen.c:643:	memcpy(&kvm->arch.xen_hvm_config, xhc, sizeof(*xhc));
arch/x86/kvm/xen.c:645:	mutex_unlock(&kvm->lock);
arch/x86/kvm/xen.c:651:	if (kvm->arch.xen_hvm_config.msr)
arch/x86/kvm/xen.h:29:		kvm->arch.xen_hvm_config.msr;
arch/x86/kvm/xen.h:35:		(kvm->arch.xen_hvm_config.flags &
arch/x86/kvm/xen.h:42:	    vcpu->arch.xen.vcpu_info_set && vcpu->kvm->arch.xen.upcall_vector)
arch/x86/kvm/vmx/vmx.c:3655:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/vmx/vmx.c:3684:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/vmx/vmx.c:3709:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/vmx/vmx.c:3710:	if (kvm->arch.apic_access_page_done)
arch/x86/kvm/vmx/vmx.c:3730:	kvm->arch.apic_access_page_done = true;
arch/x86/kvm/vmx/vmx.c:3732:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/vmx/vmx.c:4334:	if (!vcpu->kvm->arch.cpu_dirty_logging_count)
arch/x86/kvm/vmx/vmx.c:4376:	if (!vcpu->kvm->arch.bus_lock_detection_enabled)
arch/x86/kvm/vmx/vmx.c:4743:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/vmx/vmx.c:4746:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/vmx/vmx.c:6982:		kvm->arch.pause_in_guest = true;
arch/x86/kvm/vmx/vmx.c:7505:	if (vcpu->kvm->arch.cpu_dirty_logging_count)
arch/x86/kvm/irq_comm.c:32:	struct kvm_pic *pic = kvm->arch.vpic;
arch/x86/kvm/irq_comm.c:40:	struct kvm_ioapic *ioapic = kvm->arch.vioapic;
arch/x86/kvm/irq_comm.c:109:	trace_kvm_msi_set_irq(msg.address_lo | (kvm->arch.x2apic_format ?
arch/x86/kvm/irq_comm.c:112:	irq->dest_id = x86_msi_msg_get_destid(&msg, kvm->arch.x2apic_format);
arch/x86/kvm/irq_comm.c:126:	return kvm->arch.x2apic_format && (e->msi.address_hi & 0xff);
arch/x86/kvm/irq_comm.c:166:	mutex_lock(&kvm->lock);
arch/x86/kvm/irq_comm.c:168:	list_for_each_entry(vcpu, &kvm->online_vcpu_list, sched_stat_list) {
arch/x86/kvm/irq_comm.c:174:	list_for_each_entry(vcpu, &kvm->offline_vcpu_list, sched_stat_list) {
arch/x86/kvm/irq_comm.c:178:	mutex_unlock(&kvm->lock);
arch/x86/kvm/irq_comm.c:205:	unsigned long *bitmap = &kvm->arch.irq_sources_bitmap;
arch/x86/kvm/irq_comm.c:208:	mutex_lock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:221:	mutex_unlock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:231:	mutex_lock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:237:	clear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);
arch/x86/kvm/irq_comm.c:241:	kvm_ioapic_clear_all(kvm->arch.vioapic, irq_source_id);
arch/x86/kvm/irq_comm.c:242:	kvm_pic_clear_all(kvm->arch.vpic, irq_source_id);
arch/x86/kvm/irq_comm.c:244:	mutex_unlock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:250:	mutex_lock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:252:	hlist_add_head_rcu(&kimn->link, &kvm->arch.mask_notifier_list);
arch/x86/kvm/irq_comm.c:253:	mutex_unlock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:259:	mutex_lock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:261:	mutex_unlock(&kvm->irq_lock);
arch/x86/kvm/irq_comm.c:262:	synchronize_srcu(&kvm->irq_srcu);
arch/x86/kvm/irq_comm.c:271:	idx = srcu_read_lock(&kvm->irq_srcu);
arch/x86/kvm/irq_comm.c:274:		hlist_for_each_entry_rcu(kimn, &kvm->arch.mask_notifier_list, link)
arch/x86/kvm/irq_comm.c:277:	srcu_read_unlock(&kvm->irq_srcu, idx);
arch/x86/kvm/irq_comm.c:420:	idx = srcu_read_lock(&kvm->irq_srcu);
arch/x86/kvm/irq_comm.c:421:	table = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
arch/x86/kvm/irq_comm.c:423:			       kvm->arch.nr_reserved_ioapic_pins);
arch/x86/kvm/irq_comm.c:439:	srcu_read_unlock(&kvm->irq_srcu, idx);
arch/x86/kvm/lapic.c:191:	/* Read kvm->arch.apic_map_dirty before kvm->arch.apic_map.  */
arch/x86/kvm/lapic.c:192:	if (atomic_read_acquire(&kvm->arch.apic_map_dirty) == CLEAN)
arch/x86/kvm/lapic.c:195:	mutex_lock(&kvm->arch.apic_map_lock);
arch/x86/kvm/lapic.c:197:	 * Read kvm->arch.apic_map_dirty before kvm->arch.apic_map
arch/x86/kvm/lapic.c:200:	if (atomic_cmpxchg_acquire(&kvm->arch.apic_map_dirty,
arch/x86/kvm/lapic.c:203:		mutex_unlock(&kvm->arch.apic_map_lock);
arch/x86/kvm/lapic.c:267:	old = rcu_dereference_protected(kvm->arch.apic_map,
arch/x86/kvm/lapic.c:268:			lockdep_is_held(&kvm->arch.apic_map_lock));
arch/x86/kvm/lapic.c:269:	rcu_assign_pointer(kvm->arch.apic_map, new);
arch/x86/kvm/lapic.c:271:	 * Write kvm->arch.apic_map before clearing apic->apic_map_dirty.
arch/x86/kvm/lapic.c:274:	atomic_cmpxchg_release(&kvm->arch.apic_map_dirty,
arch/x86/kvm/lapic.c:276:	mutex_unlock(&kvm->arch.apic_map_lock);
arch/x86/kvm/lapic.c:297:		atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
arch/x86/kvm/lapic.c:308:	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
arch/x86/kvm/lapic.c:314:	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
arch/x86/kvm/lapic.c:320:	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
arch/x86/kvm/lapic.c:336:	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
arch/x86/kvm/lapic.c:641:	map = rcu_dereference(kvm->arch.apic_map);
arch/x86/kvm/lapic.c:832:	if (!vcpu->kvm->arch.x2apic_broadcast_quirk_disabled &&
arch/x86/kvm/lapic.c:882:	if (!kvm->arch.disabled_lapic_found) {
arch/x86/kvm/lapic.c:883:		kvm->arch.disabled_lapic_found = true;
arch/x86/kvm/lapic.c:892:	if (kvm->arch.x2apic_broadcast_quirk_disabled) {
arch/x86/kvm/lapic.c:998:	map = rcu_dereference(kvm->arch.apic_map);
arch/x86/kvm/lapic.c:1040:	map = rcu_dereference(kvm->arch.apic_map);
arch/x86/kvm/lapic.c:1177:	map = rcu_dereference(kvm->arch.apic_map);
arch/x86/kvm/lapic.c:1993:			atomic_inc(&apic->vcpu->kvm->arch.vapics_in_nmi_mode);
arch/x86/kvm/lapic.c:1995:			atomic_dec(&apic->vcpu->kvm->arch.vapics_in_nmi_mode);
arch/x86/kvm/lapic.c:2288:			atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
arch/x86/kvm/lapic.c:2575:		if (vcpu->kvm->arch.x2apic_format) {
arch/x86/kvm/lapic.c:2623:	atomic_set_release(&apic->vcpu->kvm->arch.apic_map_dirty, DIRTY);
arch/x86/kvm/x86.c:123:#include <asm/kvm-x86-ops.h>
arch/x86/kvm/x86.c:1258: * kvm-specific. Those are put in emulated_msrs_all; filtering of emulated_msrs
arch/x86/kvm/x86.c:1580:	idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/x86.c:1582:	msr_filter = srcu_dereference(kvm->arch.msr_filter, &kvm->srcu);
arch/x86/kvm/x86.c:1604:	srcu_read_unlock(&kvm->srcu, idx);
arch/x86/kvm/x86.c:1792:	if (!(vcpu->kvm->arch.user_space_msr_mask & msr_reason))
arch/x86/kvm/x86.c:2109:	struct kvm_arch *ka = &vcpu->kvm->arch;
arch/x86/kvm/x86.c:2269:	struct kvm_arch *ka = &vcpu->kvm->arch;
arch/x86/kvm/x86.c:2273:			 atomic_read(&vcpu->kvm->online_vcpus));
arch/x86/kvm/x86.c:2288:			    atomic_read(&vcpu->kvm->online_vcpus),
arch/x86/kvm/x86.c:2363:	raw_spin_lock_irqsave(&kvm->arch.tsc_write_lock, flags);
arch/x86/kvm/x86.c:2366:	elapsed = ns - kvm->arch.last_tsc_nsec;
arch/x86/kvm/x86.c:2377:			u64 tsc_exp = kvm->arch.last_tsc_write +
arch/x86/kvm/x86.c:2397:	    vcpu->arch.virtual_tsc_khz == kvm->arch.last_tsc_khz) {
arch/x86/kvm/x86.c:2399:			offset = kvm->arch.cur_tsc_offset;
arch/x86/kvm/x86.c:2406:		already_matched = (vcpu->arch.this_tsc_generation == kvm->arch.cur_tsc_generation);
arch/x86/kvm/x86.c:2415:		 * These values are tracked in kvm->arch.cur_xxx variables.
arch/x86/kvm/x86.c:2417:		kvm->arch.cur_tsc_generation++;
arch/x86/kvm/x86.c:2418:		kvm->arch.cur_tsc_nsec = ns;
arch/x86/kvm/x86.c:2419:		kvm->arch.cur_tsc_write = data;
arch/x86/kvm/x86.c:2420:		kvm->arch.cur_tsc_offset = offset;
arch/x86/kvm/x86.c:2428:	kvm->arch.last_tsc_nsec = ns;
arch/x86/kvm/x86.c:2429:	kvm->arch.last_tsc_write = data;
arch/x86/kvm/x86.c:2430:	kvm->arch.last_tsc_khz = vcpu->arch.virtual_tsc_khz;
arch/x86/kvm/x86.c:2435:	vcpu->arch.this_tsc_generation = kvm->arch.cur_tsc_generation;
arch/x86/kvm/x86.c:2436:	vcpu->arch.this_tsc_nsec = kvm->arch.cur_tsc_nsec;
arch/x86/kvm/x86.c:2437:	vcpu->arch.this_tsc_write = kvm->arch.cur_tsc_write;
arch/x86/kvm/x86.c:2440:	raw_spin_unlock_irqrestore(&kvm->arch.tsc_write_lock, flags);
arch/x86/kvm/x86.c:2442:	spin_lock_irqsave(&kvm->arch.pvclock_gtod_sync_lock, flags);
arch/x86/kvm/x86.c:2444:		kvm->arch.nr_vcpus_matched_tsc = 0;
arch/x86/kvm/x86.c:2446:		kvm->arch.nr_vcpus_matched_tsc++;
arch/x86/kvm/x86.c:2450:	spin_unlock_irqrestore(&kvm->arch.pvclock_gtod_sync_lock, flags);
arch/x86/kvm/x86.c:2633:	struct kvm_arch *ka = &kvm->arch;
arch/x86/kvm/x86.c:2638:			atomic_read(&kvm->online_vcpus));
arch/x86/kvm/x86.c:2671:	struct kvm_arch *ka = &kvm->arch;
arch/x86/kvm/x86.c:2694:	struct kvm_arch *ka = &kvm->arch;
arch/x86/kvm/x86.c:2788:	struct kvm_arch *ka = &v->kvm->arch;
arch/x86/kvm/x86.c:2857:	vcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;
arch/x86/kvm/x86.c:2915:	schedule_delayed_work(&kvm->arch.kvmclock_update_work,
arch/x86/kvm/x86.c:2931:	schedule_delayed_work(&kvm->arch.kvmclock_update_work, 0);
arch/x86/kvm/x86.c:2932:	schedule_delayed_work(&kvm->arch.kvmclock_sync_work,
arch/x86/kvm/x86.c:3153:	if (msr && msr == vcpu->kvm->arch.xen_hvm_config.msr)
arch/x86/kvm/x86.c:3280:		vcpu->kvm->arch.wall_clock = data;
arch/x86/kvm/x86.c:3287:		vcpu->kvm->arch.wall_clock = data;
arch/x86/kvm/x86.c:3616:		msr_info->data = vcpu->kvm->arch.wall_clock;
arch/x86/kvm/x86.c:3622:		msr_info->data = vcpu->kvm->arch.wall_clock;
arch/x86/kvm/x86.c:3735:		    !vcpu->kvm->arch.guest_can_read_msr_platform_info)
arch/x86/kvm/x86.c:4154:		if (!vcpu->kvm->arch.use_master_clock || vcpu->cpu == -1)
arch/x86/kvm/x86.c:4198:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:4203:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:4401:	if (!vcpu->kvm->arch.exception_payload_enabled &&
arch/x86/kvm/x86.c:4422:		if (!vcpu->kvm->arch.exception_payload_enabled)
arch/x86/kvm/x86.c:4454:	if (vcpu->kvm->arch.exception_payload_enabled)
arch/x86/kvm/x86.c:4473:		if (!vcpu->kvm->arch.exception_payload_enabled)
arch/x86/kvm/x86.c:4926:		int idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:4928:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:4932:		int idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:4934:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:4962:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:4964:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:5170:		idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:5172:		srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:5237:	mutex_lock(&kvm->slots_lock);
arch/x86/kvm/x86.c:5240:	kvm->arch.n_requested_mmu_pages = kvm_nr_mmu_pages;
arch/x86/kvm/x86.c:5242:	mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/x86.c:5248:	return kvm->arch.n_max_mmu_pages;
arch/x86/kvm/x86.c:5253:	struct kvm_pic *pic = kvm->arch.vpic;
arch/x86/kvm/x86.c:5278:	struct kvm_pic *pic = kvm->arch.vpic;
arch/x86/kvm/x86.c:5308:	struct kvm_kpit_state *kps = &kvm->arch.vpit->pit_state;
arch/x86/kvm/x86.c:5321:	struct kvm_pit *pit = kvm->arch.vpit;
arch/x86/kvm/x86.c:5333:	mutex_lock(&kvm->arch.vpit->pit_state.lock);
arch/x86/kvm/x86.c:5334:	memcpy(ps->channels, &kvm->arch.vpit->pit_state.channels,
arch/x86/kvm/x86.c:5336:	ps->flags = kvm->arch.vpit->pit_state.flags;
arch/x86/kvm/x86.c:5337:	mutex_unlock(&kvm->arch.vpit->pit_state.lock);
arch/x86/kvm/x86.c:5347:	struct kvm_pit *pit = kvm->arch.vpit;
arch/x86/kvm/x86.c:5367:	struct kvm_pit *pit = kvm->arch.vpit;
arch/x86/kvm/x86.c:5418:		kvm->arch.disabled_quirks = cap->args[0];
arch/x86/kvm/x86.c:5422:		mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5429:		if (kvm->created_vcpus)
arch/x86/kvm/x86.c:5436:		kvm->arch.irqchip_mode = KVM_IRQCHIP_SPLIT;
arch/x86/kvm/x86.c:5437:		kvm->arch.nr_reserved_ioapic_pins = cap->args[0];
arch/x86/kvm/x86.c:5440:		mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5449:			kvm->arch.x2apic_format = true;
arch/x86/kvm/x86.c:5451:			kvm->arch.x2apic_broadcast_quirk_disabled = true;
arch/x86/kvm/x86.c:5462:			kvm->arch.mwait_in_guest = true;
arch/x86/kvm/x86.c:5464:			kvm->arch.hlt_in_guest = true;
arch/x86/kvm/x86.c:5466:			kvm->arch.pause_in_guest = true;
arch/x86/kvm/x86.c:5468:			kvm->arch.cstate_in_guest = true;
arch/x86/kvm/x86.c:5472:		kvm->arch.guest_can_read_msr_platform_info = cap->args[0];
arch/x86/kvm/x86.c:5476:		kvm->arch.exception_payload_enabled = cap->args[0];
arch/x86/kvm/x86.c:5480:		kvm->arch.user_space_msr_mask = cap->args[0];
arch/x86/kvm/x86.c:5494:			kvm->arch.bus_lock_detection_enabled = true;
arch/x86/kvm/x86.c:5508:			kvm->arch.sgx_provisioning_allowed = true;
arch/x86/kvm/x86.c:5617:	mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5619:	/* The per-VM filter is protected by kvm->lock... */
arch/x86/kvm/x86.c:5620:	old_filter = srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1);
arch/x86/kvm/x86.c:5622:	rcu_assign_pointer(kvm->arch.msr_filter, new_filter);
arch/x86/kvm/x86.c:5623:	synchronize_srcu(&kvm->srcu);
arch/x86/kvm/x86.c:5628:	mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5657:		mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5659:		if (kvm->created_vcpus)
arch/x86/kvm/x86.c:5666:		mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5676:		mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5683:		if (kvm->created_vcpus)
arch/x86/kvm/x86.c:5702:		/* Write kvm->irq_routing before enabling irqchip_in_kernel. */
arch/x86/kvm/x86.c:5704:		kvm->arch.irqchip_mode = KVM_IRQCHIP_KERNEL;
arch/x86/kvm/x86.c:5706:		mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5718:		mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5720:		if (kvm->arch.vpit)
arch/x86/kvm/x86.c:5723:		kvm->arch.vpit = kvm_create_pit(kvm, u.pit_config.flags);
arch/x86/kvm/x86.c:5724:		if (kvm->arch.vpit)
arch/x86/kvm/x86.c:5727:		mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5776:		if (!kvm->arch.vpit)
arch/x86/kvm/x86.c:5791:		mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5793:		if (!kvm->arch.vpit)
arch/x86/kvm/x86.c:5797:		mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5802:		if (!kvm->arch.vpit)
arch/x86/kvm/x86.c:5817:		mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5819:		if (!kvm->arch.vpit)
arch/x86/kvm/x86.c:5823:		mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5832:		if (!kvm->arch.vpit)
arch/x86/kvm/x86.c:5839:		mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:5840:		if (kvm->created_vcpus)
arch/x86/kvm/x86.c:5843:			kvm->arch.bsp_vcpu_id = arg;
arch/x86/kvm/x86.c:5844:		mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:5877:		struct kvm_arch *ka = &kvm->arch;
arch/x86/kvm/x86.c:5905:		if (kvm->arch.use_master_clock)
arch/x86/kvm/x86.c:5921:		user_ns.flags = kvm->arch.use_master_clock ? KVM_CLOCK_TSC_STABLE : 0;
arch/x86/kvm/x86.c:7359:		write_lock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/x86.c:7360:		indirect_shadow_pages = vcpu->kvm->arch.indirect_shadow_pages;
arch/x86/kvm/x86.c:7361:		write_unlock(&vcpu->kvm->mmu_lock);
arch/x86/kvm/x86.c:7908:		struct kvm_arch *ka = &kvm->arch;
arch/x86/kvm/x86.c:8360:	return (READ_ONCE(kvm->arch.apicv_inhibit_reasons) == 0);
arch/x86/kvm/x86.c:8368:			  &kvm->arch.apicv_inhibit_reasons);
arch/x86/kvm/x86.c:8371:			&kvm->arch.apicv_inhibit_reasons);
arch/x86/kvm/x86.c:8386:	map = rcu_dereference(vcpu->kvm->arch.apic_map);
arch/x86/kvm/x86.c:9005: * In particular, kvm_request_apicv_update() expects kvm->srcu not to be
arch/x86/kvm/x86.c:9007: * synchronize_srcu(&kvm->srcu).
arch/x86/kvm/x86.c:9018:	old = READ_ONCE(kvm->arch.apicv_inhibit_reasons);
arch/x86/kvm/x86.c:9027:		old = cmpxchg(&kvm->arch.apicv_inhibit_reasons, expected, new);
arch/x86/kvm/x86.c:9134:	if (unlikely(vcpu->kvm->dirty_ring_size &&
arch/x86/kvm/x86.c:9300:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/x86/kvm/x86.c:9328:		vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:9431:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:9464:		srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
arch/x86/kvm/x86.c:9466:		vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/x86.c:9508:	vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/x86.c:9534:			srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
arch/x86/kvm/x86.c:9538:			vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
arch/x86/kvm/x86.c:9542:	srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
arch/x86/kvm/x86.c:9551:	vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:9553:	srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);
arch/x86/kvm/x86.c:10043:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:10048:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:10169:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:10171:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:10296:	if (kvm_check_tsc_unstable() && atomic_read(&kvm->online_vcpus) != 0)
arch/x86/kvm/x86.c:10422:		schedule_delayed_work(&kvm->arch.kvmclock_sync_work,
arch/x86/kvm/x86.c:10446:	idx = srcu_read_lock(&vcpu->kvm->srcu);
arch/x86/kvm/x86.c:10448:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
arch/x86/kvm/x86.c:10609:			kvm->arch.backwards_tsc_observed = true;
arch/x86/kvm/x86.c:10622:			kvm->arch.last_tsc_nsec = 0;
arch/x86/kvm/x86.c:10623:			kvm->arch.last_tsc_write = 0;
arch/x86/kvm/x86.c:10699:	return vcpu->kvm->arch.bsp_vcpu_id == vcpu->vcpu_id;
arch/x86/kvm/x86.c:10735:	INIT_HLIST_HEAD(&kvm->arch.mask_notifier_list);
arch/x86/kvm/x86.c:10736:	INIT_LIST_HEAD(&kvm->arch.active_mmu_pages);
arch/x86/kvm/x86.c:10737:	INIT_LIST_HEAD(&kvm->arch.zapped_obsolete_pages);
arch/x86/kvm/x86.c:10738:	INIT_LIST_HEAD(&kvm->arch.lpage_disallowed_mmu_pages);
arch/x86/kvm/x86.c:10739:	INIT_LIST_HEAD(&kvm->arch.assigned_dev_head);
arch/x86/kvm/x86.c:10740:	atomic_set(&kvm->arch.noncoherent_dma_count, 0);
arch/x86/kvm/x86.c:10743:	set_bit(KVM_USERSPACE_IRQ_SOURCE_ID, &kvm->arch.irq_sources_bitmap);
arch/x86/kvm/x86.c:10746:		&kvm->arch.irq_sources_bitmap);
arch/x86/kvm/x86.c:10748:	raw_spin_lock_init(&kvm->arch.tsc_write_lock);
arch/x86/kvm/x86.c:10749:	mutex_init(&kvm->arch.apic_map_lock);
arch/x86/kvm/x86.c:10750:	spin_lock_init(&kvm->arch.pvclock_gtod_sync_lock);
arch/x86/kvm/x86.c:10752:	kvm->arch.kvmclock_offset = -get_kvmclock_base_ns();
arch/x86/kvm/x86.c:10755:	kvm->arch.guest_can_read_msr_platform_info = true;
arch/x86/kvm/x86.c:10757:	INIT_DELAYED_WORK(&kvm->arch.kvmclock_update_work, kvmclock_update_fn);
arch/x86/kvm/x86.c:10758:	INIT_DELAYED_WORK(&kvm->arch.kvmclock_sync_work, kvmclock_sync_fn);
arch/x86/kvm/x86.c:10794:	mutex_lock(&kvm->lock);
arch/x86/kvm/x86.c:10795:	for (i = 0; i < atomic_read(&kvm->online_vcpus); i++)
arch/x86/kvm/x86.c:10796:		kvm->vcpus[i] = NULL;
arch/x86/kvm/x86.c:10798:	atomic_set(&kvm->online_vcpus, 0);
arch/x86/kvm/x86.c:10799:	mutex_unlock(&kvm->lock);
arch/x86/kvm/x86.c:10804:	cancel_delayed_work_sync(&kvm->arch.kvmclock_sync_work);
arch/x86/kvm/x86.c:10805:	cancel_delayed_work_sync(&kvm->arch.kvmclock_update_work);
arch/x86/kvm/x86.c:10841:	/* Called with kvm->slots_lock held.  */
arch/x86/kvm/x86.c:10893:	if (current->mm == kvm->mm) {
arch/x86/kvm/x86.c:10899:		mutex_lock(&kvm->slots_lock);
arch/x86/kvm/x86.c:10905:		mutex_unlock(&kvm->slots_lock);
arch/x86/kvm/x86.c:10908:	kvm_free_msr_filter(srcu_dereference_check(kvm->arch.msr_filter, &kvm->srcu, 1));
arch/x86/kvm/x86.c:10912:	kvfree(rcu_dereference_check(kvm->arch.apic_map, 1));
arch/x86/kvm/x86.c:10913:	kfree(srcu_dereference_check(kvm->arch.pmu_event_filter, &kvm->srcu, 1));
arch/x86/kvm/x86.c:11038:	struct kvm_arch *ka = &kvm->arch;
arch/x86/kvm/x86.c:11145:	if (!kvm->arch.n_requested_mmu_pages)
arch/x86/kvm/x86.c:11523:	if (atomic_inc_return(&kvm->arch.assigned_device_count) == 1)
arch/x86/kvm/x86.c:11530:	atomic_dec(&kvm->arch.assigned_device_count);
arch/x86/kvm/x86.c:11536:	return atomic_read(&kvm->arch.assigned_device_count);
arch/x86/kvm/x86.c:11542:	atomic_inc(&kvm->arch.noncoherent_dma_count);
arch/x86/kvm/x86.c:11548:	atomic_dec(&kvm->arch.noncoherent_dma_count);
arch/x86/kvm/x86.c:11554:	return atomic_read(&kvm->arch.noncoherent_dma_count);
drivers/gpu/drm/i915/gvt/kvmgt.c:1802:	idx = srcu_read_lock(&kvm->srcu);
drivers/gpu/drm/i915/gvt/kvmgt.c:1805:		srcu_read_unlock(&kvm->srcu, idx);
drivers/gpu/drm/i915/gvt/kvmgt.c:1809:	write_lock(&kvm->mmu_lock);
drivers/gpu/drm/i915/gvt/kvmgt.c:1818:	write_unlock(&kvm->mmu_lock);
drivers/gpu/drm/i915/gvt/kvmgt.c:1819:	srcu_read_unlock(&kvm->srcu, idx);
drivers/gpu/drm/i915/gvt/kvmgt.c:1836:	idx = srcu_read_lock(&kvm->srcu);
drivers/gpu/drm/i915/gvt/kvmgt.c:1839:		srcu_read_unlock(&kvm->srcu, idx);
drivers/gpu/drm/i915/gvt/kvmgt.c:1843:	write_lock(&kvm->mmu_lock);
drivers/gpu/drm/i915/gvt/kvmgt.c:1852:	write_unlock(&kvm->mmu_lock);
drivers/gpu/drm/i915/gvt/kvmgt.c:1853:	srcu_read_unlock(&kvm->srcu, idx);
drivers/gpu/drm/i915/gvt/kvmgt.c:1878:	write_lock(&kvm->mmu_lock);
drivers/gpu/drm/i915/gvt/kvmgt.c:1887:	write_unlock(&kvm->mmu_lock);
drivers/gpu/drm/i915/gvt/kvmgt.c:1926:	if (!kvm || kvm->mm != current->mm) {
drivers/gpu/drm/i915/gvt/kvmgt.c:2200:	idx = srcu_read_lock(&kvm->srcu);
drivers/gpu/drm/i915/gvt/kvmgt.c:2202:	srcu_read_unlock(&kvm->srcu, idx);
drivers/irqchip/irq-gic-v4.c:25: * agnostic actually means KVM-specific - what were you thinking?).
drivers/ptp/Makefile:7:ptp_kvm-$(CONFIG_X86)			:= ptp_kvm_x86.o ptp_kvm_common.o
drivers/ptp/Makefile:8:ptp_kvm-$(CONFIG_HAVE_ARM_SMCCC)	:= ptp_kvm_arm.o ptp_kvm_common.o
drivers/s390/crypto/vfio_ap_ops.c:224:	gisa = kvm->arch.gisa_int.origin;
drivers/s390/crypto/vfio_ap_ops.c:292:	if (!vcpu->kvm->arch.crypto.pqap_hook)
drivers/s390/crypto/vfio_ap_ops.c:294:	matrix_mdev = container_of(vcpu->kvm->arch.crypto.pqap_hook,
drivers/s390/crypto/vfio_ap_ops.c:1099: * The kvm->lock is taken to set the guest's AP configuration which, under
drivers/s390/crypto/vfio_ap_ops.c:1111:	if (kvm->arch.crypto.crycbd) {
drivers/s390/crypto/vfio_ap_ops.c:1125:		kvm->arch.crypto.pqap_hook = &matrix_mdev->pqap_hook;
drivers/s390/crypto/vfio_ap_ops.c:1173: * The kvm->lock is taken to clear the guest's AP configuration which, under
drivers/s390/crypto/vfio_ap_ops.c:1195:		matrix_mdev->kvm->arch.crypto.pqap_hook = NULL;
include/kvm/arm_psci.h:33:		if (vcpu->kvm->arch.psci_version)
include/kvm/arm_psci.h:34:			return vcpu->kvm->arch.psci_version;
include/linux/kvm_dirty_ring.h:84: * called with kvm->slots_lock held, returns the number of
include/linux/kvm_irqfd.h:27:	 * RCU list modified under kvm->irqfds.resampler_lock
include/linux/kvm_irqfd.h:32:	 * Entry in list of kvm->irqfd.resampler_list.  Use for sharing
include/linux/kvm_irqfd.h:34:	 * Accessed and modified under kvm->irqfds.resampler_lock
include/linux/kvm_host.h:291:	int vcpu_idx; /* index in kvm->vcpus array */
include/linux/kvm_host.h:538:	 * created_vcpus is protected by kvm->lock, and is incremented
include/linux/kvm_host.h:625:	return !!(kvm->manual_dirty_log_protect & KVM_DIRTY_LOG_INITIALLY_SET);
include/linux/kvm_host.h:630:	return srcu_dereference_check(kvm->buses[idx], &kvm->srcu,
include/linux/kvm_host.h:631:				      lockdep_is_held(&kvm->slots_lock) ||
include/linux/kvm_host.h:632:				      !refcount_read(&kvm->users_count));
include/linux/kvm_host.h:637:	int num_vcpus = atomic_read(&kvm->online_vcpus);
include/linux/kvm_host.h:642:	return kvm->vcpus[i];
include/linux/kvm_host.h:647:	     idx < atomic_read(&kvm->online_vcpus) && \
include/linux/kvm_host.h:721:	return srcu_dereference_check(kvm->memslots[as_id], &kvm->srcu,
include/linux/kvm_host.h:722:			lockdep_is_held(&kvm->slots_lock) ||
include/linux/kvm_host.h:723:			!refcount_read(&kvm->users_count));
include/linux/kvm_host.h:1278:	if (unlikely(kvm->mmu_notifier_count))
include/linux/kvm_host.h:1287:	 * rather than under kvm->mmu_lock, for scalability, so
include/linux/kvm_host.h:1288:	 * can't rely on kvm->mmu_lock to keep things ordered.
include/linux/kvm_host.h:1291:	if (kvm->mmu_notifier_seq != mmu_seq)
include/linux/kvm_host.h:1300:	lockdep_assert_held(&kvm->mmu_lock);
include/linux/kvm_host.h:1307:	if (unlikely(kvm->mmu_notifier_count) &&
include/linux/kvm_host.h:1308:	    hva >= kvm->mmu_notifier_range_start &&
include/linux/kvm_host.h:1309:	    hva < kvm->mmu_notifier_range_end)
include/linux/kvm_host.h:1311:	if (kvm->mmu_notifier_seq != mmu_seq)
include/linux/kvm_host.h:1443:	 * create is called holding kvm->lock and any operations not suitable
include/linux/kvm_host.h:1451:	 * outside of holding kvm->lock.
include/linux/kvm_host.h:1470:	 * the VM. kvm->lock is held.
tools/arch/arm/include/uapi/asm/kvm.h:213:/* KVM-as-firmware specific pseudo-registers */
tools/arch/arm64/include/uapi/asm/kvm.h:248:/* KVM-as-firmware specific pseudo-registers */
tools/build/feature/test-timerfd.c:3: * test for timerfd functions used by perf-kvm-stat-live
tools/lib/traceevent/plugins/Build:4:plugin_kvm-y          += plugin_kvm.o
tools/perf/arch/arm64/util/Build:6:perf-y += kvm-stat.o
tools/perf/arch/arm64/util/kvm-stat.c:5:#include "../../../util/kvm-stat.h"
tools/perf/arch/arm64/util/kvm-stat.c:83:	kvm->exit_reasons_isa = "arm64";
tools/perf/arch/powerpc/util/Build:3:perf-y += kvm-stat.o
tools/perf/arch/powerpc/util/kvm-stat.c:3:#include "util/kvm-stat.h"
tools/perf/arch/powerpc/util/kvm-stat.c:142:	kvm->exit_reasons = hv_exit_reasons;
tools/perf/arch/powerpc/util/kvm-stat.c:143:	kvm->exit_reasons_isa = "HV";
tools/perf/arch/powerpc/util/kvm-stat.c:171:		kvm->exit_reasons = NULL;
tools/perf/arch/powerpc/util/kvm-stat.c:172:		kvm->exit_reasons_isa = NULL;
tools/perf/arch/s390/util/Build:2:perf-y += kvm-stat.o
tools/perf/arch/s390/util/kvm-stat.c:11:#include "../../util/kvm-stat.h"
tools/perf/arch/s390/util/kvm-stat.c:105:		kvm->exit_reasons = sie_exit_reasons;
tools/perf/arch/s390/util/kvm-stat.c:106:		kvm->exit_reasons_isa = "SIE";
tools/perf/arch/x86/util/Build:4:perf-y += kvm-stat.o
tools/perf/arch/x86/util/kvm-stat.c:4:#include "../../../util/kvm-stat.h"
tools/perf/arch/x86/util/kvm-stat.c:159:		kvm->exit_reasons = vmx_exit_reasons;
tools/perf/arch/x86/util/kvm-stat.c:160:		kvm->exit_reasons_isa = "VMX";
tools/perf/arch/x86/util/kvm-stat.c:162:		kvm->exit_reasons = svm_exit_reasons;
tools/perf/arch/x86/util/kvm-stat.c:163:		kvm->exit_reasons_isa = "SVM";
tools/perf/builtin-kvm.c:25:#include "util/kvm-stat.h"
tools/perf/builtin-kvm.c:114:		(unsigned long long)exit_code, kvm->exit_reasons_isa);
tools/perf/builtin-kvm.c:133:		if (!strcmp(events_ops->name, kvm->report_event)) {
tools/perf/builtin-kvm.c:134:			kvm->events_ops = events_ops->ops;
tools/perf/builtin-kvm.c:154:		INIT_LIST_HEAD(&kvm->kvm_events_cache[i]);
tools/perf/builtin-kvm.c:234:	head = &kvm->kvm_events_cache[kvm_events_hash_fn(key->key)];
tools/perf/builtin-kvm.c:302:	child_ops = kvm->events_ops->child_ops;
tools/perf/builtin-kvm.c:352:	if (kvm->trace_vcpu == -1)
tools/perf/builtin-kvm.c:390:	if (kvm->duration && time_diff > kvm->duration) {
tools/perf/builtin-kvm.c:393:		kvm->events_ops->decode_key(kvm, &event->key, decode);
tools/perf/builtin-kvm.c:433:				 .exit_reasons = kvm->exit_reasons };
tools/perf/builtin-kvm.c:440:	if ((kvm->trace_vcpu != -1) &&
tools/perf/builtin-kvm.c:441:	    (kvm->trace_vcpu != vcpu_record->vcpu_id))
tools/perf/builtin-kvm.c:444:	if (kvm->events_ops->is_begin_event(evsel, sample, &key))
tools/perf/builtin-kvm.c:450:	if (kvm->events_ops->is_end_event(evsel, sample, &key))
tools/perf/builtin-kvm.c:497:		if (!strcmp(keys[i].name, kvm->sort_key)) {
tools/perf/builtin-kvm.c:498:			kvm->compare = keys[i].key;
tools/perf/builtin-kvm.c:503:	pr_err("Unknown compare key:%s\n", kvm->sort_key);
tools/perf/builtin-kvm.c:531:	int vcpu = kvm->trace_vcpu;
tools/perf/builtin-kvm.c:533:	kvm->total_count += get_event_count(event, vcpu);
tools/perf/builtin-kvm.c:534:	kvm->total_time += get_event_time(event, vcpu);
tools/perf/builtin-kvm.c:545:	int vcpu = kvm->trace_vcpu;
tools/perf/builtin-kvm.c:549:		list_for_each_entry(event, &kvm->kvm_events_cache[i], hash_entry) {
tools/perf/builtin-kvm.c:552:				insert_to_result(&kvm->result, event,
tools/perf/builtin-kvm.c:553:						 kvm->compare, vcpu);
tools/perf/builtin-kvm.c:573:	int vcpu = kvm->trace_vcpu;
tools/perf/builtin-kvm.c:577:	if (kvm->opts.target.system_wide)
tools/perf/builtin-kvm.c:579:	else if (kvm->opts.target.pid)
tools/perf/builtin-kvm.c:580:		pr_info("pid(s) %s, ", kvm->opts.target.pid);
tools/perf/builtin-kvm.c:610:	int vcpu = kvm->trace_vcpu;
tools/perf/builtin-kvm.c:612:	if (kvm->live) {
tools/perf/builtin-kvm.c:619:	pr_info("%*s ", decode_str_len, kvm->events_ops->name);
tools/perf/builtin-kvm.c:629:	while ((event = pop_from_result(&kvm->result))) {
tools/perf/builtin-kvm.c:637:		kvm->events_ops->decode_key(kvm, &event->key, decode);
tools/perf/builtin-kvm.c:640:		pr_info("%8.2f%% ", (double)ecount / kvm->total_count * 100);
tools/perf/builtin-kvm.c:641:		pr_info("%8.2f%% ", (double)etime / kvm->total_time * 100);
tools/perf/builtin-kvm.c:650:		kvm->total_count, kvm->total_time / (double)NSEC_PER_USEC);
tools/perf/builtin-kvm.c:652:	if (kvm->lost_events)
tools/perf/builtin-kvm.c:653:		pr_info("\nLost events: %" PRIu64 "\n\n", kvm->lost_events);
tools/perf/builtin-kvm.c:664:	kvm->lost_events++;
tools/perf/builtin-kvm.c:672:	if (kvm->pid_list && intlist__find(kvm->pid_list, sample->pid) == NULL)
tools/perf/builtin-kvm.c:711:	if (kvm->live) {
tools/perf/builtin-kvm.c:720:		cpuid = kvm->session->header.env.cpuid;
tools/perf/builtin-kvm.c:753:	struct evlist *evlist = kvm->evlist;
tools/perf/builtin-kvm.c:774:		err = perf_session__queue_event(kvm->session, event, timestamp, 0);
tools/perf/builtin-kvm.c:806:	for (i = 0; i < kvm->evlist->core.nr_mmaps; i++) {
tools/perf/builtin-kvm.c:828:		struct ordered_events *oe = &kvm->session->ordered_events;
tools/perf/builtin-kvm.c:833:			if (kvm->lost_events)
tools/perf/builtin-kvm.c:835:					kvm->lost_events);
tools/perf/builtin-kvm.c:855:	kvm->timerfd = timerfd_create(CLOCK_MONOTONIC, TFD_NONBLOCK);
tools/perf/builtin-kvm.c:856:	if (kvm->timerfd < 0) {
tools/perf/builtin-kvm.c:861:	new_value.it_value.tv_sec = kvm->display_time;
tools/perf/builtin-kvm.c:863:	new_value.it_interval.tv_sec = kvm->display_time;
tools/perf/builtin-kvm.c:866:	if (timerfd_settime(kvm->timerfd, 0, &new_value, NULL) != 0) {
tools/perf/builtin-kvm.c:868:		close(kvm->timerfd);
tools/perf/builtin-kvm.c:882:	rc = read(kvm->timerfd, &c, sizeof(uint64_t));
tools/perf/builtin-kvm.c:904:	clear_events_cache_stats(kvm->kvm_events_cache);
tools/perf/builtin-kvm.c:905:	kvm->total_count = 0;
tools/perf/builtin-kvm.c:906:	kvm->total_time = 0;
tools/perf/builtin-kvm.c:907:	kvm->lost_events = 0;
tools/perf/builtin-kvm.c:947:	kvm->live = true;
tools/perf/builtin-kvm.c:953:	if (!verify_vcpu(kvm->trace_vcpu) ||
tools/perf/builtin-kvm.c:971:	if (evlist__add_pollfd(kvm->evlist, kvm->timerfd) < 0)
tools/perf/builtin-kvm.c:974:	nr_stdin = evlist__add_pollfd(kvm->evlist, fileno(stdin));
tools/perf/builtin-kvm.c:982:	evlist__enable(kvm->evlist);
tools/perf/builtin-kvm.c:985:		struct fdarray *fda = &kvm->evlist->core.pollfd;
tools/perf/builtin-kvm.c:1000:			err = evlist__poll(kvm->evlist, 100);
tools/perf/builtin-kvm.c:1003:	evlist__disable(kvm->evlist);
tools/perf/builtin-kvm.c:1011:	if (kvm->timerfd >= 0)
tools/perf/builtin-kvm.c:1012:		close(kvm->timerfd);
tools/perf/builtin-kvm.c:1022:	struct evlist *evlist = kvm->evlist;
tools/perf/builtin-kvm.c:1025:	evlist__config(evlist, &kvm->opts, NULL);
tools/perf/builtin-kvm.c:1065:	if (evlist__mmap(evlist, kvm->opts.mmap_pages) < 0) {
tools/perf/builtin-kvm.c:1090:		.path  = kvm->file_name,
tools/perf/builtin-kvm.c:1092:		.force = kvm->force,
tools/perf/builtin-kvm.c:1095:	kvm->tool = eops;
tools/perf/builtin-kvm.c:1096:	kvm->session = perf_session__new(&file, false, &kvm->tool);
tools/perf/builtin-kvm.c:1097:	if (IS_ERR(kvm->session)) {
tools/perf/builtin-kvm.c:1099:		return PTR_ERR(kvm->session);
tools/perf/builtin-kvm.c:1102:	symbol__init(&kvm->session->header.env);
tools/perf/builtin-kvm.c:1104:	if (!perf_session__has_traces(kvm->session, "kvm record")) {
tools/perf/builtin-kvm.c:1117:	ret = perf_session__process_events(kvm->session);
tools/perf/builtin-kvm.c:1120:	perf_session__delete(kvm->session);
tools/perf/builtin-kvm.c:1126:	if (kvm->opts.target.pid) {
tools/perf/builtin-kvm.c:1127:		kvm->pid_list = intlist__new(kvm->opts.target.pid);
tools/perf/builtin-kvm.c:1128:		if (kvm->pid_list == NULL) {
tools/perf/builtin-kvm.c:1140:	int vcpu = kvm->trace_vcpu;
tools/perf/builtin-kvm.c:1225:	rec_argv[i++] = STRDUP_FAIL_EXIT(kvm->file_name);
tools/perf/builtin-kvm.c:1258:		OPT_STRING(0, "event", &kvm->report_event, "report event",
tools/perf/builtin-kvm.c:1261:		OPT_INTEGER(0, "vcpu", &kvm->trace_vcpu,
tools/perf/builtin-kvm.c:1263:		OPT_STRING('k', "key", &kvm->sort_key, "sort-key",
tools/perf/builtin-kvm.c:1266:		OPT_STRING('p', "pid", &kvm->opts.target.pid, "pid",
tools/perf/builtin-kvm.c:1268:		OPT_BOOLEAN('f', "force", &kvm->force, "don't complain, do it"),
tools/perf/builtin-kvm.c:1286:	if (!kvm->opts.target.pid)
tools/perf/builtin-kvm.c:1287:		kvm->opts.target.system_wide = true;
tools/perf/builtin-kvm.c:1349:		OPT_STRING('p', "pid", &kvm->opts.target.pid, "pid",
tools/perf/builtin-kvm.c:1351:		OPT_CALLBACK('m', "mmap-pages", &kvm->opts.mmap_pages, "pages",
tools/perf/builtin-kvm.c:1355:		OPT_BOOLEAN('a', "all-cpus", &kvm->opts.target.system_wide,
tools/perf/builtin-kvm.c:1357:		OPT_UINTEGER('d', "display", &kvm->display_time,
tools/perf/builtin-kvm.c:1359:		OPT_STRING(0, "event", &kvm->report_event, "report event",
tools/perf/builtin-kvm.c:1362:		OPT_INTEGER(0, "vcpu", &kvm->trace_vcpu,
tools/perf/builtin-kvm.c:1364:		OPT_STRING('k', "key", &kvm->sort_key, "sort-key",
tools/perf/builtin-kvm.c:1367:		OPT_U64(0, "duration", &kvm->duration,
tools/perf/builtin-kvm.c:1385:	kvm->tool.sample = process_sample_event;
tools/perf/builtin-kvm.c:1386:	kvm->tool.comm   = perf_event__process_comm;
tools/perf/builtin-kvm.c:1387:	kvm->tool.exit   = perf_event__process_exit;
tools/perf/builtin-kvm.c:1388:	kvm->tool.fork   = perf_event__process_fork;
tools/perf/builtin-kvm.c:1389:	kvm->tool.lost   = process_lost_event;
tools/perf/builtin-kvm.c:1390:	kvm->tool.namespaces  = perf_event__process_namespaces;
tools/perf/builtin-kvm.c:1391:	kvm->tool.ordered_events = true;
tools/perf/builtin-kvm.c:1392:	perf_tool__fill_defaults(&kvm->tool);
tools/perf/builtin-kvm.c:1395:	kvm->display_time = 1;
tools/perf/builtin-kvm.c:1396:	kvm->opts.user_interval = 1;
tools/perf/builtin-kvm.c:1397:	kvm->opts.mmap_pages = 512;
tools/perf/builtin-kvm.c:1398:	kvm->opts.target.uses_mmap = false;
tools/perf/builtin-kvm.c:1399:	kvm->opts.target.uid_str = NULL;
tools/perf/builtin-kvm.c:1400:	kvm->opts.target.uid = UINT_MAX;
tools/perf/builtin-kvm.c:1414:	kvm->duration *= NSEC_PER_USEC;   /* convert usec to nsec */
tools/perf/builtin-kvm.c:1419:	err = target__validate(&kvm->opts.target);
tools/perf/builtin-kvm.c:1421:		target__strerror(&kvm->opts.target, err, errbuf, BUFSIZ);
tools/perf/builtin-kvm.c:1425:	if (target__none(&kvm->opts.target))
tools/perf/builtin-kvm.c:1426:		kvm->opts.target.system_wide = true;
tools/perf/builtin-kvm.c:1438:	kvm->evlist = kvm_live_event_list();
tools/perf/builtin-kvm.c:1439:	if (kvm->evlist == NULL) {
tools/perf/builtin-kvm.c:1444:	if (evlist__create_maps(kvm->evlist, &kvm->opts.target) < 0)
tools/perf/builtin-kvm.c:1450:	kvm->session = perf_session__new(&data, false, &kvm->tool);
tools/perf/builtin-kvm.c:1451:	if (IS_ERR(kvm->session)) {
tools/perf/builtin-kvm.c:1452:		err = PTR_ERR(kvm->session);
tools/perf/builtin-kvm.c:1455:	kvm->session->evlist = kvm->evlist;
tools/perf/builtin-kvm.c:1456:	perf_session__set_id_hdr_size(kvm->session);
tools/perf/builtin-kvm.c:1457:	ordered_events__set_copy_on_queue(&kvm->session->ordered_events, true);
tools/perf/builtin-kvm.c:1458:	machine__synthesize_threads(&kvm->session->machines.host, &kvm->opts.target,
tools/perf/builtin-kvm.c:1459:				    kvm->evlist->core.threads, false, 1);
tools/perf/builtin-kvm.c:1467:	perf_session__delete(kvm->session);
tools/perf/builtin-kvm.c:1468:	kvm->session = NULL;
tools/perf/builtin-kvm.c:1469:	evlist__delete(kvm->evlist);
tools/perf/tests/parse-events.c:31:	eventfile = get_events_file("kvm-s390");
tools/perf/tests/parse-events.c:1869:		.name  = "kvm-s390:kvm_s390_create_vm",
tools/testing/selftests/kvm/Makefile:120:# On s390, build the testcases KVM-enabled
tools/testing/selftests/kvm/memslot_perf_test.c:115: * all KVM-supported platforms.
tools/testing/selftests/rcutorture/bin/kvm-again.sh:6:# Usage: kvm-again.sh /path/to/old/run [ options ]
tools/testing/selftests/rcutorture/bin/kvm-again.sh:15:T=${TMPDIR-/tmp}/kvm-again.sh.$$
tools/testing/selftests/rcutorture/bin/kvm-again.sh:145:rm -f "$rundir"/*/{console.log,console.log.diags,qemu_pid,qemu-retval,Warnings,kvm-test-1-run.sh.out,kvm-test-1-run-qemu.sh.out,vmlinux} "$rundir"/log
tools/testing/selftests/rcutorture/bin/kvm-again.sh:157:	kvm-transform.sh "$kernel_dir/bzImage" "$qemu_cmd_dir/console.log" "$jitter_dir" $dur < $T/qemu-cmd > $i
tools/testing/selftests/rcutorture/bin/kvm-again.sh:175:		print "kvm-test-1-run-batch.sh" curbatch;
tools/testing/selftests/rcutorture/bin/kvm-again.sh:183:	print "kvm-test-1-run-batch.sh" curbatch
tools/testing/selftests/rcutorture/bin/kvm-again.sh:194:	kvm-recheck.sh "$rundir" > $T/kvm-recheck.sh.out 2>&1
tools/testing/selftests/rcutorture/bin/kvm-again.sh:196:	cat $T/kvm-recheck.sh.out | tee -a "$rundir/log"
tools/testing/selftests/rcutorture/bin/kvm-build.sh:4:# Build a kvm-ready Linux kernel from the tree in the current directory.
tools/testing/selftests/rcutorture/bin/kvm-build.sh:6:# Usage: kvm-build.sh config-template resdir
tools/testing/selftests/rcutorture/bin/kvm-build.sh:14:	echo "kvm-build.sh early exit due to run STOP request"
tools/testing/selftests/rcutorture/bin/kvm-build.sh:21:	echo "kvm-build.sh :$config_template: Not a readable file"
tools/testing/selftests/rcutorture/bin/kvm-recheck-rcuscale.sh:6:# Usage: kvm-recheck-rcuscale.sh resdir
tools/testing/selftests/rcutorture/bin/kvm-recheck-rcuscale.sh:23:if kvm-recheck-rcuscale-ftrace.sh $i
tools/testing/selftests/rcutorture/bin/kvm-check-branches.sh:11:# Usage: kvm-check-branches.sh commit1 commit2..commit3 commit4 ...
tools/testing/selftests/rcutorture/bin/kvm-recheck-lock.sh:6:# Usage: kvm-recheck-lock.sh resdir
tools/testing/selftests/rcutorture/bin/kvm-recheck-rcuscale-ftrace.sh:6:# printed.  Intended to be invoked from kvm-recheck-rcuscale.sh after
tools/testing/selftests/rcutorture/bin/kvm-recheck-rcuscale-ftrace.sh:9:# Usage: kvm-recheck-rcuscale-ftrace.sh resdir
tools/testing/selftests/rcutorture/bin/kvm-recheck-rcu.sh:6:# Usage: kvm-recheck-rcu.sh resdir
tools/testing/selftests/rcutorture/bin/kvm-find-errors.sh:10:# Usage: kvm-find-errors.sh directory
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-qemu.sh:4:# Carry out a kvm-based run for the specified qemu-cmd file, which might
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-qemu.sh:7:# Usage: kvm-test-1-run-qemu.sh qemu-cmd-dir
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-qemu.sh:20:T=${TMPDIR-/tmp}/kvm-test-1-run-qemu.sh.$$
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-qemu.sh:105:			grep "^(qemu) qemu:" $resdir/kvm-test-1-run.sh.out >> $resdir/Warnings 2>&1
tools/testing/selftests/rcutorture/bin/kvm-transform.sh:6:# Usage: kvm-transform.sh bzImage console.log jitter_dir [ seconds ] < qemu-cmd-in > qemu-cmd-out
tools/testing/selftests/rcutorture/bin/kvm-recheck.sh:4:# Given the results directories for previous KVM-based torture runs,
tools/testing/selftests/rcutorture/bin/kvm-recheck.sh:8:# Usage: kvm-recheck.sh resdir ...
tools/testing/selftests/rcutorture/bin/kvm-recheck.sh:16:T=/tmp/kvm-recheck.sh.$$
tools/testing/selftests/rcutorture/bin/kvm-recheck.sh:36:		kvm-recheck-${TORTURE_SUITE}.sh $i
tools/testing/selftests/rcutorture/bin/kvm-recheck.sh:89:EDITOR=echo kvm-find-errors.sh "${@: -1}" > $T 2>&1
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-batch.sh:4:# Carry out a kvm-based run for the specified batch of scenarios, which
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-batch.sh:7:# Usage: kvm-test-1-run-batch.sh SCENARIO [ SCENARIO ... ]
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-batch.sh:16:T=${TMPDIR-/tmp}/kvm-test-1-run-batch.sh.$$
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-batch.sh:55:	echo ---- System running test: `uname -a` > $i/kvm-test-1-run-qemu.sh.out
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-batch.sh:56:	echo > $i/kvm-test-1-run-qemu.sh.out
tools/testing/selftests/rcutorture/bin/kvm-test-1-run-batch.sh:57:	kvm-test-1-run-qemu.sh $i >> $i/kvm-test-1-run-qemu.sh.out 2>&1 &
tools/testing/selftests/rcutorture/bin/kvm-recheck-refscale.sh:6:# Usage: kvm-recheck-refscale.sh resdir
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:4:# Run a kvm-based test of the specified tree on the specified configs.
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:10:# Usage: kvm-test-1-run.sh config resdir seconds qemu-args boot_args_in
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:28:T=${TMPDIR-/tmp}/kvm-test-1-run.sh.$$
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:41:	echo "kvm-test-1-run.sh :$resdir: Not a writable directory, cannot store results into it"
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:81:	ln -s $base_resdir/Make*.out $resdir  # for kvm-recheck.sh
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:82:	ln -s $base_resdir/.config $resdir  # for kvm-recheck.sh
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:88:	ln -s $base_resdir/Make*.out $resdir  # for kvm-recheck.sh
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:89:	ln -s $base_resdir/.config $resdir  # for kvm-recheck.sh
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:96:elif kvm-build.sh $T/KcList $resdir
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:196:echo "   " $ tools/testing/selftests/rcutorture/bin/kvm-recheck.sh `dirname $resdir` >> $resdir/bare-metal
tools/testing/selftests/rcutorture/bin/kvm-test-1-run.sh:216:kvm-test-1-run-qemu.sh $resdir
tools/testing/selftests/rcutorture/bin/kvm-recheck-scf.sh:6:# Usage: kvm-recheck-rcu.sh resdir
tools/testing/selftests/rcutorture/bin/kvm.sh:475:		print "kvm-test-1-run.sh " CONFIGDIR cf[j], rd cfr[jn], dur " \"" TORTURE_QEMU_ARG "\" \"" TORTURE_BOOTARGS "\" > " rd cfr[jn]  "/kvm-test-1-run.sh.out 2>&1 &"
tools/testing/selftests/rcutorture/bin/kvm.sh:522:		print "cat " rd cfr[j]  "/kvm-test-1-run.sh.out | tee -a " rd "log";
tools/testing/selftests/rcutorture/bin/kvm.sh:562:kvm-recheck.sh $resdir/$ds > $T/kvm-recheck.sh.out 2>&1
tools/testing/selftests/rcutorture/bin/kvm.sh:565:echo "cat $T/kvm-recheck.sh.out | tee -a $resdir/$ds/log" >> $T/script
tools/testing/selftests/rcutorture/doc/rcu-test-image.txt:59:	http://sripathikodi.blogspot.com/2010/02/creating-kvm-bootable-fedora-system.html
tools/testing/selftests/rcutorture/doc/rcu-test-image.txt:63:	http://www.moe.co.uk/2011/01/07/pci_add_option_rom-failed-to-find-romfile-pxe-rtl8139-bin/ -- "apt-get install kvm-pxe"
virt/kvm/coalesced_mmio.c:54:	ring = dev->kvm->coalesced_mmio_ring;
virt/kvm/coalesced_mmio.c:69:	struct kvm_coalesced_mmio_ring *ring = dev->kvm->coalesced_mmio_ring;
virt/kvm/coalesced_mmio.c:75:	spin_lock(&dev->kvm->ring_lock);
virt/kvm/coalesced_mmio.c:80:		spin_unlock(&dev->kvm->ring_lock);
virt/kvm/coalesced_mmio.c:92:	spin_unlock(&dev->kvm->ring_lock);
virt/kvm/coalesced_mmio.c:118:	kvm->coalesced_mmio_ring = page_address(page);
virt/kvm/coalesced_mmio.c:123:	 * unregistration should only happen when kvm->slots_lock is held.
virt/kvm/coalesced_mmio.c:125:	spin_lock_init(&kvm->ring_lock);
virt/kvm/coalesced_mmio.c:126:	INIT_LIST_HEAD(&kvm->coalesced_zones);
virt/kvm/coalesced_mmio.c:133:	if (kvm->coalesced_mmio_ring)
virt/kvm/coalesced_mmio.c:134:		free_page((unsigned long)kvm->coalesced_mmio_ring);
virt/kvm/coalesced_mmio.c:155:	mutex_lock(&kvm->slots_lock);
virt/kvm/coalesced_mmio.c:161:	list_add_tail(&dev->list, &kvm->coalesced_zones);
virt/kvm/coalesced_mmio.c:162:	mutex_unlock(&kvm->slots_lock);
virt/kvm/coalesced_mmio.c:167:	mutex_unlock(&kvm->slots_lock);
virt/kvm/coalesced_mmio.c:182:	mutex_lock(&kvm->slots_lock);
virt/kvm/coalesced_mmio.c:184:	list_for_each_entry_safe(dev, tmp, &kvm->coalesced_zones, list) {
virt/kvm/coalesced_mmio.c:202:	mutex_unlock(&kvm->slots_lock);
virt/kvm/vfio.c:388:	.name = "kvm-vfio",
virt/kvm/vfio.c:401:	list_for_each_entry(tmp, &dev->kvm->devices, vm_node)
virt/kvm/eventfd.c:78:	idx = srcu_read_lock(&kvm->irq_srcu);
virt/kvm/eventfd.c:83:	srcu_read_unlock(&kvm->irq_srcu, idx);
virt/kvm/eventfd.c:92:	mutex_lock(&kvm->irqfds.resampler_lock);
virt/kvm/eventfd.c:95:	synchronize_srcu(&kvm->irq_srcu);
virt/kvm/eventfd.c:105:	mutex_unlock(&kvm->irqfds.resampler_lock);
virt/kvm/eventfd.c:120:	synchronize_srcu(&kvm->irq_srcu);
virt/kvm/eventfd.c:150:/* assumes kvm->irqfds.lock is held */
virt/kvm/eventfd.c:160: * assumes kvm->irqfds.lock is held
virt/kvm/eventfd.c:200:		idx = srcu_read_lock(&kvm->irq_srcu);
virt/kvm/eventfd.c:210:		srcu_read_unlock(&kvm->irq_srcu, idx);
virt/kvm/eventfd.c:218:		spin_lock_irqsave(&kvm->irqfds.lock, iflags);
virt/kvm/eventfd.c:232:		spin_unlock_irqrestore(&kvm->irqfds.lock, iflags);
virt/kvm/eventfd.c:311:	seqcount_spinlock_init(&irqfd->irq_entry_sc, &kvm->irqfds.lock);
virt/kvm/eventfd.c:339:		mutex_lock(&kvm->irqfds.resampler_lock);
virt/kvm/eventfd.c:342:				    &kvm->irqfds.resampler_list, link) {
virt/kvm/eventfd.c:354:				mutex_unlock(&kvm->irqfds.resampler_lock);
virt/kvm/eventfd.c:364:			list_add(&resampler->link, &kvm->irqfds.resampler_list);
virt/kvm/eventfd.c:371:		synchronize_srcu(&kvm->irq_srcu);
virt/kvm/eventfd.c:373:		mutex_unlock(&kvm->irqfds.resampler_lock);
virt/kvm/eventfd.c:383:	spin_lock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:386:	list_for_each_entry(tmp, &kvm->irqfds.items, list) {
virt/kvm/eventfd.c:391:		spin_unlock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:395:	idx = srcu_read_lock(&kvm->irq_srcu);
virt/kvm/eventfd.c:398:	list_add_tail(&irqfd->list, &kvm->irqfds.items);
virt/kvm/eventfd.c:400:	spin_unlock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:425:	srcu_read_unlock(&kvm->irq_srcu, idx);
virt/kvm/eventfd.c:456:	idx = srcu_read_lock(&kvm->irq_srcu);
virt/kvm/eventfd.c:459:		hlist_for_each_entry_rcu(kian, &kvm->irq_ack_notifier_list,
virt/kvm/eventfd.c:462:				srcu_read_unlock(&kvm->irq_srcu, idx);
virt/kvm/eventfd.c:466:	srcu_read_unlock(&kvm->irq_srcu, idx);
virt/kvm/eventfd.c:476:	hlist_for_each_entry_rcu(kian, &kvm->irq_ack_notifier_list,
virt/kvm/eventfd.c:488:	idx = srcu_read_lock(&kvm->irq_srcu);
virt/kvm/eventfd.c:492:	srcu_read_unlock(&kvm->irq_srcu, idx);
virt/kvm/eventfd.c:498:	mutex_lock(&kvm->irq_lock);
virt/kvm/eventfd.c:499:	hlist_add_head_rcu(&kian->link, &kvm->irq_ack_notifier_list);
virt/kvm/eventfd.c:500:	mutex_unlock(&kvm->irq_lock);
virt/kvm/eventfd.c:507:	mutex_lock(&kvm->irq_lock);
virt/kvm/eventfd.c:509:	mutex_unlock(&kvm->irq_lock);
virt/kvm/eventfd.c:510:	synchronize_srcu(&kvm->irq_srcu);
virt/kvm/eventfd.c:519:	spin_lock_init(&kvm->irqfds.lock);
virt/kvm/eventfd.c:520:	INIT_LIST_HEAD(&kvm->irqfds.items);
virt/kvm/eventfd.c:521:	INIT_LIST_HEAD(&kvm->irqfds.resampler_list);
virt/kvm/eventfd.c:522:	mutex_init(&kvm->irqfds.resampler_lock);
virt/kvm/eventfd.c:524:	INIT_LIST_HEAD(&kvm->ioeventfds);
virt/kvm/eventfd.c:541:	spin_lock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:543:	list_for_each_entry_safe(irqfd, tmp, &kvm->irqfds.items, list) {
virt/kvm/eventfd.c:558:	spin_unlock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:592:	spin_lock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:594:	list_for_each_entry_safe(irqfd, tmp, &kvm->irqfds.items, list)
virt/kvm/eventfd.c:597:	spin_unlock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:609: * Caller must invoke synchronize_srcu(&kvm->irq_srcu) afterwards.
virt/kvm/eventfd.c:615:	spin_lock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:617:	list_for_each_entry(irqfd, &kvm->irqfds.items, list) {
virt/kvm/eventfd.c:630:	spin_unlock_irq(&kvm->irqfds.lock);
virt/kvm/eventfd.c:640:	irqfd_cleanup_wq = alloc_workqueue("kvm-irqfd-cleanup", 0, 0);
virt/kvm/eventfd.c:763:/* assumes kvm->slots_lock held */
virt/kvm/eventfd.c:769:	list_for_each_entry(_p, &kvm->ioeventfds, list)
virt/kvm/eventfd.c:821:	mutex_lock(&kvm->slots_lock);
virt/kvm/eventfd.c:837:	list_add_tail(&p->list, &kvm->ioeventfds);
virt/kvm/eventfd.c:839:	mutex_unlock(&kvm->slots_lock);
virt/kvm/eventfd.c:844:	mutex_unlock(&kvm->slots_lock);
virt/kvm/eventfd.c:869:	mutex_lock(&kvm->slots_lock);
virt/kvm/eventfd.c:871:	list_for_each_entry_safe(p, tmp, &kvm->ioeventfds, list) {
virt/kvm/eventfd.c:892:	mutex_unlock(&kvm->slots_lock);
virt/kvm/irqchip.c:29:	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
virt/kvm/irqchip.c:30:					lockdep_is_held(&kvm->irq_lock));
virt/kvm/irqchip.c:45:	irq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);
virt/kvm/irqchip.c:83:	idx = srcu_read_lock(&kvm->irq_srcu);
virt/kvm/irqchip.c:85:	srcu_read_unlock(&kvm->irq_srcu, idx);
virt/kvm/irqchip.c:124:	struct kvm_irq_routing_table *rt = rcu_access_pointer(kvm->irq_routing);
virt/kvm/irqchip.c:219:	mutex_lock(&kvm->irq_lock);
virt/kvm/irqchip.c:220:	old = rcu_dereference_protected(kvm->irq_routing, 1);
virt/kvm/irqchip.c:221:	rcu_assign_pointer(kvm->irq_routing, new);
virt/kvm/irqchip.c:224:	mutex_unlock(&kvm->irq_lock);
virt/kvm/irqchip.c:228:	synchronize_srcu_expedited(&kvm->irq_srcu);
virt/kvm/kvm_main.c:98: *	kvm->lock --> kvm->slots_lock --> kvm->irq_lock
virt/kvm/kvm_main.c:319:	long dirty_count = smp_load_acquire(&kvm->tlbs_dirty);
virt/kvm/kvm_main.c:334:		++kvm->stat.remote_tlb_flush;
virt/kvm/kvm_main.c:335:	cmpxchg(&kvm->tlbs_dirty, dirty_count, 0);
virt/kvm/kvm_main.c:453:	idx = srcu_read_lock(&kvm->srcu);
virt/kvm/kvm_main.c:455:	srcu_read_unlock(&kvm->srcu, idx);
virt/kvm/kvm_main.c:500:	idx = srcu_read_lock(&kvm->srcu);
virt/kvm/kvm_main.c:549:	if (range->flush_on_ret && (ret || kvm->tlbs_dirty))
virt/kvm/kvm_main.c:556:	srcu_read_unlock(&kvm->srcu, idx);
virt/kvm/kvm_main.c:614:	WARN_ON_ONCE(!kvm->mmu_notifier_count);
virt/kvm/kvm_main.c:627:	kvm->mmu_notifier_count++;
virt/kvm/kvm_main.c:628:	if (likely(kvm->mmu_notifier_count == 1)) {
virt/kvm/kvm_main.c:629:		kvm->mmu_notifier_range_start = start;
virt/kvm/kvm_main.c:630:		kvm->mmu_notifier_range_end = end;
virt/kvm/kvm_main.c:641:		kvm->mmu_notifier_range_start =
virt/kvm/kvm_main.c:642:			min(kvm->mmu_notifier_range_start, start);
virt/kvm/kvm_main.c:643:		kvm->mmu_notifier_range_end =
virt/kvm/kvm_main.c:644:			max(kvm->mmu_notifier_range_end, end);
virt/kvm/kvm_main.c:677:	kvm->mmu_notifier_seq++;
virt/kvm/kvm_main.c:684:	kvm->mmu_notifier_count--;
virt/kvm/kvm_main.c:703:	BUG_ON(kvm->mmu_notifier_count < 0);
virt/kvm/kvm_main.c:755:	idx = srcu_read_lock(&kvm->srcu);
virt/kvm/kvm_main.c:757:	srcu_read_unlock(&kvm->srcu, idx);
virt/kvm/kvm_main.c:773:	kvm->mmu_notifier.ops = &kvm_mmu_notifier_ops;
virt/kvm/kvm_main.c:774:	return mmu_notifier_register(&kvm->mmu_notifier, current->mm);
virt/kvm/kvm_main.c:837:	if (!kvm->debugfs_dentry)
virt/kvm/kvm_main.c:840:	debugfs_remove_recursive(kvm->debugfs_dentry);
virt/kvm/kvm_main.c:842:	if (kvm->debugfs_stat_data) {
virt/kvm/kvm_main.c:844:			kfree(kvm->debugfs_stat_data[i]);
virt/kvm/kvm_main.c:845:		kfree(kvm->debugfs_stat_data);
virt/kvm/kvm_main.c:859:	kvm->debugfs_dentry = debugfs_create_dir(dir_name, kvm_debugfs_dir);
virt/kvm/kvm_main.c:861:	kvm->debugfs_stat_data = kcalloc(kvm_debugfs_num_entries,
virt/kvm/kvm_main.c:862:					 sizeof(*kvm->debugfs_stat_data),
virt/kvm/kvm_main.c:864:	if (!kvm->debugfs_stat_data)
virt/kvm/kvm_main.c:874:		kvm->debugfs_stat_data[p - debugfs_entries] = stat_data;
virt/kvm/kvm_main.c:876:				    kvm->debugfs_dentry, stat_data,
virt/kvm/kvm_main.c:910:	kvm->mm = current->mm;
virt/kvm/kvm_main.c:912:	mutex_init(&kvm->lock);
virt/kvm/kvm_main.c:913:	mutex_init(&kvm->irq_lock);
virt/kvm/kvm_main.c:914:	mutex_init(&kvm->slots_lock);
virt/kvm/kvm_main.c:915:	INIT_LIST_HEAD(&kvm->devices);
virt/kvm/kvm_main.c:916:	INIT_LIST_HEAD(&kvm->online_vcpu_list);
virt/kvm/kvm_main.c:917:	INIT_LIST_HEAD(&kvm->offline_vcpu_list);
virt/kvm/kvm_main.c:921:	if (init_srcu_struct(&kvm->srcu))
virt/kvm/kvm_main.c:923:	if (init_srcu_struct(&kvm->irq_srcu))
virt/kvm/kvm_main.c:926:	refcount_set(&kvm->users_count, 1);
virt/kvm/kvm_main.c:934:		rcu_assign_pointer(kvm->memslots[i], slots);
virt/kvm/kvm_main.c:938:		rcu_assign_pointer(kvm->buses[i],
virt/kvm/kvm_main.c:940:		if (!kvm->buses[i])
virt/kvm/kvm_main.c:944:	kvm->max_halt_poll_ns = halt_poll_ns;
virt/kvm/kvm_main.c:955:	INIT_HLIST_HEAD(&kvm->irq_ack_notifier_list);
virt/kvm/kvm_main.c:967:	list_add(&kvm->vm_list, &vm_list);
virt/kvm/kvm_main.c:976:	if (kvm->mmu_notifier.ops)
virt/kvm/kvm_main.c:977:		mmu_notifier_unregister(&kvm->mmu_notifier, current->mm);
virt/kvm/kvm_main.c:984:	WARN_ON_ONCE(!refcount_dec_and_test(&kvm->users_count));
virt/kvm/kvm_main.c:989:	cleanup_srcu_struct(&kvm->irq_srcu);
virt/kvm/kvm_main.c:991:	cleanup_srcu_struct(&kvm->srcu);
virt/kvm/kvm_main.c:1003:	 * We do not need to take the kvm->lock here, because nobody else
virt/kvm/kvm_main.c:1007:	list_for_each_entry_safe(dev, tmp, &kvm->devices, vm_node) {
virt/kvm/kvm_main.c:1016:	struct mm_struct *mm = kvm->mm;
virt/kvm/kvm_main.c:1022:	list_del(&kvm->vm_list);
virt/kvm/kvm_main.c:1032:		kvm->buses[i] = NULL;
virt/kvm/kvm_main.c:1036:	mmu_notifier_unregister(&kvm->mmu_notifier, kvm->mm);
virt/kvm/kvm_main.c:1044:	cleanup_srcu_struct(&kvm->irq_srcu);
virt/kvm/kvm_main.c:1045:	cleanup_srcu_struct(&kvm->srcu);
virt/kvm/kvm_main.c:1054:	refcount_inc(&kvm->users_count);
virt/kvm/kvm_main.c:1060:	if (refcount_dec_and_test(&kvm->users_count))
virt/kvm/kvm_main.c:1074:	WARN_ON(refcount_dec_and_test(&kvm->users_count));
virt/kvm/kvm_main.c:1288:	rcu_assign_pointer(kvm->memslots[as_id], slots);
virt/kvm/kvm_main.c:1289:	synchronize_srcu_expedited(&kvm->srcu);
virt/kvm/kvm_main.c:1432: * Must be called holding kvm->slots_lock for write.
virt/kvm/kvm_main.c:1530:	else if (!new.dirty_bitmap && !kvm->dirty_ring_size) {
virt/kvm/kvm_main.c:1559:	mutex_lock(&kvm->slots_lock);
virt/kvm/kvm_main.c:1561:	mutex_unlock(&kvm->slots_lock);
virt/kvm/kvm_main.c:1592:	if (kvm->dirty_ring_size)
virt/kvm/kvm_main.c:1657:	if (kvm->dirty_ring_size)
virt/kvm/kvm_main.c:1676:	if (kvm->manual_dirty_log_protect) {
virt/kvm/kvm_main.c:1742:	mutex_lock(&kvm->slots_lock);
virt/kvm/kvm_main.c:1746:	mutex_unlock(&kvm->slots_lock);
virt/kvm/kvm_main.c:1769:	if (kvm->dirty_ring_size)
virt/kvm/kvm_main.c:1837:	mutex_lock(&kvm->slots_lock);
virt/kvm/kvm_main.c:1841:	mutex_unlock(&kvm->slots_lock);
virt/kvm/kvm_main.c:2853:		if (kvm->dirty_ring_size)
virt/kvm/kvm_main.c:2917:	if (val > vcpu->kvm->max_halt_poll_ns)
virt/kvm/kvm_main.c:2918:		val = vcpu->kvm->max_halt_poll_ns;
virt/kvm/kvm_main.c:2943:	int idx = srcu_read_lock(&vcpu->kvm->srcu);
virt/kvm/kvm_main.c:2958:	srcu_read_unlock(&vcpu->kvm->srcu, idx);
virt/kvm/kvm_main.c:3024:		} else if (vcpu->kvm->max_halt_poll_ns) {
virt/kvm/kvm_main.c:3029:					block_ns > vcpu->kvm->max_halt_poll_ns)
virt/kvm/kvm_main.c:3032:			else if (vcpu->halt_poll_ns < vcpu->kvm->max_halt_poll_ns &&
virt/kvm/kvm_main.c:3033:					block_ns < vcpu->kvm->max_halt_poll_ns)
virt/kvm/kvm_main.c:3172:	int last_boosted_vcpu = me->kvm->last_boosted_vcpu;
virt/kvm/kvm_main.c:3209:				kvm->last_boosted_vcpu = i;
virt/kvm/kvm_main.c:3230:	     kvm->dirty_ring_size / PAGE_SIZE);
virt/kvm/kvm_main.c:3249:		page = virt_to_page(vcpu->kvm->coalesced_mmio_ring);
virt/kvm/kvm_main.c:3303:	snprintf(name, sizeof(name), "kvm-vcpu:%d", vcpu->vcpu_id);
virt/kvm/kvm_main.c:3318:					    vcpu->kvm->debugfs_dentry);
virt/kvm/kvm_main.c:3336:	mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:3337:	if (kvm->created_vcpus == KVM_MAX_VCPUS) {
virt/kvm/kvm_main.c:3338:		mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3342:	kvm->created_vcpus++;
virt/kvm/kvm_main.c:3343:	mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3369:	if (kvm->dirty_ring_size) {
virt/kvm/kvm_main.c:3371:					 id, kvm->dirty_ring_size);
virt/kvm/kvm_main.c:3376:	mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:3382:	vcpu->vcpu_idx = atomic_read(&kvm->online_vcpus);
virt/kvm/kvm_main.c:3383:	BUG_ON(kvm->vcpus[vcpu->vcpu_idx]);
virt/kvm/kvm_main.c:3393:	kvm->vcpus[vcpu->vcpu_idx] = vcpu;
virt/kvm/kvm_main.c:3396:	 * Pairs with smp_rmb() in kvm_get_vcpu.  Write kvm->vcpus
virt/kvm/kvm_main.c:3397:	 * before kvm->online_vcpu's incremented value.
virt/kvm/kvm_main.c:3400:	atomic_inc(&kvm->online_vcpus);
virt/kvm/kvm_main.c:3403:	list_add(&vcpu->sched_stat_list, &kvm->offline_vcpu_list);
virt/kvm/kvm_main.c:3405:	mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3411:	mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3420:	mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:3421:	kvm->created_vcpus--;
virt/kvm/kvm_main.c:3422:	mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3446:	if (vcpu->kvm->mm != current->mm)
virt/kvm/kvm_main.c:3652:	if (vcpu->kvm->mm != current->mm)
virt/kvm/kvm_main.c:3718:	if (dev->kvm->mm != current->mm)
virt/kvm/kvm_main.c:3742:		mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:3745:		mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3819:	mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:3822:		mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3826:	list_add(&dev->vm_node, &kvm->devices);
virt/kvm/kvm_main.c:3827:	mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3836:		mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:3838:		mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3919:	if (kvm->dirty_ring_size)
virt/kvm/kvm_main.c:3922:	mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:3924:	if (kvm->created_vcpus) {
virt/kvm/kvm_main.c:3928:		kvm->dirty_ring_size = size;
virt/kvm/kvm_main.c:3932:	mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:3942:	if (!kvm->dirty_ring_size)
virt/kvm/kvm_main.c:3945:	mutex_lock(&kvm->slots_lock);
virt/kvm/kvm_main.c:3950:	mutex_unlock(&kvm->slots_lock);
virt/kvm/kvm_main.c:3977:		kvm->manual_dirty_log_protect = cap->args[0];
virt/kvm/kvm_main.c:3985:		kvm->max_halt_poll_ns = cap->args[0];
virt/kvm/kvm_main.c:4002:	if (kvm->mm != current->mm)
virt/kvm/kvm_main.c:4200:	if (kvm->mm != current->mm)
virt/kvm/kvm_main.c:4256:	file = anon_inode_getfile("kvm-vm", &kvm_vm_fops, kvm, O_RDWR);
virt/kvm/kvm_main.c:4527:/* kvm_io_bus_write - called under kvm->slots_lock */
virt/kvm/kvm_main.c:4540:	bus = srcu_dereference(vcpu->kvm->buses[bus_idx], &vcpu->kvm->srcu);
virt/kvm/kvm_main.c:4548:/* kvm_io_bus_write_cookie - called under kvm->slots_lock */
virt/kvm/kvm_main.c:4560:	bus = srcu_dereference(vcpu->kvm->buses[bus_idx], &vcpu->kvm->srcu);
virt/kvm/kvm_main.c:4598:/* kvm_io_bus_read - called under kvm->slots_lock */
virt/kvm/kvm_main.c:4611:	bus = srcu_dereference(vcpu->kvm->buses[bus_idx], &vcpu->kvm->srcu);
virt/kvm/kvm_main.c:4654:	rcu_assign_pointer(kvm->buses[bus_idx], new_bus);
virt/kvm/kvm_main.c:4655:	synchronize_srcu_expedited(&kvm->srcu);
virt/kvm/kvm_main.c:4667:	lockdep_assert_held(&kvm->slots_lock);
virt/kvm/kvm_main.c:4691:	rcu_assign_pointer(kvm->buses[bus_idx], new_bus);
virt/kvm/kvm_main.c:4692:	synchronize_srcu_expedited(&kvm->srcu);
virt/kvm/kvm_main.c:4715:	srcu_idx = srcu_read_lock(&kvm->srcu);
virt/kvm/kvm_main.c:4717:	bus = srcu_dereference(kvm->buses[bus_idx], &kvm->srcu);
virt/kvm/kvm_main.c:4728:	srcu_read_unlock(&kvm->srcu, srcu_idx);
virt/kvm/kvm_main.c:4746:	if (!refcount_inc_not_zero(&stat_data->kvm->users_count))
virt/kvm/kvm_main.c:4970:		kvm->userspace_pid = task_pid_nr(current);
virt/kvm/kvm_main.c:4974:	add_uevent_var(env, "PID=%d", kvm->userspace_pid);
virt/kvm/kvm_main.c:4976:	if (!IS_ERR_OR_NULL(kvm->debugfs_dentry)) {
virt/kvm/kvm_main.c:4980:			tmp = dentry_path_raw(kvm->debugfs_dentry, p, PATH_MAX);
virt/kvm/kvm_main.c:5040:	mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:5042:	list_add(&vcpu->sched_stat_list, &kvm->online_vcpu_list);
virt/kvm/kvm_main.c:5043:	mutex_unlock(&kvm->lock);
virt/kvm/kvm_main.c:5060:	mutex_lock(&kvm->lock);
virt/kvm/kvm_main.c:5062:	list_add(&vcpu->sched_stat_list, &kvm->offline_vcpu_list);
virt/kvm/kvm_main.c:5063:	mutex_unlock(&kvm->lock);
